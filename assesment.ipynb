{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assesment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMxf2pw2+9O8/Su9bPN0KAq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyuponponzu/signate_assesment/blob/master/assesment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02-SmIgQ-1F2",
        "colab_type": "text"
      },
      "source": [
        "# **セットアップ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OlT_CraoQ7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "feabd4ba-767e-47cd-880a-b827fd8fa46d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCFE5R89ofYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d79f041e-cb57-423c-feda-9db695f3bbe7"
      },
      "source": [
        "%cd /content/drive/'My Drive'/SIGNATE/\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/SIGNATE\n",
            "assesment.ipynb  sample_submit.csv  test.csv   train.pkl\n",
            "catboost_info\t target.pkl\t    train.csv  zipcode_onehot.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njwjw3wm9Xk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca975e69-04de-41c3-c7d2-bb4aa5dee9d9"
      },
      "source": [
        "!pip install japanize-matplotlib\n",
        "#!pip install pymc3==3.8\n",
        "!pip install pandas-profiling==2.7.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: japanize-matplotlib in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from japanize-matplotlib) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize-matplotlib) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize-matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize-matplotlib) (1.18.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize-matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize-matplotlib) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->japanize-matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pandas-profiling==2.7.1 in /usr/local/lib/python3.6/dist-packages (2.7.1)\n",
            "Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (7.5.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (1.4.1)\n",
            "Requirement already satisfied: visions[type_image_path]==0.4.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (0.4.1)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (1.18.5)\n",
            "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (1.0.5)\n",
            "Requirement already satisfied: astropy>=4.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (4.0.1.post1)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (4.48.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (2.23.0)\n",
            "Requirement already satisfied: phik>=0.9.10 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (0.10.0)\n",
            "Requirement already satisfied: confuse>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (1.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (0.16.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (0.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (3.2.2)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (0.0.6)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.7.1) (2.11.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.0.7)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.3.3)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.5.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (2.5)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (20.1.0)\n",
            "Requirement already satisfied: Pillow; extra == \"type_image_path\" in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (7.0.0)\n",
            "Requirement already satisfied: imagehash; extra == \"type_image_path\" in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (4.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.7.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.7.1) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (3.0.4)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.10->pandas-profiling==2.7.1) (0.48.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.7.1) (3.13)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from missingno>=0.4.2->pandas-profiling==2.7.1) (0.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.11.1->pandas-profiling==2.7.1) (1.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.6.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (49.6.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.10->pandas-profiling==2.7.1) (0.31.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (19.0.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.2.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (3.1.5)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XroF8bUI-5OR",
        "colab_type": "text"
      },
      "source": [
        "# **データ探索**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq0fO9Tkpbsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1e7e7688-e41e-4287-de09-c991d208f398"
      },
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from IPython.core.display import display, HTML \n",
        "warnings.filterwarnings('ignore')\n",
        "train=pd.read_csv(\"train.csv\")\n",
        "test=pd.read_csv(\"test.csv\")\n",
        "\n",
        "import pandas_profiling as pdp\n",
        "df=pd.concat([train,test],sort=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/japanize_matplotlib/japanize_matplotlib.py:15: MatplotlibDeprecationWarning: \n",
            "The createFontList function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use FontManager.addfont instead.\n",
            "  font_list = font_manager.createFontList(font_files)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F2EbnHTpWoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "a0bd3512-f744-4f87-d98c-9b5f54e8b629"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>amenities</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bed_type</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>cancellation_policy</th>\n",
              "      <th>city</th>\n",
              "      <th>cleaning_fee</th>\n",
              "      <th>description</th>\n",
              "      <th>first_review</th>\n",
              "      <th>host_has_profile_pic</th>\n",
              "      <th>host_identity_verified</th>\n",
              "      <th>host_response_rate</th>\n",
              "      <th>host_since</th>\n",
              "      <th>instant_bookable</th>\n",
              "      <th>last_review</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>name</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>property_type</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>room_type</th>\n",
              "      <th>thumbnail_url</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>{TV,\"Wireless Internet\",Kitchen,\"Free parking ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>flexible</td>\n",
              "      <td>LA</td>\n",
              "      <td>t</td>\n",
              "      <td>My place is meant for family and a few friends...</td>\n",
              "      <td>2016-07-27</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-07-13</td>\n",
              "      <td>f</td>\n",
              "      <td>2016-07-27</td>\n",
              "      <td>33.788931</td>\n",
              "      <td>-118.154761</td>\n",
              "      <td>The Penthouse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>60.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90804</td>\n",
              "      <td>138.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>strict</td>\n",
              "      <td>DC</td>\n",
              "      <td>t</td>\n",
              "      <td>This is a new listing for a lovely guest bedro...</td>\n",
              "      <td>2016-09-12</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2015-12-30</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-03-31</td>\n",
              "      <td>38.934810</td>\n",
              "      <td>-76.978190</td>\n",
              "      <td>Guest Bedroom in Brookland</td>\n",
              "      <td>Brookland</td>\n",
              "      <td>9</td>\n",
              "      <td>House</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/e4d8b51f-6...</td>\n",
              "      <td>20018</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",Kitchen,\"Indo...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>strict</td>\n",
              "      <td>NYC</td>\n",
              "      <td>t</td>\n",
              "      <td>We're looking forward to your stay at our apt....</td>\n",
              "      <td>2016-06-15</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>100%</td>\n",
              "      <td>2016-05-21</td>\n",
              "      <td>t</td>\n",
              "      <td>2017-08-13</td>\n",
              "      <td>40.695118</td>\n",
              "      <td>-73.926240</td>\n",
              "      <td>Clean Modern Room in Lux Apt 1 Block From J Train</td>\n",
              "      <td>Bushwick</td>\n",
              "      <td>27</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>83.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/5ffecc9b-d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>strict</td>\n",
              "      <td>SF</td>\n",
              "      <td>t</td>\n",
              "      <td>BEST CITY VIEWS - - ROOF DECK W/ BBQ &amp; WiFi - ...</td>\n",
              "      <td>2014-03-15</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2012-06-19</td>\n",
              "      <td>t</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>37.796728</td>\n",
              "      <td>-122.411906</td>\n",
              "      <td>BEST views + reviews! 5/5 stars*****</td>\n",
              "      <td>Nob Hill</td>\n",
              "      <td>38</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>95.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94133</td>\n",
              "      <td>166.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",\"Air conditio...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>strict</td>\n",
              "      <td>NYC</td>\n",
              "      <td>t</td>\n",
              "      <td>Charming Apartment on the upper west side of M...</td>\n",
              "      <td>2015-08-05</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2015-03-25</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-09-10</td>\n",
              "      <td>40.785050</td>\n",
              "      <td>-73.974691</td>\n",
              "      <td>Charming 1-bedroom - UWS Manhattan</td>\n",
              "      <td>Upper West Side</td>\n",
              "      <td>5</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/92879730/5...</td>\n",
              "      <td>10024</td>\n",
              "      <td>165.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  accommodates  ... zipcode      y\n",
              "0   0             6  ...   90804  138.0\n",
              "1   1             2  ...   20018   42.0\n",
              "2   2             2  ...     NaN   65.0\n",
              "3   3             2  ...   94133  166.0\n",
              "4   4             2  ...   10024  165.0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0rRI4iM0pME",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "994a4731-cbbb-4e8c-f9f4-96df6448fdf0"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>amenities</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bed_type</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>cancellation_policy</th>\n",
              "      <th>city</th>\n",
              "      <th>cleaning_fee</th>\n",
              "      <th>description</th>\n",
              "      <th>first_review</th>\n",
              "      <th>host_has_profile_pic</th>\n",
              "      <th>host_identity_verified</th>\n",
              "      <th>host_response_rate</th>\n",
              "      <th>host_since</th>\n",
              "      <th>instant_bookable</th>\n",
              "      <th>last_review</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>name</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>property_type</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>room_type</th>\n",
              "      <th>thumbnail_url</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>{TV,\"Cable TV\",\"Wireless Internet\",\"Air condit...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>strict</td>\n",
              "      <td>Boston</td>\n",
              "      <td>t</td>\n",
              "      <td>Feel free to book INSTANTLY. You can check-in ...</td>\n",
              "      <td>2017-01-09</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>100%</td>\n",
              "      <td>2016-08-23</td>\n",
              "      <td>t</td>\n",
              "      <td>2017-09-25</td>\n",
              "      <td>42.359278</td>\n",
              "      <td>-71.069962</td>\n",
              "      <td>Gorgeous 2BR/2BA Duplex in Beacon Hill</td>\n",
              "      <td>Beacon Hill</td>\n",
              "      <td>58</td>\n",
              "      <td>House</td>\n",
              "      <td>90.0</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/7e4808b4-5...</td>\n",
              "      <td>02114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>moderate</td>\n",
              "      <td>LA</td>\n",
              "      <td>t</td>\n",
              "      <td>The guest house is close to: Equinox West Holl...</td>\n",
              "      <td>2016-08-17</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2014-09-03</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-05-02</td>\n",
              "      <td>34.084747</td>\n",
              "      <td>-118.367355</td>\n",
              "      <td>Luxury 1 Bedroom West Hollywood City Center</td>\n",
              "      <td>West Hollywood</td>\n",
              "      <td>4</td>\n",
              "      <td>Guesthouse</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/5392fbd6-6...</td>\n",
              "      <td>90046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,\"Wireless Internet\",\"Air conditioning\",Kit...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>flexible</td>\n",
              "      <td>NYC</td>\n",
              "      <td>f</td>\n",
              "      <td>Private room in a three bedroom apartment in N...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2012-10-17</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.720541</td>\n",
              "      <td>-73.959192</td>\n",
              "      <td>Bedroom with Patio in Prime Williamsburg Locat...</td>\n",
              "      <td>Williamsburg</td>\n",
              "      <td>0</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private room</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/544d3b89-d...</td>\n",
              "      <td>11249.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>strict</td>\n",
              "      <td>NYC</td>\n",
              "      <td>f</td>\n",
              "      <td>The apartment is located in historic Bed Stuy ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013-01-23</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.681117</td>\n",
              "      <td>-73.944091</td>\n",
              "      <td>Cozy apartment in Brooklyn</td>\n",
              "      <td>Bedford-Stuyvesant</td>\n",
              "      <td>0</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/26baf7ba-0...</td>\n",
              "      <td>11216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",\"Air conditio...</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>strict</td>\n",
              "      <td>LA</td>\n",
              "      <td>t</td>\n",
              "      <td>Our cozy, pet friendly one bedroom apartment/l...</td>\n",
              "      <td>2015-08-01</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2014-12-28</td>\n",
              "      <td>f</td>\n",
              "      <td>2016-09-11</td>\n",
              "      <td>34.150995</td>\n",
              "      <td>-118.409359</td>\n",
              "      <td>Cozy, sunny, pet friendly loft/apt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>Loft</td>\n",
              "      <td>92.0</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/86107545/9...</td>\n",
              "      <td>91604</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  accommodates  ...                                      thumbnail_url  zipcode\n",
              "0   0             6  ...  https://a0.muscache.com/im/pictures/7e4808b4-5...    02114\n",
              "1   1             3  ...  https://a0.muscache.com/im/pictures/5392fbd6-6...    90046\n",
              "2   2             2  ...  https://a0.muscache.com/im/pictures/544d3b89-d...  11249.0\n",
              "3   3             4  ...  https://a0.muscache.com/im/pictures/26baf7ba-0...    11216\n",
              "4   4             3  ...  https://a0.muscache.com/im/pictures/86107545/9...    91604\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omVj3b8I0tRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "fd8317a4-cd6a-44a5-b318-1c8530b87563"
      },
      "source": [
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!TRAIN\")\n",
        "print(\"COLUMNS\")\n",
        "display(train.columns)\n",
        "print(\"LENGTH\")\n",
        "display(train.shape)\n",
        "\n",
        "print(\"\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!TEST\")\n",
        "print(\"COLUMNS\")\n",
        "display(test.columns)\n",
        "print(\"LENGTH\")\n",
        "display(test.shape)\n",
        "\n",
        "print(\"\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!NULL CHECK\")\n",
        "display(df.isnull().sum())\n",
        "\n",
        "print(\"\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!UNIQUE CHECK\")\n",
        "for i in df.columns:\n",
        "    # if (i in [\"id\", \"host_since\", \"last_review\", \"latitude\", \"longitude\", \"name\", \"neighbourhood\", \"thumbnail_url\", \"zipcode\", \"y\", \"description\" ,\"first_review\"]):\n",
        "    #   continue;\n",
        "    if i == \"amenities\":\n",
        "      print(\"--------------------\"+ i + \"--------------------\")\n",
        "      func = lambda x: x.replace(\"\\'\",\"\").replace(\"{\",\"\").replace(\"}\",\"\").replace('\\\"',\"\").split(\",\")\n",
        "      s = set()\n",
        "      for i in df[\"amenities\"]:\n",
        "        s = s | set(func(i))  \n",
        "      print(s)\n",
        "    else :\n",
        "      print(\"--------------------\"+ i + \"--------------------\")\n",
        "      print(df[i].unique())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-296a8e24c56c>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    if i in [\"y\", \"zipcode\"]\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pueE3qpnNzSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df[df[\"y\"] > 750]\n",
        "#2%弱が外れ値？\n",
        "\n",
        "#yの分布を見てみる\n",
        "df[\"y\"].hist()\n",
        "df[df[\"y\"] > 750][\"y\"].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL0i8Ux6O3g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# レビュースコアとyの値の関係\n",
        "# ついでにyの外れ値の具合を見る\n",
        "# これを見る感じ、ガッツリ気色悪い外れ値はなさそう\n",
        "temp = df.copy(deep=True)\n",
        "temp[\"review_scores_rating\"] = temp[\"review_scores_rating\"].map(lambda x: 0 if np.isnan(x) else round(x))\n",
        "sns.stripplot(x=\"review_scores_rating\",y=\"y\",data=temp)#正の相関"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kupJLrMfQ43z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp[\"review_scores_rating\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDzHZ9uf4CGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdp.ProfileReport(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMdudl-3_Jce",
        "colab_type": "text"
      },
      "source": [
        "# **とりあえずベースライン**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g14gAZjjPvPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "a1c1af8f-137f-467a-ad35-a8beb094414d"
      },
      "source": [
        "!pip install catboost scikit-learn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.16.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOYdnfZm5mBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# from catboost import CatBoost\n",
        "from catboost import CatBoostRegressor, FeaturesData, Pool\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afutxgENJRnV",
        "colab_type": "text"
      },
      "source": [
        "## **na全て削除、共通化できそうにない特徴量も全て削除**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKzn87Tc5ZyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# results\n",
        "# [85.9447521058982, 78.32003890836233, 82.52707618223008, 86.6723659654161, 84.45736221190403]\n",
        "def cross_validate(split_size=5):\n",
        "  results = []\n",
        "  kf = KFold(n_splits=split_size)\n",
        "  for train_idx, val_idx in kf.split(X_train, y_train):\n",
        "    train_x = X_train[train_idx]\n",
        "    train_y = y_train[train_idx]\n",
        "    val_x = X_train[val_idx]\n",
        "    val_y = y_train[val_idx]\n",
        "    rmse = run_catboost(train_x, train_y, val_x, val_y)\n",
        "    results.append(rmse)\n",
        "  return results\n",
        "\n",
        "def run_catboost(x,y,val_x,val_y):\n",
        "  # params = {\n",
        "  #       # タスク設定と損失関数\n",
        "  #       'loss_function': 'Logloss',\n",
        "  #       # 学習ラウンド数\n",
        "  #       'num_boost_round': 100,\n",
        "  #   }\n",
        "  # モデルを学習する\n",
        "  categorical_features_indices = []\n",
        "  for index, j in enumerate(X_train[0]):\n",
        "    if (type(j) == str):\n",
        "      categorical_features_indices.append(index)\n",
        "  train_pool = Pool(x, label=y, cat_features=categorical_features_indices)\n",
        "  test_pool = Pool(val_x, label=val_y, cat_features=categorical_features_indices)\n",
        "  model = CatBoostRegressor(iterations=3000, learning_rate=0.05, depth=5)\n",
        "  model.fit(train_pool)\n",
        "  # 検証用データを分類する\n",
        "  # NOTE: 確率がほしいときは prediction_type='Probability' を使う\n",
        "  pred_y = model.predict(test_pool)\n",
        "  # 精度 (Accuracy) を検証する\n",
        "  rmse = np.sqrt(mean_squared_error(val_y, pred_y))\n",
        "  print('RMSE:', rmse)\n",
        "  return rmse\n",
        "\n",
        "X_train = df.dropna().drop([\"amenities\", \"y\",\"id\",\"description\", \"host_since\", \"last_review\", \"latitude\", \"longitude\", \"name\", \"neighbourhood\", \"thumbnail_url\", \"zipcode\",\"first_review\"],axis=1).values\n",
        "y_train = df.dropna()[\"y\"].values\n",
        "base_results = cross_validate(split_size=5)\n",
        "print(\"results\")\n",
        "print(base_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-voRcQBuGJE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in X_train[0]:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYi2UiCSFAdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Y7shmKT_W7",
        "colab_type": "text"
      },
      "source": [
        "# **特徴量作成**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktPScrkaUFmH",
        "colab_type": "text"
      },
      "source": [
        "## **特徴量整形**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZtgjqqZUK8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#方向性\n",
        "\"\"\"\n",
        "まだ：\n",
        "description \n",
        "　bertかなんかで特徴量算出、\n",
        "　pcaとかで8割限度に圧縮\n",
        "name\n",
        "　一旦中身見てみて、意味有りげならbert\n",
        "neighborhood\n",
        "　中身見てみて、意味有りげならカテゴリ化\n",
        "　もしくはbert\n",
        "\n",
        "やった：\n",
        "ammenities \n",
        "　ワンホット\n",
        "bed_type \n",
        "　ワンホット\n",
        "cancellation_policy \n",
        "　意味ある数を付与\n",
        "city \n",
        "　ワンホット\n",
        "first_reviewとlast_review \n",
        "　ある程度の期間(半年とか？)で区切ってカ\n",
        "　テゴリ化してワンホットに(カテゴリのま\n",
        "　まだと意味が取れない気がする)\n",
        "host_since\n",
        "　ワンホット\n",
        "latitudeとlongitude\n",
        "　それぞれ5区切りとか適切な範囲でカテゴ\n",
        "　リ化、ワンホット化？zipcodeと相関高そ\n",
        "　う\n",
        "zipcode\n",
        "　上3桁とかで括ってみるとか？これあれば\n",
        "　上要らない気がする\n",
        "review_scores_rating\n",
        "　0.5区切りとかで集約\n",
        "room_type\n",
        "　カテゴリ化、順序付けできそう\n",
        "\n",
        "property_type\n",
        "　中身見てみて、意味有りげならカテゴリ化\n",
        "　もしくはbert\n",
        "thumbnail_url\n",
        "　バイナリとか？有る無しだけで良い気がす\n",
        "　る、もしくは何個有るかの数\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSp_TdXfMXCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dummy = df.copy(deep=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLpqA3PDUp8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#amenities ワンホット\n",
        "func = lambda x: x.replace(\"\\'\",\"\").replace(\"{\",\"\").replace(\"}\",\"\").replace('\\\"',\"\").strip().split(\",\")\n",
        "s = set()\n",
        "for i in df[\"amenities\"]:\n",
        "  s = s | set(func(i))  \n",
        "s.remove(\"\")\n",
        "s.add(\"id\")\n",
        "# print(s)\n",
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# #LabelEncoderのインスタンスを生成\n",
        "# le = LabelEncoder()\n",
        "# #ラベルを覚えさせる\n",
        "# le = le.fit(list(s))\n",
        "# #ラベルを整数に変換\n",
        "# le.transform(df['amenities'])\n",
        "\n",
        "ameni_df = pd.DataFrame(columns=list(s))\n",
        "for id,i in zip(df[\"id\"],df[\"amenities\"]):\n",
        "  print(id)\n",
        "  ret = i.replace(\"\\'\",\"\").replace(\"{\",\"\").replace(\"}\",\"\").replace('\\\"',\"\").strip().split(\",\")\n",
        "  newline = pd.DataFrame(np.zeros(len(list(s))).reshape(1,131), columns=list(s))\n",
        "  newline[\"id\"] = id\n",
        "  ameni_df = ameni_df.append(newline, ignore_index=True)\n",
        "  for _ in ret:\n",
        "    ameni_df[_] = 1\n",
        "ameni_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi8L6bnYeBia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#bed_type 　ワンホット\n",
        "df_dummy = df.copy(deep=True)\n",
        "pd.get_dummies(df_dummy, columns=['bed_type'])\n",
        "df_dummy.head()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6sSaWR1gcWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "2a7d9071-0593-4496-94c9-ad478207277e"
      },
      "source": [
        "#cancellation_policy 　意味ある数を付与\n",
        "cancellation_policy_dict = {'flexible': 5, 'strict':3, 'moderate':4, 'super_strict_30':2, 'super_strict_60':1}\n",
        "df_dummy = df_dummy.replace(cancellation_policy_dict)\n",
        "df_dummy.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>amenities</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bed_type</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>cancellation_policy</th>\n",
              "      <th>city</th>\n",
              "      <th>cleaning_fee</th>\n",
              "      <th>description</th>\n",
              "      <th>first_review</th>\n",
              "      <th>host_has_profile_pic</th>\n",
              "      <th>host_identity_verified</th>\n",
              "      <th>host_response_rate</th>\n",
              "      <th>host_since</th>\n",
              "      <th>instant_bookable</th>\n",
              "      <th>last_review</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>name</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>property_type</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>room_type</th>\n",
              "      <th>thumbnail_url</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>{TV,\"Wireless Internet\",Kitchen,\"Free parking ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "      <td>LA</td>\n",
              "      <td>t</td>\n",
              "      <td>My place is meant for family and a few friends...</td>\n",
              "      <td>2016-07-27</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-07-13</td>\n",
              "      <td>f</td>\n",
              "      <td>2016-07-27</td>\n",
              "      <td>33.788931</td>\n",
              "      <td>-118.154761</td>\n",
              "      <td>The Penthouse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>60.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90804</td>\n",
              "      <td>138.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>DC</td>\n",
              "      <td>t</td>\n",
              "      <td>This is a new listing for a lovely guest bedro...</td>\n",
              "      <td>2016-09-12</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2015-12-30</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-03-31</td>\n",
              "      <td>38.934810</td>\n",
              "      <td>-76.978190</td>\n",
              "      <td>Guest Bedroom in Brookland</td>\n",
              "      <td>Brookland</td>\n",
              "      <td>9</td>\n",
              "      <td>House</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/e4d8b51f-6...</td>\n",
              "      <td>20018</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",Kitchen,\"Indo...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NYC</td>\n",
              "      <td>t</td>\n",
              "      <td>We're looking forward to your stay at our apt....</td>\n",
              "      <td>2016-06-15</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>100%</td>\n",
              "      <td>2016-05-21</td>\n",
              "      <td>t</td>\n",
              "      <td>2017-08-13</td>\n",
              "      <td>40.695118</td>\n",
              "      <td>-73.926240</td>\n",
              "      <td>Clean Modern Room in Lux Apt 1 Block From J Train</td>\n",
              "      <td>Bushwick</td>\n",
              "      <td>27</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>83.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/5ffecc9b-d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>SF</td>\n",
              "      <td>t</td>\n",
              "      <td>BEST CITY VIEWS - - ROOF DECK W/ BBQ &amp; WiFi - ...</td>\n",
              "      <td>2014-03-15</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2012-06-19</td>\n",
              "      <td>t</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>37.796728</td>\n",
              "      <td>-122.411906</td>\n",
              "      <td>BEST views + reviews! 5/5 stars*****</td>\n",
              "      <td>Nob Hill</td>\n",
              "      <td>38</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>95.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94133</td>\n",
              "      <td>166.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",\"Air conditio...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NYC</td>\n",
              "      <td>t</td>\n",
              "      <td>Charming Apartment on the upper west side of M...</td>\n",
              "      <td>2015-08-05</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2015-03-25</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-09-10</td>\n",
              "      <td>40.785050</td>\n",
              "      <td>-73.974691</td>\n",
              "      <td>Charming 1-bedroom - UWS Manhattan</td>\n",
              "      <td>Upper West Side</td>\n",
              "      <td>5</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/92879730/5...</td>\n",
              "      <td>10024</td>\n",
              "      <td>165.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  accommodates  ... zipcode      y\n",
              "0   0             6  ...   90804  138.0\n",
              "1   1             2  ...   20018   42.0\n",
              "2   2             2  ...     NaN   65.0\n",
              "3   3             2  ...   94133  166.0\n",
              "4   4             2  ...   10024  165.0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE8qJG7qgcYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#city 　ワンホット\n",
        "pd.get_dummies(df_dummy, columns=['city'])\n",
        "df_dummy.head()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1OAGE-ogcaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first_review 日付に区切ってカテゴリ化\n",
        "df_dummy['first_review'] = pd.to_datetime(df_dummy['first_review'])\n",
        "# df_dummy['first_review'] = df_dummy['first_review'].dt.round(\"Y\")\n",
        "df_dummy['first_review'] = df_dummy['first_review'].dt.to_period('6M').dt.to_timestamp()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfGcDtLkgcek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#last_review 日付に区切ってカテゴリ化\n",
        "df_dummy['last_review'] = pd.to_datetime(df_dummy['last_review'])\n",
        "df_dummy['last_review'] = df_dummy['last_review'].dt.to_period('6M').dt.to_timestamp()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8jjrQBFgcgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#host_since 日付に区切ってカテゴリ化\n",
        "df_dummy['host_since'] = pd.to_datetime(df_dummy['host_since'])\n",
        "df_dummy['host_since'] = df_dummy['host_since'].dt.to_period('6M').dt.to_timestamp()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAuYnEySMuYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dummy = df_dummy.astype({'first_review': str, 'last_review': str, 'host_since': str})"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQRvs7cPgckg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "935a9dc4-0323-4026-b94f-221004da68b4"
      },
      "source": [
        "#latitudeとlongitude　それぞれ5区切りとか適切な範囲でカテゴリ化、ワンホット化？zipcodeと相関高そう\n",
        "print(df_dummy[\"latitude\"].max())\n",
        "print(df_dummy[\"latitude\"].min())\n",
        "df_dummy[\"latitude\"] = df_dummy[\"latitude\"].round()\n",
        "df_dummy = df_dummy.astype({'latitude': str})"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42.39043717872241\n",
            "33.33890467150096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEVus7-6gcju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "708adedb-c11f-4b9e-8561-2ccb2db1850a"
      },
      "source": [
        "#latitudeとlongitude　それぞれ5区切りとか適切な範囲でカテゴリ化、ワンホット化？zipcodeと相関高そう\n",
        "print(df_dummy[\"longitude\"].max())\n",
        "print(df_dummy[\"longitude\"].min())\n",
        "df_dummy[\"longitude\"] = df_dummy[\"longitude\"].round()\n",
        "df_dummy[\"longitude\"] = pd.cut(df_dummy[\"longitude\"], 13, labels=[i for i in range(int(abs(df_dummy[\"longitude\"].max())),\n",
        "                  int(abs(df_dummy[\"longitude\"].min())),4)])\n",
        "df_dummy = df_dummy.astype({'longitude': str})"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-70.98504659974512\n",
            "-122.51149998987214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Te5JsMgcdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "#zipcode 頭3桁でワンホット\n",
        "__1 = [\"zip1_\" + str(i) for i in range(10)]\n",
        "__1.append(\"id\")\n",
        "zip1 = pd.DataFrame(columns=__1)\n",
        "__2 = [\"zip2_\" + str(i) for i in range(10)]\n",
        "__2.append(\"id\")\n",
        "zip2 = pd.DataFrame(columns=__2)\n",
        "__3 = [\"zip3_\" + str(i) for i in range(10)]\n",
        "__3.append(\"id\")\n",
        "zip3 = pd.DataFrame(columns=__3)\n",
        "\n",
        "for id, _ in zip(df_dummy[\"id\"],df_dummy[\"zipcode\"]):\n",
        "  if type(_) == str:\n",
        "    _ = _[0:5]\n",
        "  newline1 = pd.DataFrame(np.zeros(11).reshape(1,11), columns=__1)\n",
        "  newline2 = pd.DataFrame(np.zeros(11).reshape(1,11), columns=__2)\n",
        "  newline3 = pd.DataFrame(np.zeros(11).reshape(1,11), columns=__3)\n",
        "  newline1[\"id\"] = id\n",
        "  newline2[\"id\"] = id\n",
        "  newline3[\"id\"] = id\n",
        "  try:\n",
        "    if math.isnan(float(_)) :\n",
        "      zip1 = zip1.append(newline1, ignore_index=True)\n",
        "      zip2 = zip2.append(newline2, ignore_index=True)\n",
        "      zip3 = zip3.append(newline3, ignore_index=True)\n",
        "    else :  \n",
        "      newline1[_[0]] = 1\n",
        "      newline2[_[1]] = 1\n",
        "      newline3[_[2]] = 1\n",
        "      zip1 = zip1.append(newline1, ignore_index=True)\n",
        "      zip2 = zip2.append(newline2, ignore_index=True)\n",
        "      zip3 = zip3.append(newline3, ignore_index=True)\n",
        "  except:\n",
        "    zip1 = zip1.append(newline1, ignore_index=True)\n",
        "    zip2 = zip2.append(newline2, ignore_index=True)\n",
        "    zip3 = zip3.append(newline3, ignore_index=True)\n",
        "\n",
        "zip1 = zip1.astype('str')\n",
        "zip2 = zip2.astype('str')\n",
        "zip3 = zip3.astype('str')"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suNa99YWllg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip1 = zip1.drop([\"zip1_\" + str(i) for i in range(10)], axis=1).replace({\"nan\":0, \"1.0\":\"1\"})\n",
        "zip2 = zip2.drop([\"zip2_\" + str(i) for i in range(10)], axis=1).replace({\"nan\":0, \"1.0\":\"1\"})\n",
        "zip3 = zip3.drop([\"zip3_\" + str(i) for i in range(10)], axis=1).replace({\"nan\":0, \"1.0\":\"1\"})"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bSXVrOBQ8SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# zip_ = pd.concat([zip1,zip2],axis=1)\n",
        "# zip = pd.concat([zip_,zip3],axis=1)\n",
        "# suffixes=('_zip1', '_zip2'),\n",
        "# zip1=zip1.rename(columns={str(i):\"zip1_\"+str(i) for i in range(10)})\n",
        "# zip2=zip2.rename(columns={str(i):\"zip2_\"+str(i) for i in range(10)})\n",
        "# zip3=zip3.rename(columns={str(i):\"zip3_\"+str(i) for i in range(10)})\n",
        "__ = pd.concat([zip1,zip2.drop(\"id\",axis=1)], axis=1)\n",
        "zip = pd.concat([__,zip3.drop(\"id\",axis=1)], axis=1)"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJRBPZByM2QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_dummy_backup = df_dummy.copy(deep=True)\n",
        "# pd.concat([df_dummy.reset_index(drop=True),zip.drop(\"id\",axis=1)])\n",
        "# zip\n",
        "# df_dummy.reset_index(drop=True).append(zip,axis=1)\n",
        "zip.to_pickle('./zipcode_onehot.pkl')"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkgnlC8Ls_6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#room_type　カテゴリ化、順序付けできそう\n",
        "pd.get_dummies(df_dummy, columns=['room_type'])\n",
        "df_dummy.head()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdiqnZzetysA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# review_scores_rating　0.5区切りとかで集約\n",
        "df_dummy[\"review_scores_rating\"]=df[\"review_scores_rating\"].fillna(df[\"review_scores_rating\"].mean())\n",
        "df_dummy[\"review_scores_rating\"] = pd.cut(df_dummy[\"review_scores_rating\"], 20, labels=[i*5 for i in range(20)])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sdTCk8qvDsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# property_type 欠損値を0に、それ以外を1に\n",
        "df_dummy[\"thumbnail_url\"][df_dummy[\"thumbnail_url\"].notnull()] = 1\n",
        "df_dummy[\"thumbnail_url\"] = df_dummy[\"thumbnail_url\"].fillna(0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCW6EvSWvDxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adHGsnupvD0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CknfkZYWvD2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd569c81-259b-4b5d-9402-e8d4a148ed95"
      },
      "source": [
        "df_dummy"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>amenities</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bed_type</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>cancellation_policy</th>\n",
              "      <th>city</th>\n",
              "      <th>cleaning_fee</th>\n",
              "      <th>description</th>\n",
              "      <th>first_review</th>\n",
              "      <th>host_has_profile_pic</th>\n",
              "      <th>host_identity_verified</th>\n",
              "      <th>host_response_rate</th>\n",
              "      <th>host_since</th>\n",
              "      <th>instant_bookable</th>\n",
              "      <th>last_review</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>name</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>property_type</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>room_type</th>\n",
              "      <th>thumbnail_url</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>{TV,\"Wireless Internet\",Kitchen,\"Free parking ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "      <td>LA</td>\n",
              "      <td>t</td>\n",
              "      <td>My place is meant for family and a few friends...</td>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>f</td>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>34.0</td>\n",
              "      <td>75</td>\n",
              "      <td>The Penthouse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>45</td>\n",
              "      <td>Private room</td>\n",
              "      <td>0</td>\n",
              "      <td>90804</td>\n",
              "      <td>138.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>DC</td>\n",
              "      <td>t</td>\n",
              "      <td>This is a new listing for a lovely guest bedro...</td>\n",
              "      <td>2016-09-01</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2015-12-01</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-03-01</td>\n",
              "      <td>39.0</td>\n",
              "      <td>115</td>\n",
              "      <td>Guest Bedroom in Brookland</td>\n",
              "      <td>Brookland</td>\n",
              "      <td>9</td>\n",
              "      <td>House</td>\n",
              "      <td>95</td>\n",
              "      <td>Private room</td>\n",
              "      <td>1</td>\n",
              "      <td>20018</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",Kitchen,\"Indo...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NYC</td>\n",
              "      <td>t</td>\n",
              "      <td>We're looking forward to your stay at our apt....</td>\n",
              "      <td>2016-06-01</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>100%</td>\n",
              "      <td>2016-05-01</td>\n",
              "      <td>t</td>\n",
              "      <td>2017-08-01</td>\n",
              "      <td>41.0</td>\n",
              "      <td>119</td>\n",
              "      <td>Clean Modern Room in Lux Apt 1 Block From J Train</td>\n",
              "      <td>Bushwick</td>\n",
              "      <td>27</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>75</td>\n",
              "      <td>Private room</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>SF</td>\n",
              "      <td>t</td>\n",
              "      <td>BEST CITY VIEWS - - ROOF DECK W/ BBQ &amp; WiFi - ...</td>\n",
              "      <td>2014-03-01</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2012-06-01</td>\n",
              "      <td>t</td>\n",
              "      <td>2017-09-01</td>\n",
              "      <td>38.0</td>\n",
              "      <td>71</td>\n",
              "      <td>BEST views + reviews! 5/5 stars*****</td>\n",
              "      <td>Nob Hill</td>\n",
              "      <td>38</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>90</td>\n",
              "      <td>Private room</td>\n",
              "      <td>0</td>\n",
              "      <td>94133</td>\n",
              "      <td>166.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",\"Air conditio...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NYC</td>\n",
              "      <td>t</td>\n",
              "      <td>Charming Apartment on the upper west side of M...</td>\n",
              "      <td>2015-08-01</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2015-03-01</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-09-01</td>\n",
              "      <td>41.0</td>\n",
              "      <td>119</td>\n",
              "      <td>Charming 1-bedroom - UWS Manhattan</td>\n",
              "      <td>Upper West Side</td>\n",
              "      <td>5</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>95</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>1</td>\n",
              "      <td>10024</td>\n",
              "      <td>165.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18523</th>\n",
              "      <td>18523</td>\n",
              "      <td>4</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",\"Air conditio...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NYC</td>\n",
              "      <td>t</td>\n",
              "      <td>The Greenhouse, located on Green Street, is a ...</td>\n",
              "      <td>NaT</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>100%</td>\n",
              "      <td>2009-11-01</td>\n",
              "      <td>f</td>\n",
              "      <td>NaT</td>\n",
              "      <td>41.0</td>\n",
              "      <td>119</td>\n",
              "      <td>Spacious 2BR Greenpoint Getaway</td>\n",
              "      <td>Greenpoint</td>\n",
              "      <td>0</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>90</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>1</td>\n",
              "      <td>11222</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18524</th>\n",
              "      <td>18524</td>\n",
              "      <td>2</td>\n",
              "      <td>{TV,\"Wireless Internet\",\"Air conditioning\",Kit...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>f</td>\n",
              "      <td>Two bedroom, one bathroom with large dining/li...</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>100%</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>42.0</td>\n",
              "      <td>103</td>\n",
              "      <td>Walk up Apartment in Lakeview/Wrigleyville</td>\n",
              "      <td>Lakeview</td>\n",
              "      <td>9</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>85</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>0</td>\n",
              "      <td>60657</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18525</th>\n",
              "      <td>18525</td>\n",
              "      <td>5</td>\n",
              "      <td>{TV,\"Wireless Internet\",\"Air conditioning\",Kit...</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>t</td>\n",
              "      <td>Happy Holidays! If you're looking for a big op...</td>\n",
              "      <td>NaT</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>100%</td>\n",
              "      <td>2014-09-01</td>\n",
              "      <td>f</td>\n",
              "      <td>NaT</td>\n",
              "      <td>42.0</td>\n",
              "      <td>103</td>\n",
              "      <td>Beautiful Logan Square Home</td>\n",
              "      <td>Avondale</td>\n",
              "      <td>0</td>\n",
              "      <td>House</td>\n",
              "      <td>90</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>1</td>\n",
              "      <td>60618</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18526</th>\n",
              "      <td>18526</td>\n",
              "      <td>2</td>\n",
              "      <td>{Internet,\"Wireless Internet\",\"Air conditionin...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NYC</td>\n",
              "      <td>t</td>\n",
              "      <td>This is a cozy one-bedroom apartment a few blo...</td>\n",
              "      <td>2016-04-01</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>100%</td>\n",
              "      <td>2014-03-01</td>\n",
              "      <td>f</td>\n",
              "      <td>2017-05-01</td>\n",
              "      <td>41.0</td>\n",
              "      <td>119</td>\n",
              "      <td>Charming 1 BR apartment east of Central Park</td>\n",
              "      <td>East Harlem</td>\n",
              "      <td>4</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>90</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>1</td>\n",
              "      <td>10029.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18527</th>\n",
              "      <td>18527</td>\n",
              "      <td>1</td>\n",
              "      <td>{TV,Internet,\"Wireless Internet\",Kitchen,\"Elev...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Bed</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>LA</td>\n",
              "      <td>f</td>\n",
              "      <td>Charming clean living room for rent. Amenities...</td>\n",
              "      <td>2015-08-01</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>100%</td>\n",
              "      <td>2015-08-01</td>\n",
              "      <td>t</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>34.0</td>\n",
              "      <td>75</td>\n",
              "      <td>Clean Spacious living room for rent</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>95</td>\n",
              "      <td>Shared room</td>\n",
              "      <td>1</td>\n",
              "      <td>90027</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74111 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  accommodates  ...  zipcode      y\n",
              "0          0             6  ...    90804  138.0\n",
              "1          1             2  ...    20018   42.0\n",
              "2          2             2  ...      NaN   65.0\n",
              "3          3             2  ...    94133  166.0\n",
              "4          4             2  ...    10024  165.0\n",
              "...      ...           ...  ...      ...    ...\n",
              "18523  18523             4  ...    11222    NaN\n",
              "18524  18524             2  ...    60657    NaN\n",
              "18525  18525             5  ...    60618    NaN\n",
              "18526  18526             2  ...  10029.0    NaN\n",
              "18527  18527             1  ...    90027    NaN\n",
              "\n",
              "[74111 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7X2HwjwKX3n",
        "colab_type": "text"
      },
      "source": [
        "## **とりあえず欠損値を埋めてみる**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVbXjpUtKWag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#とりあえずの方向性\n",
        "\"\"\"\n",
        "bathrooms                   200 float 平均\n",
        "bedrooms                     91 char 平均の方が良さそう\n",
        "beds                        131 float 平均\n",
        "host_response_rate        18299 char 平均\n",
        "neighbourhood              6872 char 0でもいいかも(多分ないってことだから)\n",
        "host_has_profile_pic        188 int 0.5?\n",
        "host_identity_verified      188 int 0.5?\n",
        "\n",
        "完了済：\n",
        "review_scores_rating      16722 float null多すぎて検討つかないからとりあえず平均\n",
        "thumbnail_url              8216 char 0\n",
        "zipcode                     966 全部0\n",
        "first_review              15864 char onehot全部0\n",
        "host_since                  188 char onehot全部0\n",
        "last_review               15827 char onehot全部0\n",
        "平均値打ち込んだやつは全部新たなラベル1を付け加える(変更判定ラベル)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql2uxle0s9Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dummy[\"host_response_rate\"] = df_dummy[\"host_response_rate\"].map(lambda x: int(x.replace(\"%\",\"\").strip()) if type(x)==str else x )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErzxX1Q8toU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3e5388bc-71f0-4ad2-c03e-8b766e01bd54"
      },
      "source": [
        "df_dummy[\"host_response_rate\"]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          NaN\n",
              "1        100.0\n",
              "2        100.0\n",
              "3        100.0\n",
              "4        100.0\n",
              "         ...  \n",
              "18523    100.0\n",
              "18524    100.0\n",
              "18525    100.0\n",
              "18526    100.0\n",
              "18527    100.0\n",
              "Name: host_response_rate, Length: 74111, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8tBRfnCKWdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#　平均処理\n",
        "df_dummy[\"bathrooms\"]=df_dummy[\"bathrooms\"].fillna(df[\"bathrooms\"].mean())\n",
        "df_dummy[\"bedrooms\"]=df_dummy[\"bedrooms\"].fillna(df[\"bedrooms\"].mean())\n",
        "df_dummy[\"beds\"]=df_dummy[\"beds\"].fillna(df[\"beds\"].mean())\n",
        "df_dummy[\"host_response_rate\"]=df_dummy[\"host_response_rate\"].fillna(\"0\")\n",
        "\n",
        "#0埋め\n",
        "df_dummy[\"neighbourhood\"]=df_dummy[\"neighbourhood\"].fillna(\"0\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76xtWy7ogMj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t-fを0-1に変える\n",
        "df_dummy[\"cleaning_fee\"]=df_dummy[\"cleaning_fee\"].replace({\"t\":1, \"f\":0})\n",
        "df_dummy[\"host_has_profile_pic\"]=df_dummy[\"host_has_profile_pic\"].replace({\"t\":1, \"f\":0})\n",
        "df_dummy[\"host_identity_verified\"]=df_dummy[\"host_identity_verified\"].replace({\"t\":1, \"f\":0})\n",
        "df_dummy[\"instant_bookable\"]=df_dummy[\"instant_bookable\"].replace({\"t\":1, \"f\":0})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHpdsp1-KWfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t-fのやつを0.5で埋める\n",
        "df_dummy[\"host_has_profile_pic\"]=df_dummy[\"host_has_profile_pic\"].fillna(0.5)\n",
        "df_dummy[\"host_identity_verified\"]=df_dummy[\"host_identity_verified\"].fillna(0.5)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OGYYGy6KWhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 上で変になってたやつ\n",
        "df_dummy[\"first_review\"]=df_dummy[\"first_review\"].replace({\"NaT\":\"0\"})\n",
        "df_dummy[\"last_review\"]=df_dummy[\"last_review\"].replace({\"NaT\":\"0\"})\n",
        "df_dummy[\"host_since\"]=df_dummy[\"host_since\"].replace({\"NaT\":\"0\"})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51jHmqFSuN7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dummy_train = df_dummy.copy(deep=True)\n",
        "df_dummy_train = df_dummy_train.drop([\"id\",\"amenities\",\"description\",\"name\",\"zipcode\"], axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11zyFjrWwNiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_df_dummy_train=df_dummy_train[0:55583]\n",
        "TARGET = df_dummy_train[55583:]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZngNdQQSzdw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_df_dummy_train.to_pickle('./train.pkl')\n",
        "TARGET.to_pickle('./target.pkl')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxJccBLoz9Vs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "de0fff42-b6d3-47a2-f540-6ae1ef2d0f64"
      },
      "source": [
        "X_df_dummy_train.isnull().sum()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "accommodates              0\n",
              "bathrooms                 0\n",
              "bed_type                  0\n",
              "bedrooms                  0\n",
              "beds                      0\n",
              "cancellation_policy       0\n",
              "city                      0\n",
              "cleaning_fee              0\n",
              "first_review              0\n",
              "host_has_profile_pic      0\n",
              "host_identity_verified    0\n",
              "host_response_rate        0\n",
              "host_since                0\n",
              "instant_bookable          0\n",
              "last_review               0\n",
              "latitude                  0\n",
              "longitude                 0\n",
              "neighbourhood             0\n",
              "number_of_reviews         0\n",
              "property_type             0\n",
              "review_scores_rating      0\n",
              "room_type                 0\n",
              "thumbnail_url             0\n",
              "y                         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDI390jBjdLh",
        "colab_type": "text"
      },
      "source": [
        "# **とりあえずCatBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5F9alRXjcYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "outputId": "78f63b54-69c4-4dbd-aa87-e9ad2a2d0c8b"
      },
      "source": [
        "def cross_validate(split_size=5):\n",
        "  results = []\n",
        "  kf = KFold(n_splits=split_size)\n",
        "  for train_idx, val_idx in kf.split(X_train, y_train):\n",
        "    train_x = X_train[train_idx]\n",
        "    train_y = y_train[train_idx]\n",
        "    val_x = X_train[val_idx]\n",
        "    val_y = y_train[val_idx]\n",
        "    rmse = run_catboost(train_x, train_y, val_x, val_y)\n",
        "    results.append(rmse)\n",
        "  return results\n",
        "\n",
        "def run_catboost(x,y,val_x,val_y):\n",
        "  # params = {\n",
        "  #       # タスク設定と損失関数\n",
        "  #       'loss_function': 'Logloss',\n",
        "  #       # 学習ラウンド数\n",
        "  #       'num_boost_round': 100,\n",
        "  #   }\n",
        "  # モデルを学習する\n",
        "  categorical_features_indices = []\n",
        "  for index, j in enumerate(X_train[0]):\n",
        "    if (type(j) == str):\n",
        "      categorical_features_indices.append(index)\n",
        "  train_pool = Pool(x, label=y, cat_features=categorical_features_indices)\n",
        "  test_pool = Pool(val_x, label=val_y, cat_features=categorical_features_indices)\n",
        "  model = CatBoostRegressor(iterations=3000, learning_rate=0.05, depth=5)\n",
        "  model.fit(train_pool)\n",
        "  # 検証用データを分類する\n",
        "  # NOTE: 確率がほしいときは prediction_type='Probability' を使う\n",
        "  pred_y = model.predict(test_pool)\n",
        "  # 精度 (Accuracy) を検証する\n",
        "  rmse = np.sqrt(mean_squared_error(val_y, pred_y))\n",
        "  print('RMSE:', rmse)\n",
        "  return rmse\n",
        "\n",
        "X_train = X_df_dummy_train.dropna().drop([\"y\"],axis=1).values\n",
        "y_train = X_df_dummy_train.dropna()[\"y\"].values\n",
        "def_results = cross_validate(split_size=5)\n",
        "print(\"results\")\n",
        "print(def_results)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_id_object_bytes_string_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: bad object for id: 100.0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-299c88a986d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_df_dummy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_df_dummy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdef_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdef_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-299c88a986d6>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(split_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mval_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_catboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-299c88a986d6>\u001b[0m in \u001b[0;36mrun_catboost\u001b[0;34m(x, y, val_x, val_y)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mtrain_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0mtest_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    453\u001b[0m                     )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msamples_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_baseline_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_objects_order_layout_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_data_from_generic_matrix\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: Invalid type for cat_feature[non-default value idx=0,feature_idx=11]=100.0 : cat_features must be integer or string, real number values and NaN values should be converted to string."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbExD_tjwE7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f639076-e5ef-4cfe-8dac-70b90edb668f"
      },
      "source": [
        "def run_catboost(x,y,target):\n",
        "  # params = {\n",
        "  #       # タスク設定と損失関数\n",
        "  #       'loss_function': 'Logloss',\n",
        "  #       # 学習ラウンド数\n",
        "  #       'num_boost_round': 100,\n",
        "  #   }\n",
        "  # モデルを学習する\n",
        "  categorical_features_indices = []\n",
        "  for index, j in enumerate(X_train[0]):\n",
        "    if (type(j) == str):\n",
        "      categorical_features_indices.append(index)\n",
        "  train_pool = Pool(x, label=y, cat_features=categorical_features_indices)\n",
        "  test_pool = Pool(target, cat_features=categorical_features_indices)\n",
        "  model = CatBoostRegressor(iterations=3000, learning_rate=0.05, depth=5)\n",
        "  model.fit(train_pool)\n",
        "  # 検証用データを分類する\n",
        "  # NOTE: 確率がほしいときは prediction_type='Probability' を使う\n",
        "  pred_y = model.predict(test_pool)\n",
        "  # 精度 (Accuracy) を検証する\n",
        "  # rmse = np.sqrt(mean_squared_error(val_y, pred_y))\n",
        "  # print('RMSE:', rmse)\n",
        "  return pred_y\n",
        "\n",
        "X_train = X_df_dummy_train.dropna().drop([\"y\"],axis=1).values\n",
        "y_train = X_df_dummy_train.dropna()[\"y\"].values\n",
        "target = TARGET.dropna().drop([\"y\"],axis=1).values\n",
        "predict = run_catboost(X_train, y_train, target)\n",
        "print(\"results\")\n",
        "print(predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 164.8290629\ttotal: 165ms\tremaining: 8m 13s\n",
            "1:\tlearn: 161.7235292\ttotal: 321ms\tremaining: 8m 1s\n",
            "2:\tlearn: 158.7714496\ttotal: 405ms\tremaining: 6m 44s\n",
            "3:\tlearn: 156.0853311\ttotal: 490ms\tremaining: 6m 6s\n",
            "4:\tlearn: 153.5576468\ttotal: 569ms\tremaining: 5m 40s\n",
            "5:\tlearn: 151.3304281\ttotal: 657ms\tremaining: 5m 27s\n",
            "6:\tlearn: 149.1712928\ttotal: 741ms\tremaining: 5m 17s\n",
            "7:\tlearn: 146.8877453\ttotal: 831ms\tremaining: 5m 10s\n",
            "8:\tlearn: 144.7250010\ttotal: 936ms\tremaining: 5m 11s\n",
            "9:\tlearn: 142.7561918\ttotal: 1.04s\tremaining: 5m 11s\n",
            "10:\tlearn: 140.9590806\ttotal: 1.12s\tremaining: 5m 4s\n",
            "11:\tlearn: 139.2544135\ttotal: 1.2s\tremaining: 4m 57s\n",
            "12:\tlearn: 137.6548385\ttotal: 1.26s\tremaining: 4m 50s\n",
            "13:\tlearn: 136.1336018\ttotal: 1.34s\tremaining: 4m 45s\n",
            "14:\tlearn: 134.7160495\ttotal: 1.43s\tremaining: 4m 44s\n",
            "15:\tlearn: 133.4066927\ttotal: 1.5s\tremaining: 4m 40s\n",
            "16:\tlearn: 132.2426152\ttotal: 1.58s\tremaining: 4m 37s\n",
            "17:\tlearn: 131.1608022\ttotal: 1.68s\tremaining: 4m 37s\n",
            "18:\tlearn: 130.1465299\ttotal: 1.75s\tremaining: 4m 35s\n",
            "19:\tlearn: 129.2144282\ttotal: 1.83s\tremaining: 4m 32s\n",
            "20:\tlearn: 128.3432997\ttotal: 1.91s\tremaining: 4m 30s\n",
            "21:\tlearn: 127.5405508\ttotal: 2s\tremaining: 4m 30s\n",
            "22:\tlearn: 126.7617055\ttotal: 2.07s\tremaining: 4m 28s\n",
            "23:\tlearn: 126.0903708\ttotal: 2.15s\tremaining: 4m 26s\n",
            "24:\tlearn: 125.4253071\ttotal: 2.24s\tremaining: 4m 26s\n",
            "25:\tlearn: 124.7425017\ttotal: 2.32s\tremaining: 4m 25s\n",
            "26:\tlearn: 124.1575628\ttotal: 2.4s\tremaining: 4m 23s\n",
            "27:\tlearn: 123.4953634\ttotal: 2.48s\tremaining: 4m 23s\n",
            "28:\tlearn: 122.9365056\ttotal: 2.55s\tremaining: 4m 21s\n",
            "29:\tlearn: 122.3216868\ttotal: 2.65s\tremaining: 4m 22s\n",
            "30:\tlearn: 121.8150327\ttotal: 2.72s\tremaining: 4m 20s\n",
            "31:\tlearn: 121.3399940\ttotal: 2.8s\tremaining: 4m 19s\n",
            "32:\tlearn: 120.8721650\ttotal: 2.87s\tremaining: 4m 18s\n",
            "33:\tlearn: 120.4822083\ttotal: 2.97s\tremaining: 4m 19s\n",
            "34:\tlearn: 120.1320640\ttotal: 3.04s\tremaining: 4m 17s\n",
            "35:\tlearn: 119.8038553\ttotal: 3.13s\tremaining: 4m 17s\n",
            "36:\tlearn: 119.4585111\ttotal: 3.22s\tremaining: 4m 17s\n",
            "37:\tlearn: 119.1515766\ttotal: 3.29s\tremaining: 4m 16s\n",
            "38:\tlearn: 118.7723048\ttotal: 3.37s\tremaining: 4m 16s\n",
            "39:\tlearn: 118.4757126\ttotal: 3.45s\tremaining: 4m 15s\n",
            "40:\tlearn: 118.1488100\ttotal: 3.53s\tremaining: 4m 14s\n",
            "41:\tlearn: 117.9206741\ttotal: 3.62s\tremaining: 4m 14s\n",
            "42:\tlearn: 117.6253922\ttotal: 3.69s\tremaining: 4m 14s\n",
            "43:\tlearn: 117.3955535\ttotal: 3.78s\tremaining: 4m 14s\n",
            "44:\tlearn: 117.1739247\ttotal: 3.86s\tremaining: 4m 13s\n",
            "45:\tlearn: 116.9868116\ttotal: 3.93s\tremaining: 4m 12s\n",
            "46:\tlearn: 116.6202840\ttotal: 4.02s\tremaining: 4m 12s\n",
            "47:\tlearn: 116.3297338\ttotal: 4.09s\tremaining: 4m 11s\n",
            "48:\tlearn: 116.0698812\ttotal: 4.17s\tremaining: 4m 11s\n",
            "49:\tlearn: 115.9198065\ttotal: 4.25s\tremaining: 4m 10s\n",
            "50:\tlearn: 115.7615803\ttotal: 4.33s\tremaining: 4m 10s\n",
            "51:\tlearn: 115.6116677\ttotal: 4.41s\tremaining: 4m 10s\n",
            "52:\tlearn: 115.4687807\ttotal: 4.5s\tremaining: 4m 10s\n",
            "53:\tlearn: 115.2723861\ttotal: 4.58s\tremaining: 4m 9s\n",
            "54:\tlearn: 115.1240666\ttotal: 4.67s\tremaining: 4m 10s\n",
            "55:\tlearn: 115.0135343\ttotal: 4.74s\tremaining: 4m 9s\n",
            "56:\tlearn: 114.8630778\ttotal: 4.83s\tremaining: 4m 9s\n",
            "57:\tlearn: 114.7272541\ttotal: 4.91s\tremaining: 4m 8s\n",
            "58:\tlearn: 114.6269966\ttotal: 4.97s\tremaining: 4m 7s\n",
            "59:\tlearn: 114.4108450\ttotal: 5.06s\tremaining: 4m 7s\n",
            "60:\tlearn: 114.2764303\ttotal: 5.16s\tremaining: 4m 8s\n",
            "61:\tlearn: 114.1580837\ttotal: 5.23s\tremaining: 4m 7s\n",
            "62:\tlearn: 114.0519069\ttotal: 5.32s\tremaining: 4m 8s\n",
            "63:\tlearn: 113.9376811\ttotal: 5.41s\tremaining: 4m 7s\n",
            "64:\tlearn: 113.8219120\ttotal: 5.49s\tremaining: 4m 7s\n",
            "65:\tlearn: 113.7403212\ttotal: 5.58s\tremaining: 4m 7s\n",
            "66:\tlearn: 113.6752287\ttotal: 5.65s\tremaining: 4m 7s\n",
            "67:\tlearn: 113.5179381\ttotal: 5.73s\tremaining: 4m 6s\n",
            "68:\tlearn: 113.4281622\ttotal: 5.8s\tremaining: 4m 6s\n",
            "69:\tlearn: 113.2486837\ttotal: 5.89s\tremaining: 4m 6s\n",
            "70:\tlearn: 113.1615853\ttotal: 5.98s\tremaining: 4m 6s\n",
            "71:\tlearn: 113.0750586\ttotal: 6.04s\tremaining: 4m 5s\n",
            "72:\tlearn: 113.0112922\ttotal: 6.13s\tremaining: 4m 5s\n",
            "73:\tlearn: 112.9282591\ttotal: 6.22s\tremaining: 4m 5s\n",
            "74:\tlearn: 112.8803199\ttotal: 6.32s\tremaining: 4m 6s\n",
            "75:\tlearn: 112.8209071\ttotal: 6.4s\tremaining: 4m 6s\n",
            "76:\tlearn: 112.7699552\ttotal: 6.47s\tremaining: 4m 5s\n",
            "77:\tlearn: 112.7112005\ttotal: 6.56s\tremaining: 4m 5s\n",
            "78:\tlearn: 112.6339943\ttotal: 6.66s\tremaining: 4m 6s\n",
            "79:\tlearn: 112.5816307\ttotal: 6.74s\tremaining: 4m 6s\n",
            "80:\tlearn: 112.5157187\ttotal: 6.83s\tremaining: 4m 5s\n",
            "81:\tlearn: 112.4394231\ttotal: 6.91s\tremaining: 4m 5s\n",
            "82:\tlearn: 112.3757214\ttotal: 6.99s\tremaining: 4m 5s\n",
            "83:\tlearn: 112.3185220\ttotal: 7.07s\tremaining: 4m 5s\n",
            "84:\tlearn: 112.2173275\ttotal: 7.14s\tremaining: 4m 5s\n",
            "85:\tlearn: 112.1611699\ttotal: 7.22s\tremaining: 4m 4s\n",
            "86:\tlearn: 112.0863052\ttotal: 7.29s\tremaining: 4m 4s\n",
            "87:\tlearn: 112.0449977\ttotal: 7.37s\tremaining: 4m 3s\n",
            "88:\tlearn: 111.9555696\ttotal: 7.45s\tremaining: 4m 3s\n",
            "89:\tlearn: 111.8819662\ttotal: 7.54s\tremaining: 4m 3s\n",
            "90:\tlearn: 111.7886062\ttotal: 7.64s\tremaining: 4m 4s\n",
            "91:\tlearn: 111.6750228\ttotal: 7.71s\tremaining: 4m 3s\n",
            "92:\tlearn: 111.5639241\ttotal: 7.81s\tremaining: 4m 4s\n",
            "93:\tlearn: 111.4545699\ttotal: 7.9s\tremaining: 4m 4s\n",
            "94:\tlearn: 111.2878658\ttotal: 8s\tremaining: 4m 4s\n",
            "95:\tlearn: 111.2479437\ttotal: 8.07s\tremaining: 4m 4s\n",
            "96:\tlearn: 111.2227315\ttotal: 8.17s\tremaining: 4m 4s\n",
            "97:\tlearn: 111.1834010\ttotal: 8.24s\tremaining: 4m 4s\n",
            "98:\tlearn: 111.1301243\ttotal: 8.33s\tremaining: 4m 4s\n",
            "99:\tlearn: 111.0723403\ttotal: 8.42s\tremaining: 4m 4s\n",
            "100:\tlearn: 111.0102809\ttotal: 8.51s\tremaining: 4m 4s\n",
            "101:\tlearn: 110.9472865\ttotal: 8.58s\tremaining: 4m 3s\n",
            "102:\tlearn: 110.8923923\ttotal: 8.67s\tremaining: 4m 3s\n",
            "103:\tlearn: 110.8326746\ttotal: 8.75s\tremaining: 4m 3s\n",
            "104:\tlearn: 110.7913544\ttotal: 8.84s\tremaining: 4m 3s\n",
            "105:\tlearn: 110.7074122\ttotal: 8.93s\tremaining: 4m 3s\n",
            "106:\tlearn: 110.6652434\ttotal: 9.02s\tremaining: 4m 3s\n",
            "107:\tlearn: 110.6313317\ttotal: 9.12s\tremaining: 4m 4s\n",
            "108:\tlearn: 110.4977084\ttotal: 9.21s\tremaining: 4m 4s\n",
            "109:\tlearn: 110.4561191\ttotal: 9.3s\tremaining: 4m 4s\n",
            "110:\tlearn: 110.3950087\ttotal: 9.39s\tremaining: 4m 4s\n",
            "111:\tlearn: 110.3456421\ttotal: 9.47s\tremaining: 4m 4s\n",
            "112:\tlearn: 110.2712079\ttotal: 9.55s\tremaining: 4m 3s\n",
            "113:\tlearn: 110.2176699\ttotal: 9.64s\tremaining: 4m 4s\n",
            "114:\tlearn: 110.1061840\ttotal: 9.73s\tremaining: 4m 4s\n",
            "115:\tlearn: 110.0794288\ttotal: 9.81s\tremaining: 4m 3s\n",
            "116:\tlearn: 110.0510521\ttotal: 9.9s\tremaining: 4m 3s\n",
            "117:\tlearn: 110.0262187\ttotal: 9.98s\tremaining: 4m 3s\n",
            "118:\tlearn: 109.9669483\ttotal: 10.1s\tremaining: 4m 3s\n",
            "119:\tlearn: 109.9410831\ttotal: 10.1s\tremaining: 4m 3s\n",
            "120:\tlearn: 109.8685499\ttotal: 10.2s\tremaining: 4m 3s\n",
            "121:\tlearn: 109.8589221\ttotal: 10.3s\tremaining: 4m 3s\n",
            "122:\tlearn: 109.8122354\ttotal: 10.4s\tremaining: 4m 3s\n",
            "123:\tlearn: 109.7814350\ttotal: 10.5s\tremaining: 4m 2s\n",
            "124:\tlearn: 109.6850594\ttotal: 10.6s\tremaining: 4m 2s\n",
            "125:\tlearn: 109.6525972\ttotal: 10.6s\tremaining: 4m 2s\n",
            "126:\tlearn: 109.5931254\ttotal: 10.7s\tremaining: 4m 2s\n",
            "127:\tlearn: 109.5468145\ttotal: 10.8s\tremaining: 4m 2s\n",
            "128:\tlearn: 109.5108586\ttotal: 10.9s\tremaining: 4m 2s\n",
            "129:\tlearn: 109.4905227\ttotal: 11s\tremaining: 4m 1s\n",
            "130:\tlearn: 109.4570172\ttotal: 11s\tremaining: 4m 1s\n",
            "131:\tlearn: 109.3970776\ttotal: 11.1s\tremaining: 4m 1s\n",
            "132:\tlearn: 109.3485801\ttotal: 11.2s\tremaining: 4m 1s\n",
            "133:\tlearn: 109.3317387\ttotal: 11.3s\tremaining: 4m 1s\n",
            "134:\tlearn: 109.2899942\ttotal: 11.4s\tremaining: 4m 1s\n",
            "135:\tlearn: 109.2383591\ttotal: 11.5s\tremaining: 4m 1s\n",
            "136:\tlearn: 109.2163967\ttotal: 11.5s\tremaining: 4m 1s\n",
            "137:\tlearn: 109.1878962\ttotal: 11.6s\tremaining: 4m 1s\n",
            "138:\tlearn: 109.1685998\ttotal: 11.7s\tremaining: 4m 1s\n",
            "139:\tlearn: 109.1497299\ttotal: 11.8s\tremaining: 4m 1s\n",
            "140:\tlearn: 109.1292756\ttotal: 11.9s\tremaining: 4m 1s\n",
            "141:\tlearn: 109.1078642\ttotal: 12s\tremaining: 4m 1s\n",
            "142:\tlearn: 109.0863296\ttotal: 12.1s\tremaining: 4m 1s\n",
            "143:\tlearn: 109.0143209\ttotal: 12.2s\tremaining: 4m 1s\n",
            "144:\tlearn: 108.9591431\ttotal: 12.2s\tremaining: 4m 1s\n",
            "145:\tlearn: 108.9362285\ttotal: 12.3s\tremaining: 4m\n",
            "146:\tlearn: 108.8996961\ttotal: 12.4s\tremaining: 4m 1s\n",
            "147:\tlearn: 108.8881619\ttotal: 12.5s\tremaining: 4m 1s\n",
            "148:\tlearn: 108.8545695\ttotal: 12.6s\tremaining: 4m\n",
            "149:\tlearn: 108.8006010\ttotal: 12.7s\tremaining: 4m 1s\n",
            "150:\tlearn: 108.7753128\ttotal: 12.8s\tremaining: 4m 1s\n",
            "151:\tlearn: 108.7641817\ttotal: 12.9s\tremaining: 4m 1s\n",
            "152:\tlearn: 108.7328158\ttotal: 13s\tremaining: 4m 1s\n",
            "153:\tlearn: 108.7150314\ttotal: 13.1s\tremaining: 4m 1s\n",
            "154:\tlearn: 108.6948807\ttotal: 13.2s\tremaining: 4m 1s\n",
            "155:\tlearn: 108.6723724\ttotal: 13.3s\tremaining: 4m 1s\n",
            "156:\tlearn: 108.6541951\ttotal: 13.4s\tremaining: 4m 1s\n",
            "157:\tlearn: 108.6281987\ttotal: 13.5s\tremaining: 4m 2s\n",
            "158:\tlearn: 108.5965679\ttotal: 13.6s\tremaining: 4m 2s\n",
            "159:\tlearn: 108.5798971\ttotal: 13.7s\tremaining: 4m 2s\n",
            "160:\tlearn: 108.5370417\ttotal: 13.8s\tremaining: 4m 3s\n",
            "161:\tlearn: 108.5328537\ttotal: 13.9s\tremaining: 4m 3s\n",
            "162:\tlearn: 108.4617474\ttotal: 14s\tremaining: 4m 3s\n",
            "163:\tlearn: 108.4449995\ttotal: 14.1s\tremaining: 4m 3s\n",
            "164:\tlearn: 108.4234827\ttotal: 14.1s\tremaining: 4m 3s\n",
            "165:\tlearn: 108.3778599\ttotal: 14.2s\tremaining: 4m 3s\n",
            "166:\tlearn: 108.3440392\ttotal: 14.3s\tremaining: 4m 3s\n",
            "167:\tlearn: 108.3190704\ttotal: 14.4s\tremaining: 4m 3s\n",
            "168:\tlearn: 108.3089823\ttotal: 14.5s\tremaining: 4m 3s\n",
            "169:\tlearn: 108.2892146\ttotal: 14.6s\tremaining: 4m 3s\n",
            "170:\tlearn: 108.2601286\ttotal: 14.7s\tremaining: 4m 3s\n",
            "171:\tlearn: 108.2416681\ttotal: 14.8s\tremaining: 4m 3s\n",
            "172:\tlearn: 108.2362323\ttotal: 14.9s\tremaining: 4m 3s\n",
            "173:\tlearn: 108.2203318\ttotal: 15s\tremaining: 4m 3s\n",
            "174:\tlearn: 108.2057143\ttotal: 15.1s\tremaining: 4m 3s\n",
            "175:\tlearn: 108.1942479\ttotal: 15.2s\tremaining: 4m 3s\n",
            "176:\tlearn: 108.1699529\ttotal: 15.3s\tremaining: 4m 3s\n",
            "177:\tlearn: 108.1525739\ttotal: 15.4s\tremaining: 4m 3s\n",
            "178:\tlearn: 108.1203897\ttotal: 15.4s\tremaining: 4m 3s\n",
            "179:\tlearn: 108.0909843\ttotal: 15.5s\tremaining: 4m 3s\n",
            "180:\tlearn: 108.0729379\ttotal: 15.7s\tremaining: 4m 3s\n",
            "181:\tlearn: 108.0583112\ttotal: 15.7s\tremaining: 4m 3s\n",
            "182:\tlearn: 108.0514474\ttotal: 15.8s\tremaining: 4m 3s\n",
            "183:\tlearn: 108.0415162\ttotal: 15.9s\tremaining: 4m 3s\n",
            "184:\tlearn: 108.0296684\ttotal: 16s\tremaining: 4m 3s\n",
            "185:\tlearn: 108.0106042\ttotal: 16.1s\tremaining: 4m 3s\n",
            "186:\tlearn: 107.9939838\ttotal: 16.2s\tremaining: 4m 3s\n",
            "187:\tlearn: 107.9804432\ttotal: 16.3s\tremaining: 4m 3s\n",
            "188:\tlearn: 107.9675340\ttotal: 16.3s\tremaining: 4m 3s\n",
            "189:\tlearn: 107.9516913\ttotal: 16.4s\tremaining: 4m 3s\n",
            "190:\tlearn: 107.9304145\ttotal: 16.5s\tremaining: 4m 3s\n",
            "191:\tlearn: 107.9114288\ttotal: 16.6s\tremaining: 4m 2s\n",
            "192:\tlearn: 107.8986445\ttotal: 16.7s\tremaining: 4m 3s\n",
            "193:\tlearn: 107.8666392\ttotal: 16.8s\tremaining: 4m 3s\n",
            "194:\tlearn: 107.8355673\ttotal: 16.9s\tremaining: 4m 2s\n",
            "195:\tlearn: 107.8249968\ttotal: 17s\tremaining: 4m 3s\n",
            "196:\tlearn: 107.8009967\ttotal: 17.1s\tremaining: 4m 3s\n",
            "197:\tlearn: 107.7761974\ttotal: 17.2s\tremaining: 4m 3s\n",
            "198:\tlearn: 107.7273107\ttotal: 17.3s\tremaining: 4m 3s\n",
            "199:\tlearn: 107.7127968\ttotal: 17.4s\tremaining: 4m 3s\n",
            "200:\tlearn: 107.7031734\ttotal: 17.5s\tremaining: 4m 3s\n",
            "201:\tlearn: 107.6793980\ttotal: 17.6s\tremaining: 4m 3s\n",
            "202:\tlearn: 107.6559227\ttotal: 17.7s\tremaining: 4m 3s\n",
            "203:\tlearn: 107.6465508\ttotal: 17.8s\tremaining: 4m 3s\n",
            "204:\tlearn: 107.6348035\ttotal: 17.9s\tremaining: 4m 3s\n",
            "205:\tlearn: 107.6275655\ttotal: 17.9s\tremaining: 4m 3s\n",
            "206:\tlearn: 107.6191936\ttotal: 18s\tremaining: 4m 3s\n",
            "207:\tlearn: 107.5912781\ttotal: 18.1s\tremaining: 4m 3s\n",
            "208:\tlearn: 107.5802927\ttotal: 18.2s\tremaining: 4m 3s\n",
            "209:\tlearn: 107.5522718\ttotal: 18.3s\tremaining: 4m 3s\n",
            "210:\tlearn: 107.5381809\ttotal: 18.4s\tremaining: 4m 3s\n",
            "211:\tlearn: 107.5097618\ttotal: 18.5s\tremaining: 4m 2s\n",
            "212:\tlearn: 107.4966659\ttotal: 18.6s\tremaining: 4m 2s\n",
            "213:\tlearn: 107.4911377\ttotal: 18.7s\tremaining: 4m 2s\n",
            "214:\tlearn: 107.4849851\ttotal: 18.7s\tremaining: 4m 2s\n",
            "215:\tlearn: 107.4572214\ttotal: 18.8s\tremaining: 4m 2s\n",
            "216:\tlearn: 107.4314922\ttotal: 18.9s\tremaining: 4m 2s\n",
            "217:\tlearn: 107.4223289\ttotal: 19s\tremaining: 4m 2s\n",
            "218:\tlearn: 107.4071081\ttotal: 19.1s\tremaining: 4m 2s\n",
            "219:\tlearn: 107.4026166\ttotal: 19.2s\tremaining: 4m 2s\n",
            "220:\tlearn: 107.3874026\ttotal: 19.3s\tremaining: 4m 2s\n",
            "221:\tlearn: 107.3669290\ttotal: 19.4s\tremaining: 4m 2s\n",
            "222:\tlearn: 107.3624201\ttotal: 19.4s\tremaining: 4m 2s\n",
            "223:\tlearn: 107.3520885\ttotal: 19.5s\tremaining: 4m 1s\n",
            "224:\tlearn: 107.2987254\ttotal: 19.6s\tremaining: 4m 1s\n",
            "225:\tlearn: 107.2819747\ttotal: 19.7s\tremaining: 4m 1s\n",
            "226:\tlearn: 107.2685684\ttotal: 19.8s\tremaining: 4m 1s\n",
            "227:\tlearn: 107.2478249\ttotal: 19.8s\tremaining: 4m 1s\n",
            "228:\tlearn: 107.2347183\ttotal: 19.9s\tremaining: 4m 1s\n",
            "229:\tlearn: 107.2175298\ttotal: 20s\tremaining: 4m 1s\n",
            "230:\tlearn: 107.1704743\ttotal: 20.1s\tremaining: 4m\n",
            "231:\tlearn: 107.1623247\ttotal: 20.2s\tremaining: 4m\n",
            "232:\tlearn: 107.1230802\ttotal: 20.3s\tremaining: 4m\n",
            "233:\tlearn: 107.1013421\ttotal: 20.3s\tremaining: 4m\n",
            "234:\tlearn: 107.0840525\ttotal: 20.4s\tremaining: 4m\n",
            "235:\tlearn: 107.0639207\ttotal: 20.5s\tremaining: 4m\n",
            "236:\tlearn: 107.0390866\ttotal: 20.6s\tremaining: 4m\n",
            "237:\tlearn: 107.0273690\ttotal: 20.7s\tremaining: 4m\n",
            "238:\tlearn: 107.0081013\ttotal: 20.8s\tremaining: 3m 59s\n",
            "239:\tlearn: 107.0006312\ttotal: 20.8s\tremaining: 3m 59s\n",
            "240:\tlearn: 106.9890551\ttotal: 20.9s\tremaining: 3m 59s\n",
            "241:\tlearn: 106.9787781\ttotal: 21s\tremaining: 3m 59s\n",
            "242:\tlearn: 106.9753707\ttotal: 21.1s\tremaining: 3m 59s\n",
            "243:\tlearn: 106.9637743\ttotal: 21.2s\tremaining: 3m 59s\n",
            "244:\tlearn: 106.9507936\ttotal: 21.3s\tremaining: 3m 59s\n",
            "245:\tlearn: 106.9237524\ttotal: 21.4s\tremaining: 3m 59s\n",
            "246:\tlearn: 106.8945870\ttotal: 21.5s\tremaining: 3m 59s\n",
            "247:\tlearn: 106.8824464\ttotal: 21.6s\tremaining: 3m 59s\n",
            "248:\tlearn: 106.8563049\ttotal: 21.6s\tremaining: 3m 58s\n",
            "249:\tlearn: 106.8459151\ttotal: 21.7s\tremaining: 3m 58s\n",
            "250:\tlearn: 106.8296893\ttotal: 21.8s\tremaining: 3m 58s\n",
            "251:\tlearn: 106.8110156\ttotal: 21.9s\tremaining: 3m 58s\n",
            "252:\tlearn: 106.8032075\ttotal: 22s\tremaining: 3m 58s\n",
            "253:\tlearn: 106.7944279\ttotal: 22.1s\tremaining: 3m 58s\n",
            "254:\tlearn: 106.7895112\ttotal: 22.2s\tremaining: 3m 58s\n",
            "255:\tlearn: 106.7799724\ttotal: 22.2s\tremaining: 3m 58s\n",
            "256:\tlearn: 106.7708659\ttotal: 22.3s\tremaining: 3m 57s\n",
            "257:\tlearn: 106.7618655\ttotal: 22.4s\tremaining: 3m 57s\n",
            "258:\tlearn: 106.7500730\ttotal: 22.5s\tremaining: 3m 57s\n",
            "259:\tlearn: 106.7399559\ttotal: 22.5s\tremaining: 3m 57s\n",
            "260:\tlearn: 106.7286685\ttotal: 22.6s\tremaining: 3m 57s\n",
            "261:\tlearn: 106.7054732\ttotal: 22.7s\tremaining: 3m 57s\n",
            "262:\tlearn: 106.6878057\ttotal: 22.8s\tremaining: 3m 57s\n",
            "263:\tlearn: 106.6604979\ttotal: 22.9s\tremaining: 3m 57s\n",
            "264:\tlearn: 106.6490004\ttotal: 23s\tremaining: 3m 57s\n",
            "265:\tlearn: 106.6433546\ttotal: 23.1s\tremaining: 3m 57s\n",
            "266:\tlearn: 106.6267044\ttotal: 23.2s\tremaining: 3m 56s\n",
            "267:\tlearn: 106.6163657\ttotal: 23.2s\tremaining: 3m 56s\n",
            "268:\tlearn: 106.5976463\ttotal: 23.3s\tremaining: 3m 56s\n",
            "269:\tlearn: 106.5916944\ttotal: 23.4s\tremaining: 3m 56s\n",
            "270:\tlearn: 106.5872756\ttotal: 23.5s\tremaining: 3m 56s\n",
            "271:\tlearn: 106.5659697\ttotal: 23.6s\tremaining: 3m 56s\n",
            "272:\tlearn: 106.5519908\ttotal: 23.7s\tremaining: 3m 56s\n",
            "273:\tlearn: 106.5421091\ttotal: 23.7s\tremaining: 3m 56s\n",
            "274:\tlearn: 106.5295952\ttotal: 23.8s\tremaining: 3m 56s\n",
            "275:\tlearn: 106.4856684\ttotal: 23.9s\tremaining: 3m 56s\n",
            "276:\tlearn: 106.4711918\ttotal: 24s\tremaining: 3m 55s\n",
            "277:\tlearn: 106.4634728\ttotal: 24.1s\tremaining: 3m 55s\n",
            "278:\tlearn: 106.4401528\ttotal: 24.2s\tremaining: 3m 55s\n",
            "279:\tlearn: 106.4321350\ttotal: 24.3s\tremaining: 3m 55s\n",
            "280:\tlearn: 106.4292156\ttotal: 24.3s\tremaining: 3m 55s\n",
            "281:\tlearn: 106.4240136\ttotal: 24.4s\tremaining: 3m 55s\n",
            "282:\tlearn: 106.4149864\ttotal: 24.5s\tremaining: 3m 55s\n",
            "283:\tlearn: 106.4065790\ttotal: 24.6s\tremaining: 3m 55s\n",
            "284:\tlearn: 106.4040624\ttotal: 24.7s\tremaining: 3m 55s\n",
            "285:\tlearn: 106.3903295\ttotal: 24.8s\tremaining: 3m 55s\n",
            "286:\tlearn: 106.3772131\ttotal: 24.9s\tremaining: 3m 55s\n",
            "287:\tlearn: 106.3739858\ttotal: 25s\tremaining: 3m 54s\n",
            "288:\tlearn: 106.3656703\ttotal: 25s\tremaining: 3m 54s\n",
            "289:\tlearn: 106.3568795\ttotal: 25.1s\tremaining: 3m 54s\n",
            "290:\tlearn: 106.3510800\ttotal: 25.2s\tremaining: 3m 54s\n",
            "291:\tlearn: 106.3352465\ttotal: 25.3s\tremaining: 3m 54s\n",
            "292:\tlearn: 106.2952935\ttotal: 25.4s\tremaining: 3m 54s\n",
            "293:\tlearn: 106.2743220\ttotal: 25.5s\tremaining: 3m 54s\n",
            "294:\tlearn: 106.2692467\ttotal: 25.6s\tremaining: 3m 54s\n",
            "295:\tlearn: 106.2595880\ttotal: 25.6s\tremaining: 3m 54s\n",
            "296:\tlearn: 106.2536873\ttotal: 25.7s\tremaining: 3m 54s\n",
            "297:\tlearn: 106.2384424\ttotal: 25.8s\tremaining: 3m 54s\n",
            "298:\tlearn: 106.2259430\ttotal: 25.9s\tremaining: 3m 54s\n",
            "299:\tlearn: 106.2132105\ttotal: 26s\tremaining: 3m 54s\n",
            "300:\tlearn: 106.2073908\ttotal: 26.1s\tremaining: 3m 54s\n",
            "301:\tlearn: 106.2003466\ttotal: 26.2s\tremaining: 3m 53s\n",
            "302:\tlearn: 106.1852860\ttotal: 26.3s\tremaining: 3m 53s\n",
            "303:\tlearn: 106.1753983\ttotal: 26.4s\tremaining: 3m 53s\n",
            "304:\tlearn: 106.1540001\ttotal: 26.5s\tremaining: 3m 53s\n",
            "305:\tlearn: 106.1463320\ttotal: 26.6s\tremaining: 3m 53s\n",
            "306:\tlearn: 106.1276786\ttotal: 26.6s\tremaining: 3m 53s\n",
            "307:\tlearn: 106.1187518\ttotal: 26.7s\tremaining: 3m 53s\n",
            "308:\tlearn: 106.1132843\ttotal: 26.8s\tremaining: 3m 53s\n",
            "309:\tlearn: 106.1057171\ttotal: 26.9s\tremaining: 3m 53s\n",
            "310:\tlearn: 106.0962662\ttotal: 27s\tremaining: 3m 53s\n",
            "311:\tlearn: 106.0744192\ttotal: 27s\tremaining: 3m 52s\n",
            "312:\tlearn: 106.0600675\ttotal: 27.1s\tremaining: 3m 52s\n",
            "313:\tlearn: 106.0525519\ttotal: 27.2s\tremaining: 3m 52s\n",
            "314:\tlearn: 106.0432138\ttotal: 27.3s\tremaining: 3m 52s\n",
            "315:\tlearn: 106.0357641\ttotal: 27.4s\tremaining: 3m 52s\n",
            "316:\tlearn: 106.0295720\ttotal: 27.5s\tremaining: 3m 52s\n",
            "317:\tlearn: 106.0158314\ttotal: 27.6s\tremaining: 3m 52s\n",
            "318:\tlearn: 106.0006166\ttotal: 27.6s\tremaining: 3m 52s\n",
            "319:\tlearn: 105.9754177\ttotal: 27.7s\tremaining: 3m 52s\n",
            "320:\tlearn: 105.9655776\ttotal: 27.8s\tremaining: 3m 52s\n",
            "321:\tlearn: 105.9534912\ttotal: 27.9s\tremaining: 3m 52s\n",
            "322:\tlearn: 105.9431707\ttotal: 28s\tremaining: 3m 52s\n",
            "323:\tlearn: 105.9368071\ttotal: 28.1s\tremaining: 3m 51s\n",
            "324:\tlearn: 105.9279390\ttotal: 28.2s\tremaining: 3m 51s\n",
            "325:\tlearn: 105.9211290\ttotal: 28.2s\tremaining: 3m 51s\n",
            "326:\tlearn: 105.9159381\ttotal: 28.3s\tremaining: 3m 51s\n",
            "327:\tlearn: 105.9111548\ttotal: 28.4s\tremaining: 3m 51s\n",
            "328:\tlearn: 105.9058225\ttotal: 28.5s\tremaining: 3m 51s\n",
            "329:\tlearn: 105.9001164\ttotal: 28.6s\tremaining: 3m 51s\n",
            "330:\tlearn: 105.8897240\ttotal: 28.7s\tremaining: 3m 51s\n",
            "331:\tlearn: 105.8791990\ttotal: 28.7s\tremaining: 3m 50s\n",
            "332:\tlearn: 105.8754833\ttotal: 28.8s\tremaining: 3m 50s\n",
            "333:\tlearn: 105.8662968\ttotal: 28.9s\tremaining: 3m 50s\n",
            "334:\tlearn: 105.8563558\ttotal: 29s\tremaining: 3m 50s\n",
            "335:\tlearn: 105.8341240\ttotal: 29.1s\tremaining: 3m 50s\n",
            "336:\tlearn: 105.8299548\ttotal: 29.2s\tremaining: 3m 50s\n",
            "337:\tlearn: 105.8259608\ttotal: 29.2s\tremaining: 3m 50s\n",
            "338:\tlearn: 105.8184854\ttotal: 29.3s\tremaining: 3m 49s\n",
            "339:\tlearn: 105.7849719\ttotal: 29.4s\tremaining: 3m 49s\n",
            "340:\tlearn: 105.7757473\ttotal: 29.5s\tremaining: 3m 49s\n",
            "341:\tlearn: 105.7683981\ttotal: 29.6s\tremaining: 3m 49s\n",
            "342:\tlearn: 105.7472991\ttotal: 29.6s\tremaining: 3m 49s\n",
            "343:\tlearn: 105.7404103\ttotal: 29.7s\tremaining: 3m 49s\n",
            "344:\tlearn: 105.7332702\ttotal: 29.8s\tremaining: 3m 49s\n",
            "345:\tlearn: 105.7247707\ttotal: 29.9s\tremaining: 3m 49s\n",
            "346:\tlearn: 105.7169421\ttotal: 30s\tremaining: 3m 49s\n",
            "347:\tlearn: 105.7094660\ttotal: 30s\tremaining: 3m 48s\n",
            "348:\tlearn: 105.7013988\ttotal: 30.1s\tremaining: 3m 48s\n",
            "349:\tlearn: 105.6905009\ttotal: 30.2s\tremaining: 3m 48s\n",
            "350:\tlearn: 105.6866045\ttotal: 30.2s\tremaining: 3m 48s\n",
            "351:\tlearn: 105.6751670\ttotal: 30.3s\tremaining: 3m 48s\n",
            "352:\tlearn: 105.6716116\ttotal: 30.4s\tremaining: 3m 48s\n",
            "353:\tlearn: 105.6650957\ttotal: 30.5s\tremaining: 3m 48s\n",
            "354:\tlearn: 105.6566386\ttotal: 30.6s\tremaining: 3m 48s\n",
            "355:\tlearn: 105.6507962\ttotal: 30.7s\tremaining: 3m 48s\n",
            "356:\tlearn: 105.6419973\ttotal: 30.8s\tremaining: 3m 47s\n",
            "357:\tlearn: 105.6289987\ttotal: 30.9s\tremaining: 3m 47s\n",
            "358:\tlearn: 105.6235957\ttotal: 31s\tremaining: 3m 47s\n",
            "359:\tlearn: 105.6166547\ttotal: 31s\tremaining: 3m 47s\n",
            "360:\tlearn: 105.6102349\ttotal: 31.1s\tremaining: 3m 47s\n",
            "361:\tlearn: 105.6006800\ttotal: 31.2s\tremaining: 3m 47s\n",
            "362:\tlearn: 105.5942505\ttotal: 31.3s\tremaining: 3m 47s\n",
            "363:\tlearn: 105.5771899\ttotal: 31.4s\tremaining: 3m 47s\n",
            "364:\tlearn: 105.5736144\ttotal: 31.5s\tremaining: 3m 47s\n",
            "365:\tlearn: 105.5692596\ttotal: 31.6s\tremaining: 3m 47s\n",
            "366:\tlearn: 105.5628909\ttotal: 31.7s\tremaining: 3m 47s\n",
            "367:\tlearn: 105.5477346\ttotal: 31.8s\tremaining: 3m 47s\n",
            "368:\tlearn: 105.5407939\ttotal: 31.8s\tremaining: 3m 47s\n",
            "369:\tlearn: 105.5360958\ttotal: 31.9s\tremaining: 3m 46s\n",
            "370:\tlearn: 105.5298664\ttotal: 32s\tremaining: 3m 46s\n",
            "371:\tlearn: 105.5118168\ttotal: 32.1s\tremaining: 3m 46s\n",
            "372:\tlearn: 105.5012173\ttotal: 32.2s\tremaining: 3m 46s\n",
            "373:\tlearn: 105.4976661\ttotal: 32.2s\tremaining: 3m 46s\n",
            "374:\tlearn: 105.4724239\ttotal: 32.3s\tremaining: 3m 46s\n",
            "375:\tlearn: 105.4666389\ttotal: 32.4s\tremaining: 3m 46s\n",
            "376:\tlearn: 105.4605313\ttotal: 32.5s\tremaining: 3m 46s\n",
            "377:\tlearn: 105.4485003\ttotal: 32.6s\tremaining: 3m 46s\n",
            "378:\tlearn: 105.4456186\ttotal: 32.7s\tremaining: 3m 46s\n",
            "379:\tlearn: 105.4359915\ttotal: 32.8s\tremaining: 3m 45s\n",
            "380:\tlearn: 105.4229586\ttotal: 32.9s\tremaining: 3m 45s\n",
            "381:\tlearn: 105.4144960\ttotal: 32.9s\tremaining: 3m 45s\n",
            "382:\tlearn: 105.3860571\ttotal: 33s\tremaining: 3m 45s\n",
            "383:\tlearn: 105.3740890\ttotal: 33.1s\tremaining: 3m 45s\n",
            "384:\tlearn: 105.3666496\ttotal: 33.2s\tremaining: 3m 45s\n",
            "385:\tlearn: 105.3581063\ttotal: 33.3s\tremaining: 3m 45s\n",
            "386:\tlearn: 105.3307506\ttotal: 33.4s\tremaining: 3m 45s\n",
            "387:\tlearn: 105.3226215\ttotal: 33.5s\tremaining: 3m 45s\n",
            "388:\tlearn: 105.3156671\ttotal: 33.6s\tremaining: 3m 45s\n",
            "389:\tlearn: 105.3028980\ttotal: 33.6s\tremaining: 3m 45s\n",
            "390:\tlearn: 105.2797172\ttotal: 33.7s\tremaining: 3m 45s\n",
            "391:\tlearn: 105.2761491\ttotal: 33.8s\tremaining: 3m 44s\n",
            "392:\tlearn: 105.2724283\ttotal: 33.9s\tremaining: 3m 44s\n",
            "393:\tlearn: 105.2648366\ttotal: 34s\tremaining: 3m 44s\n",
            "394:\tlearn: 105.2433624\ttotal: 34.1s\tremaining: 3m 44s\n",
            "395:\tlearn: 105.2411772\ttotal: 34.1s\tremaining: 3m 44s\n",
            "396:\tlearn: 105.2204091\ttotal: 34.2s\tremaining: 3m 44s\n",
            "397:\tlearn: 105.2003327\ttotal: 34.3s\tremaining: 3m 44s\n",
            "398:\tlearn: 105.1950549\ttotal: 34.4s\tremaining: 3m 44s\n",
            "399:\tlearn: 105.1824212\ttotal: 34.5s\tremaining: 3m 43s\n",
            "400:\tlearn: 105.1736824\ttotal: 34.5s\tremaining: 3m 43s\n",
            "401:\tlearn: 105.1707774\ttotal: 34.6s\tremaining: 3m 43s\n",
            "402:\tlearn: 105.1565983\ttotal: 34.7s\tremaining: 3m 43s\n",
            "403:\tlearn: 105.1428261\ttotal: 34.8s\tremaining: 3m 43s\n",
            "404:\tlearn: 105.1379459\ttotal: 34.9s\tremaining: 3m 43s\n",
            "405:\tlearn: 105.1351175\ttotal: 35s\tremaining: 3m 43s\n",
            "406:\tlearn: 105.1323285\ttotal: 35.1s\tremaining: 3m 43s\n",
            "407:\tlearn: 105.1178368\ttotal: 35.1s\tremaining: 3m 43s\n",
            "408:\tlearn: 105.1062896\ttotal: 35.2s\tremaining: 3m 43s\n",
            "409:\tlearn: 105.1007844\ttotal: 35.3s\tremaining: 3m 42s\n",
            "410:\tlearn: 105.0951509\ttotal: 35.4s\tremaining: 3m 42s\n",
            "411:\tlearn: 105.0915677\ttotal: 35.5s\tremaining: 3m 42s\n",
            "412:\tlearn: 105.0841314\ttotal: 35.6s\tremaining: 3m 42s\n",
            "413:\tlearn: 105.0669946\ttotal: 35.7s\tremaining: 3m 42s\n",
            "414:\tlearn: 105.0541103\ttotal: 35.8s\tremaining: 3m 42s\n",
            "415:\tlearn: 105.0521553\ttotal: 35.8s\tremaining: 3m 42s\n",
            "416:\tlearn: 105.0249204\ttotal: 35.9s\tremaining: 3m 42s\n",
            "417:\tlearn: 105.0217395\ttotal: 36s\tremaining: 3m 42s\n",
            "418:\tlearn: 105.0180972\ttotal: 36.1s\tremaining: 3m 42s\n",
            "419:\tlearn: 105.0126564\ttotal: 36.2s\tremaining: 3m 42s\n",
            "420:\tlearn: 105.0071721\ttotal: 36.3s\tremaining: 3m 42s\n",
            "421:\tlearn: 104.9959457\ttotal: 36.3s\tremaining: 3m 41s\n",
            "422:\tlearn: 104.9734112\ttotal: 36.4s\tremaining: 3m 41s\n",
            "423:\tlearn: 104.9700715\ttotal: 36.5s\tremaining: 3m 41s\n",
            "424:\tlearn: 104.9632995\ttotal: 36.6s\tremaining: 3m 41s\n",
            "425:\tlearn: 104.9571999\ttotal: 36.7s\tremaining: 3m 41s\n",
            "426:\tlearn: 104.9539585\ttotal: 36.8s\tremaining: 3m 41s\n",
            "427:\tlearn: 104.9512022\ttotal: 36.9s\tremaining: 3m 41s\n",
            "428:\tlearn: 104.9442894\ttotal: 36.9s\tremaining: 3m 41s\n",
            "429:\tlearn: 104.9415049\ttotal: 37s\tremaining: 3m 41s\n",
            "430:\tlearn: 104.9203825\ttotal: 37.1s\tremaining: 3m 41s\n",
            "431:\tlearn: 104.9010531\ttotal: 37.2s\tremaining: 3m 41s\n",
            "432:\tlearn: 104.8920046\ttotal: 37.3s\tremaining: 3m 40s\n",
            "433:\tlearn: 104.8797872\ttotal: 37.4s\tremaining: 3m 40s\n",
            "434:\tlearn: 104.8587386\ttotal: 37.5s\tremaining: 3m 40s\n",
            "435:\tlearn: 104.8530802\ttotal: 37.5s\tremaining: 3m 40s\n",
            "436:\tlearn: 104.8329063\ttotal: 37.6s\tremaining: 3m 40s\n",
            "437:\tlearn: 104.8284799\ttotal: 37.7s\tremaining: 3m 40s\n",
            "438:\tlearn: 104.8173837\ttotal: 37.8s\tremaining: 3m 40s\n",
            "439:\tlearn: 104.8034822\ttotal: 37.9s\tremaining: 3m 40s\n",
            "440:\tlearn: 104.7966078\ttotal: 38s\tremaining: 3m 40s\n",
            "441:\tlearn: 104.7952550\ttotal: 38.1s\tremaining: 3m 40s\n",
            "442:\tlearn: 104.7882043\ttotal: 38.1s\tremaining: 3m 40s\n",
            "443:\tlearn: 104.7707489\ttotal: 38.2s\tremaining: 3m 39s\n",
            "444:\tlearn: 104.7681390\ttotal: 38.3s\tremaining: 3m 39s\n",
            "445:\tlearn: 104.7568685\ttotal: 38.4s\tremaining: 3m 39s\n",
            "446:\tlearn: 104.7543877\ttotal: 38.4s\tremaining: 3m 39s\n",
            "447:\tlearn: 104.7460945\ttotal: 38.5s\tremaining: 3m 39s\n",
            "448:\tlearn: 104.7447949\ttotal: 38.6s\tremaining: 3m 39s\n",
            "449:\tlearn: 104.7414193\ttotal: 38.7s\tremaining: 3m 39s\n",
            "450:\tlearn: 104.7389700\ttotal: 38.8s\tremaining: 3m 39s\n",
            "451:\tlearn: 104.7340131\ttotal: 38.9s\tremaining: 3m 39s\n",
            "452:\tlearn: 104.7280526\ttotal: 39s\tremaining: 3m 39s\n",
            "453:\tlearn: 104.7168554\ttotal: 39s\tremaining: 3m 38s\n",
            "454:\tlearn: 104.7140520\ttotal: 39.1s\tremaining: 3m 38s\n",
            "455:\tlearn: 104.7037537\ttotal: 39.2s\tremaining: 3m 38s\n",
            "456:\tlearn: 104.6862897\ttotal: 39.3s\tremaining: 3m 38s\n",
            "457:\tlearn: 104.6774146\ttotal: 39.4s\tremaining: 3m 38s\n",
            "458:\tlearn: 104.6676024\ttotal: 39.5s\tremaining: 3m 38s\n",
            "459:\tlearn: 104.6651692\ttotal: 39.5s\tremaining: 3m 38s\n",
            "460:\tlearn: 104.6618980\ttotal: 39.6s\tremaining: 3m 38s\n",
            "461:\tlearn: 104.6583268\ttotal: 39.7s\tremaining: 3m 38s\n",
            "462:\tlearn: 104.6538052\ttotal: 39.8s\tremaining: 3m 38s\n",
            "463:\tlearn: 104.6506339\ttotal: 39.9s\tremaining: 3m 38s\n",
            "464:\tlearn: 104.6405243\ttotal: 40s\tremaining: 3m 37s\n",
            "465:\tlearn: 104.6374946\ttotal: 40s\tremaining: 3m 37s\n",
            "466:\tlearn: 104.6321569\ttotal: 40.1s\tremaining: 3m 37s\n",
            "467:\tlearn: 104.6249924\ttotal: 40.2s\tremaining: 3m 37s\n",
            "468:\tlearn: 104.6207389\ttotal: 40.3s\tremaining: 3m 37s\n",
            "469:\tlearn: 104.6039611\ttotal: 40.4s\tremaining: 3m 37s\n",
            "470:\tlearn: 104.5871308\ttotal: 40.5s\tremaining: 3m 37s\n",
            "471:\tlearn: 104.5821150\ttotal: 40.6s\tremaining: 3m 37s\n",
            "472:\tlearn: 104.5740750\ttotal: 40.6s\tremaining: 3m 37s\n",
            "473:\tlearn: 104.5729158\ttotal: 40.7s\tremaining: 3m 37s\n",
            "474:\tlearn: 104.5664777\ttotal: 40.8s\tremaining: 3m 36s\n",
            "475:\tlearn: 104.5507395\ttotal: 40.9s\tremaining: 3m 36s\n",
            "476:\tlearn: 104.5434678\ttotal: 41s\tremaining: 3m 36s\n",
            "477:\tlearn: 104.5285708\ttotal: 41.1s\tremaining: 3m 36s\n",
            "478:\tlearn: 104.5225883\ttotal: 41.2s\tremaining: 3m 36s\n",
            "479:\tlearn: 104.5175603\ttotal: 41.2s\tremaining: 3m 36s\n",
            "480:\tlearn: 104.5116416\ttotal: 41.3s\tremaining: 3m 36s\n",
            "481:\tlearn: 104.5091862\ttotal: 41.4s\tremaining: 3m 36s\n",
            "482:\tlearn: 104.5040563\ttotal: 41.5s\tremaining: 3m 36s\n",
            "483:\tlearn: 104.4961028\ttotal: 41.6s\tremaining: 3m 36s\n",
            "484:\tlearn: 104.4890616\ttotal: 41.7s\tremaining: 3m 36s\n",
            "485:\tlearn: 104.4832229\ttotal: 41.8s\tremaining: 3m 36s\n",
            "486:\tlearn: 104.4767661\ttotal: 41.8s\tremaining: 3m 35s\n",
            "487:\tlearn: 104.4737931\ttotal: 41.9s\tremaining: 3m 35s\n",
            "488:\tlearn: 104.4679889\ttotal: 42s\tremaining: 3m 35s\n",
            "489:\tlearn: 104.4671847\ttotal: 42.1s\tremaining: 3m 35s\n",
            "490:\tlearn: 104.4550695\ttotal: 42.2s\tremaining: 3m 35s\n",
            "491:\tlearn: 104.4444832\ttotal: 42.3s\tremaining: 3m 35s\n",
            "492:\tlearn: 104.4434127\ttotal: 42.4s\tremaining: 3m 35s\n",
            "493:\tlearn: 104.4383662\ttotal: 42.5s\tremaining: 3m 35s\n",
            "494:\tlearn: 104.4368974\ttotal: 42.5s\tremaining: 3m 35s\n",
            "495:\tlearn: 104.4334252\ttotal: 42.6s\tremaining: 3m 35s\n",
            "496:\tlearn: 104.4315535\ttotal: 42.7s\tremaining: 3m 35s\n",
            "497:\tlearn: 104.4296398\ttotal: 42.8s\tremaining: 3m 34s\n",
            "498:\tlearn: 104.4224641\ttotal: 42.9s\tremaining: 3m 34s\n",
            "499:\tlearn: 104.4152659\ttotal: 43s\tremaining: 3m 34s\n",
            "500:\tlearn: 104.4106574\ttotal: 43s\tremaining: 3m 34s\n",
            "501:\tlearn: 104.4102613\ttotal: 43.1s\tremaining: 3m 34s\n",
            "502:\tlearn: 104.3935637\ttotal: 43.2s\tremaining: 3m 34s\n",
            "503:\tlearn: 104.3886300\ttotal: 43.3s\tremaining: 3m 34s\n",
            "504:\tlearn: 104.3810064\ttotal: 43.3s\tremaining: 3m 34s\n",
            "505:\tlearn: 104.3647325\ttotal: 43.4s\tremaining: 3m 34s\n",
            "506:\tlearn: 104.3592079\ttotal: 43.5s\tremaining: 3m 34s\n",
            "507:\tlearn: 104.3343774\ttotal: 43.6s\tremaining: 3m 34s\n",
            "508:\tlearn: 104.3249758\ttotal: 43.7s\tremaining: 3m 34s\n",
            "509:\tlearn: 104.3116824\ttotal: 43.8s\tremaining: 3m 33s\n",
            "510:\tlearn: 104.3043902\ttotal: 43.9s\tremaining: 3m 33s\n",
            "511:\tlearn: 104.2962740\ttotal: 44s\tremaining: 3m 33s\n",
            "512:\tlearn: 104.2880835\ttotal: 44.1s\tremaining: 3m 33s\n",
            "513:\tlearn: 104.2753554\ttotal: 44.2s\tremaining: 3m 33s\n",
            "514:\tlearn: 104.2684317\ttotal: 44.3s\tremaining: 3m 33s\n",
            "515:\tlearn: 104.2600092\ttotal: 44.4s\tremaining: 3m 33s\n",
            "516:\tlearn: 104.2567505\ttotal: 44.5s\tremaining: 3m 33s\n",
            "517:\tlearn: 104.2431428\ttotal: 44.5s\tremaining: 3m 33s\n",
            "518:\tlearn: 104.2374044\ttotal: 44.6s\tremaining: 3m 33s\n",
            "519:\tlearn: 104.2370592\ttotal: 44.7s\tremaining: 3m 33s\n",
            "520:\tlearn: 104.2307521\ttotal: 44.8s\tremaining: 3m 32s\n",
            "521:\tlearn: 104.2243224\ttotal: 44.8s\tremaining: 3m 32s\n",
            "522:\tlearn: 104.2195466\ttotal: 44.9s\tremaining: 3m 32s\n",
            "523:\tlearn: 104.2116540\ttotal: 45s\tremaining: 3m 32s\n",
            "524:\tlearn: 104.2085691\ttotal: 45.1s\tremaining: 3m 32s\n",
            "525:\tlearn: 104.2028585\ttotal: 45.2s\tremaining: 3m 32s\n",
            "526:\tlearn: 104.1911288\ttotal: 45.3s\tremaining: 3m 32s\n",
            "527:\tlearn: 104.1813753\ttotal: 45.4s\tremaining: 3m 32s\n",
            "528:\tlearn: 104.1759842\ttotal: 45.4s\tremaining: 3m 32s\n",
            "529:\tlearn: 104.1714642\ttotal: 45.5s\tremaining: 3m 32s\n",
            "530:\tlearn: 104.1670506\ttotal: 45.6s\tremaining: 3m 32s\n",
            "531:\tlearn: 104.1521621\ttotal: 45.7s\tremaining: 3m 32s\n",
            "532:\tlearn: 104.1462869\ttotal: 45.8s\tremaining: 3m 32s\n",
            "533:\tlearn: 104.1411895\ttotal: 45.9s\tremaining: 3m 32s\n",
            "534:\tlearn: 104.1295330\ttotal: 46s\tremaining: 3m 31s\n",
            "535:\tlearn: 104.1213896\ttotal: 46.1s\tremaining: 3m 31s\n",
            "536:\tlearn: 104.1135413\ttotal: 46.2s\tremaining: 3m 31s\n",
            "537:\tlearn: 104.1041864\ttotal: 46.3s\tremaining: 3m 31s\n",
            "538:\tlearn: 104.0995284\ttotal: 46.3s\tremaining: 3m 31s\n",
            "539:\tlearn: 104.0960299\ttotal: 46.4s\tremaining: 3m 31s\n",
            "540:\tlearn: 104.0848614\ttotal: 46.5s\tremaining: 3m 31s\n",
            "541:\tlearn: 104.0780611\ttotal: 46.6s\tremaining: 3m 31s\n",
            "542:\tlearn: 104.0678954\ttotal: 46.7s\tremaining: 3m 31s\n",
            "543:\tlearn: 104.0609682\ttotal: 46.8s\tremaining: 3m 31s\n",
            "544:\tlearn: 104.0595416\ttotal: 46.9s\tremaining: 3m 31s\n",
            "545:\tlearn: 104.0557791\ttotal: 47s\tremaining: 3m 31s\n",
            "546:\tlearn: 104.0529176\ttotal: 47.1s\tremaining: 3m 31s\n",
            "547:\tlearn: 104.0367284\ttotal: 47.1s\tremaining: 3m 30s\n",
            "548:\tlearn: 104.0261233\ttotal: 47.2s\tremaining: 3m 30s\n",
            "549:\tlearn: 104.0238478\ttotal: 47.3s\tremaining: 3m 30s\n",
            "550:\tlearn: 104.0170948\ttotal: 47.4s\tremaining: 3m 30s\n",
            "551:\tlearn: 104.0149914\ttotal: 47.5s\tremaining: 3m 30s\n",
            "552:\tlearn: 104.0133163\ttotal: 47.6s\tremaining: 3m 30s\n",
            "553:\tlearn: 104.0124273\ttotal: 47.6s\tremaining: 3m 30s\n",
            "554:\tlearn: 104.0101095\ttotal: 47.7s\tremaining: 3m 30s\n",
            "555:\tlearn: 103.9934624\ttotal: 47.8s\tremaining: 3m 30s\n",
            "556:\tlearn: 103.9871464\ttotal: 47.9s\tremaining: 3m 30s\n",
            "557:\tlearn: 103.9691955\ttotal: 48s\tremaining: 3m 30s\n",
            "558:\tlearn: 103.9670370\ttotal: 48.1s\tremaining: 3m 29s\n",
            "559:\tlearn: 103.9603689\ttotal: 48.2s\tremaining: 3m 29s\n",
            "560:\tlearn: 103.9585237\ttotal: 48.3s\tremaining: 3m 29s\n",
            "561:\tlearn: 103.9564249\ttotal: 48.3s\tremaining: 3m 29s\n",
            "562:\tlearn: 103.9458194\ttotal: 48.4s\tremaining: 3m 29s\n",
            "563:\tlearn: 103.9355841\ttotal: 48.5s\tremaining: 3m 29s\n",
            "564:\tlearn: 103.9286353\ttotal: 48.6s\tremaining: 3m 29s\n",
            "565:\tlearn: 103.9260122\ttotal: 48.7s\tremaining: 3m 29s\n",
            "566:\tlearn: 103.9221286\ttotal: 48.8s\tremaining: 3m 29s\n",
            "567:\tlearn: 103.9160430\ttotal: 48.9s\tremaining: 3m 29s\n",
            "568:\tlearn: 103.9035071\ttotal: 49s\tremaining: 3m 29s\n",
            "569:\tlearn: 103.9004290\ttotal: 49s\tremaining: 3m 29s\n",
            "570:\tlearn: 103.8949073\ttotal: 49.1s\tremaining: 3m 28s\n",
            "571:\tlearn: 103.8898897\ttotal: 49.2s\tremaining: 3m 28s\n",
            "572:\tlearn: 103.8817996\ttotal: 49.3s\tremaining: 3m 28s\n",
            "573:\tlearn: 103.8731887\ttotal: 49.4s\tremaining: 3m 28s\n",
            "574:\tlearn: 103.8556902\ttotal: 49.4s\tremaining: 3m 28s\n",
            "575:\tlearn: 103.8509215\ttotal: 49.5s\tremaining: 3m 28s\n",
            "576:\tlearn: 103.8499007\ttotal: 49.6s\tremaining: 3m 28s\n",
            "577:\tlearn: 103.8466645\ttotal: 49.7s\tremaining: 3m 28s\n",
            "578:\tlearn: 103.8451871\ttotal: 49.8s\tremaining: 3m 28s\n",
            "579:\tlearn: 103.8426195\ttotal: 49.9s\tremaining: 3m 28s\n",
            "580:\tlearn: 103.8295312\ttotal: 50s\tremaining: 3m 28s\n",
            "581:\tlearn: 103.8228428\ttotal: 50.1s\tremaining: 3m 27s\n",
            "582:\tlearn: 103.8099213\ttotal: 50.1s\tremaining: 3m 27s\n",
            "583:\tlearn: 103.8020472\ttotal: 50.2s\tremaining: 3m 27s\n",
            "584:\tlearn: 103.7891145\ttotal: 50.3s\tremaining: 3m 27s\n",
            "585:\tlearn: 103.7855348\ttotal: 50.4s\tremaining: 3m 27s\n",
            "586:\tlearn: 103.7795791\ttotal: 50.5s\tremaining: 3m 27s\n",
            "587:\tlearn: 103.7748661\ttotal: 50.5s\tremaining: 3m 27s\n",
            "588:\tlearn: 103.7689661\ttotal: 50.6s\tremaining: 3m 27s\n",
            "589:\tlearn: 103.7646862\ttotal: 50.7s\tremaining: 3m 27s\n",
            "590:\tlearn: 103.7636387\ttotal: 50.8s\tremaining: 3m 27s\n",
            "591:\tlearn: 103.7577136\ttotal: 50.9s\tremaining: 3m 26s\n",
            "592:\tlearn: 103.7445265\ttotal: 51s\tremaining: 3m 26s\n",
            "593:\tlearn: 103.7403850\ttotal: 51.1s\tremaining: 3m 26s\n",
            "594:\tlearn: 103.7292186\ttotal: 51.2s\tremaining: 3m 26s\n",
            "595:\tlearn: 103.7250634\ttotal: 51.2s\tremaining: 3m 26s\n",
            "596:\tlearn: 103.7162250\ttotal: 51.3s\tremaining: 3m 26s\n",
            "597:\tlearn: 103.7130127\ttotal: 51.4s\tremaining: 3m 26s\n",
            "598:\tlearn: 103.7095026\ttotal: 51.5s\tremaining: 3m 26s\n",
            "599:\tlearn: 103.6982287\ttotal: 51.6s\tremaining: 3m 26s\n",
            "600:\tlearn: 103.6954163\ttotal: 51.7s\tremaining: 3m 26s\n",
            "601:\tlearn: 103.6870029\ttotal: 51.8s\tremaining: 3m 26s\n",
            "602:\tlearn: 103.6848988\ttotal: 51.9s\tremaining: 3m 26s\n",
            "603:\tlearn: 103.6833697\ttotal: 51.9s\tremaining: 3m 26s\n",
            "604:\tlearn: 103.6780324\ttotal: 52s\tremaining: 3m 25s\n",
            "605:\tlearn: 103.6767614\ttotal: 52.1s\tremaining: 3m 25s\n",
            "606:\tlearn: 103.6717547\ttotal: 52.2s\tremaining: 3m 25s\n",
            "607:\tlearn: 103.6562403\ttotal: 52.3s\tremaining: 3m 25s\n",
            "608:\tlearn: 103.6515525\ttotal: 52.4s\tremaining: 3m 25s\n",
            "609:\tlearn: 103.6487069\ttotal: 52.4s\tremaining: 3m 25s\n",
            "610:\tlearn: 103.6442042\ttotal: 52.5s\tremaining: 3m 25s\n",
            "611:\tlearn: 103.6405242\ttotal: 52.6s\tremaining: 3m 25s\n",
            "612:\tlearn: 103.6388749\ttotal: 52.7s\tremaining: 3m 25s\n",
            "613:\tlearn: 103.6375870\ttotal: 52.8s\tremaining: 3m 25s\n",
            "614:\tlearn: 103.6235220\ttotal: 52.9s\tremaining: 3m 25s\n",
            "615:\tlearn: 103.6209309\ttotal: 53s\tremaining: 3m 24s\n",
            "616:\tlearn: 103.6190142\ttotal: 53.1s\tremaining: 3m 24s\n",
            "617:\tlearn: 103.6152412\ttotal: 53.1s\tremaining: 3m 24s\n",
            "618:\tlearn: 103.6074167\ttotal: 53.2s\tremaining: 3m 24s\n",
            "619:\tlearn: 103.6063522\ttotal: 53.3s\tremaining: 3m 24s\n",
            "620:\tlearn: 103.5914633\ttotal: 53.4s\tremaining: 3m 24s\n",
            "621:\tlearn: 103.5811693\ttotal: 53.5s\tremaining: 3m 24s\n",
            "622:\tlearn: 103.5774478\ttotal: 53.5s\tremaining: 3m 24s\n",
            "623:\tlearn: 103.5743786\ttotal: 53.6s\tremaining: 3m 24s\n",
            "624:\tlearn: 103.5578962\ttotal: 53.7s\tremaining: 3m 24s\n",
            "625:\tlearn: 103.5554768\ttotal: 53.8s\tremaining: 3m 24s\n",
            "626:\tlearn: 103.5336038\ttotal: 53.9s\tremaining: 3m 23s\n",
            "627:\tlearn: 103.5310361\ttotal: 54s\tremaining: 3m 23s\n",
            "628:\tlearn: 103.5187013\ttotal: 54.1s\tremaining: 3m 23s\n",
            "629:\tlearn: 103.5037552\ttotal: 54.2s\tremaining: 3m 23s\n",
            "630:\tlearn: 103.5012129\ttotal: 54.2s\tremaining: 3m 23s\n",
            "631:\tlearn: 103.5010216\ttotal: 54.3s\tremaining: 3m 23s\n",
            "632:\tlearn: 103.4996175\ttotal: 54.4s\tremaining: 3m 23s\n",
            "633:\tlearn: 103.4954178\ttotal: 54.5s\tremaining: 3m 23s\n",
            "634:\tlearn: 103.4900817\ttotal: 54.6s\tremaining: 3m 23s\n",
            "635:\tlearn: 103.4896350\ttotal: 54.6s\tremaining: 3m 23s\n",
            "636:\tlearn: 103.4816447\ttotal: 54.7s\tremaining: 3m 23s\n",
            "637:\tlearn: 103.4783931\ttotal: 54.8s\tremaining: 3m 22s\n",
            "638:\tlearn: 103.4759573\ttotal: 54.9s\tremaining: 3m 22s\n",
            "639:\tlearn: 103.4689490\ttotal: 55s\tremaining: 3m 22s\n",
            "640:\tlearn: 103.4678355\ttotal: 55.1s\tremaining: 3m 22s\n",
            "641:\tlearn: 103.4624846\ttotal: 55.2s\tremaining: 3m 22s\n",
            "642:\tlearn: 103.4586276\ttotal: 55.3s\tremaining: 3m 22s\n",
            "643:\tlearn: 103.4528546\ttotal: 55.3s\tremaining: 3m 22s\n",
            "644:\tlearn: 103.4515679\ttotal: 55.4s\tremaining: 3m 22s\n",
            "645:\tlearn: 103.4510724\ttotal: 55.5s\tremaining: 3m 22s\n",
            "646:\tlearn: 103.4411237\ttotal: 55.6s\tremaining: 3m 22s\n",
            "647:\tlearn: 103.4398492\ttotal: 55.6s\tremaining: 3m 21s\n",
            "648:\tlearn: 103.4382726\ttotal: 55.7s\tremaining: 3m 21s\n",
            "649:\tlearn: 103.4336057\ttotal: 55.8s\tremaining: 3m 21s\n",
            "650:\tlearn: 103.4286989\ttotal: 55.9s\tremaining: 3m 21s\n",
            "651:\tlearn: 103.4277664\ttotal: 55.9s\tremaining: 3m 21s\n",
            "652:\tlearn: 103.4269453\ttotal: 56s\tremaining: 3m 21s\n",
            "653:\tlearn: 103.4218936\ttotal: 56.1s\tremaining: 3m 21s\n",
            "654:\tlearn: 103.4149992\ttotal: 56.2s\tremaining: 3m 21s\n",
            "655:\tlearn: 103.4140261\ttotal: 56.3s\tremaining: 3m 21s\n",
            "656:\tlearn: 103.4132609\ttotal: 56.4s\tremaining: 3m 21s\n",
            "657:\tlearn: 103.3997291\ttotal: 56.4s\tremaining: 3m 20s\n",
            "658:\tlearn: 103.3976348\ttotal: 56.5s\tremaining: 3m 20s\n",
            "659:\tlearn: 103.3899712\ttotal: 56.6s\tremaining: 3m 20s\n",
            "660:\tlearn: 103.3788326\ttotal: 56.7s\tremaining: 3m 20s\n",
            "661:\tlearn: 103.3785149\ttotal: 56.8s\tremaining: 3m 20s\n",
            "662:\tlearn: 103.3657885\ttotal: 56.9s\tremaining: 3m 20s\n",
            "663:\tlearn: 103.3617142\ttotal: 57s\tremaining: 3m 20s\n",
            "664:\tlearn: 103.3527006\ttotal: 57.1s\tremaining: 3m 20s\n",
            "665:\tlearn: 103.3494501\ttotal: 57.1s\tremaining: 3m 20s\n",
            "666:\tlearn: 103.3426331\ttotal: 57.2s\tremaining: 3m 20s\n",
            "667:\tlearn: 103.3389914\ttotal: 57.3s\tremaining: 3m 20s\n",
            "668:\tlearn: 103.3310103\ttotal: 57.4s\tremaining: 3m 19s\n",
            "669:\tlearn: 103.3280693\ttotal: 57.5s\tremaining: 3m 19s\n",
            "670:\tlearn: 103.3192396\ttotal: 57.6s\tremaining: 3m 19s\n",
            "671:\tlearn: 103.3145561\ttotal: 57.7s\tremaining: 3m 19s\n",
            "672:\tlearn: 103.3049890\ttotal: 57.7s\tremaining: 3m 19s\n",
            "673:\tlearn: 103.3006283\ttotal: 57.8s\tremaining: 3m 19s\n",
            "674:\tlearn: 103.2980754\ttotal: 57.9s\tremaining: 3m 19s\n",
            "675:\tlearn: 103.2950521\ttotal: 58s\tremaining: 3m 19s\n",
            "676:\tlearn: 103.2911892\ttotal: 58.1s\tremaining: 3m 19s\n",
            "677:\tlearn: 103.2824771\ttotal: 58.1s\tremaining: 3m 19s\n",
            "678:\tlearn: 103.2678561\ttotal: 58.2s\tremaining: 3m 19s\n",
            "679:\tlearn: 103.2506410\ttotal: 58.3s\tremaining: 3m 18s\n",
            "680:\tlearn: 103.2431350\ttotal: 58.4s\tremaining: 3m 18s\n",
            "681:\tlearn: 103.2425145\ttotal: 58.5s\tremaining: 3m 18s\n",
            "682:\tlearn: 103.2394246\ttotal: 58.6s\tremaining: 3m 18s\n",
            "683:\tlearn: 103.2300371\ttotal: 58.7s\tremaining: 3m 18s\n",
            "684:\tlearn: 103.2168480\ttotal: 58.7s\tremaining: 3m 18s\n",
            "685:\tlearn: 103.2113407\ttotal: 58.8s\tremaining: 3m 18s\n",
            "686:\tlearn: 103.2080178\ttotal: 58.9s\tremaining: 3m 18s\n",
            "687:\tlearn: 103.2072433\ttotal: 59s\tremaining: 3m 18s\n",
            "688:\tlearn: 103.2049932\ttotal: 59.1s\tremaining: 3m 18s\n",
            "689:\tlearn: 103.2030217\ttotal: 59.2s\tremaining: 3m 18s\n",
            "690:\tlearn: 103.1923735\ttotal: 59.3s\tremaining: 3m 18s\n",
            "691:\tlearn: 103.1875438\ttotal: 59.4s\tremaining: 3m 17s\n",
            "692:\tlearn: 103.1834801\ttotal: 59.5s\tremaining: 3m 17s\n",
            "693:\tlearn: 103.1741184\ttotal: 59.5s\tremaining: 3m 17s\n",
            "694:\tlearn: 103.1714682\ttotal: 59.6s\tremaining: 3m 17s\n",
            "695:\tlearn: 103.1677493\ttotal: 59.7s\tremaining: 3m 17s\n",
            "696:\tlearn: 103.1590016\ttotal: 59.8s\tremaining: 3m 17s\n",
            "697:\tlearn: 103.1546700\ttotal: 59.9s\tremaining: 3m 17s\n",
            "698:\tlearn: 103.1489219\ttotal: 60s\tremaining: 3m 17s\n",
            "699:\tlearn: 103.1463517\ttotal: 1m\tremaining: 3m 17s\n",
            "700:\tlearn: 103.1427437\ttotal: 1m\tremaining: 3m 17s\n",
            "701:\tlearn: 103.1351543\ttotal: 1m\tremaining: 3m 17s\n",
            "702:\tlearn: 103.1305093\ttotal: 1m\tremaining: 3m 17s\n",
            "703:\tlearn: 103.1210464\ttotal: 1m\tremaining: 3m 17s\n",
            "704:\tlearn: 103.1175689\ttotal: 1m\tremaining: 3m 16s\n",
            "705:\tlearn: 103.1020963\ttotal: 1m\tremaining: 3m 16s\n",
            "706:\tlearn: 103.0962324\ttotal: 1m\tremaining: 3m 16s\n",
            "707:\tlearn: 103.0882755\ttotal: 1m\tremaining: 3m 16s\n",
            "708:\tlearn: 103.0790179\ttotal: 1m\tremaining: 3m 16s\n",
            "709:\tlearn: 103.0718978\ttotal: 1m\tremaining: 3m 16s\n",
            "710:\tlearn: 103.0696819\ttotal: 1m 1s\tremaining: 3m 16s\n",
            "711:\tlearn: 103.0487198\ttotal: 1m 1s\tremaining: 3m 16s\n",
            "712:\tlearn: 103.0417593\ttotal: 1m 1s\tremaining: 3m 16s\n",
            "713:\tlearn: 103.0386636\ttotal: 1m 1s\tremaining: 3m 16s\n",
            "714:\tlearn: 103.0381339\ttotal: 1m 1s\tremaining: 3m 16s\n",
            "715:\tlearn: 103.0358026\ttotal: 1m 1s\tremaining: 3m 16s\n",
            "716:\tlearn: 103.0088815\ttotal: 1m 1s\tremaining: 3m 15s\n",
            "717:\tlearn: 103.0055851\ttotal: 1m 1s\tremaining: 3m 15s\n",
            "718:\tlearn: 102.9939751\ttotal: 1m 1s\tremaining: 3m 15s\n",
            "719:\tlearn: 102.9920115\ttotal: 1m 1s\tremaining: 3m 15s\n",
            "720:\tlearn: 102.9846615\ttotal: 1m 1s\tremaining: 3m 15s\n",
            "721:\tlearn: 102.9834745\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "722:\tlearn: 102.9672067\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "723:\tlearn: 102.9655309\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "724:\tlearn: 102.9615113\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "725:\tlearn: 102.9589601\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "726:\tlearn: 102.9572198\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "727:\tlearn: 102.9507016\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "728:\tlearn: 102.9424156\ttotal: 1m 2s\tremaining: 3m 15s\n",
            "729:\tlearn: 102.9176567\ttotal: 1m 2s\tremaining: 3m 14s\n",
            "730:\tlearn: 102.9152011\ttotal: 1m 2s\tremaining: 3m 14s\n",
            "731:\tlearn: 102.8996896\ttotal: 1m 2s\tremaining: 3m 14s\n",
            "732:\tlearn: 102.8874983\ttotal: 1m 2s\tremaining: 3m 14s\n",
            "733:\tlearn: 102.8633707\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "734:\tlearn: 102.8519295\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "735:\tlearn: 102.8475974\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "736:\tlearn: 102.8345955\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "737:\tlearn: 102.8339263\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "738:\tlearn: 102.8116990\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "739:\tlearn: 102.8060744\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "740:\tlearn: 102.8001432\ttotal: 1m 3s\tremaining: 3m 14s\n",
            "741:\tlearn: 102.7962549\ttotal: 1m 3s\tremaining: 3m 13s\n",
            "742:\tlearn: 102.7899681\ttotal: 1m 3s\tremaining: 3m 13s\n",
            "743:\tlearn: 102.7814213\ttotal: 1m 3s\tremaining: 3m 13s\n",
            "744:\tlearn: 102.7687284\ttotal: 1m 3s\tremaining: 3m 13s\n",
            "745:\tlearn: 102.7654490\ttotal: 1m 4s\tremaining: 3m 13s\n",
            "746:\tlearn: 102.7536303\ttotal: 1m 4s\tremaining: 3m 13s\n",
            "747:\tlearn: 102.7457579\ttotal: 1m 4s\tremaining: 3m 13s\n",
            "748:\tlearn: 102.7413925\ttotal: 1m 4s\tremaining: 3m 13s\n",
            "749:\tlearn: 102.7394942\ttotal: 1m 4s\tremaining: 3m 13s\n",
            "750:\tlearn: 102.7326530\ttotal: 1m 4s\tremaining: 3m 13s\n",
            "751:\tlearn: 102.7306938\ttotal: 1m 4s\tremaining: 3m 12s\n",
            "752:\tlearn: 102.7202010\ttotal: 1m 4s\tremaining: 3m 12s\n",
            "753:\tlearn: 102.7190815\ttotal: 1m 4s\tremaining: 3m 12s\n",
            "754:\tlearn: 102.7166487\ttotal: 1m 4s\tremaining: 3m 12s\n",
            "755:\tlearn: 102.7135207\ttotal: 1m 4s\tremaining: 3m 12s\n",
            "756:\tlearn: 102.7037921\ttotal: 1m 4s\tremaining: 3m 12s\n",
            "757:\tlearn: 102.7007033\ttotal: 1m 5s\tremaining: 3m 12s\n",
            "758:\tlearn: 102.6871665\ttotal: 1m 5s\tremaining: 3m 12s\n",
            "759:\tlearn: 102.6770656\ttotal: 1m 5s\tremaining: 3m 12s\n",
            "760:\tlearn: 102.6745912\ttotal: 1m 5s\tremaining: 3m 12s\n",
            "761:\tlearn: 102.6714103\ttotal: 1m 5s\tremaining: 3m 12s\n",
            "762:\tlearn: 102.6676191\ttotal: 1m 5s\tremaining: 3m 11s\n",
            "763:\tlearn: 102.6643294\ttotal: 1m 5s\tremaining: 3m 11s\n",
            "764:\tlearn: 102.6552717\ttotal: 1m 5s\tremaining: 3m 11s\n",
            "765:\tlearn: 102.6528883\ttotal: 1m 5s\tremaining: 3m 11s\n",
            "766:\tlearn: 102.6516857\ttotal: 1m 5s\tremaining: 3m 11s\n",
            "767:\tlearn: 102.6508236\ttotal: 1m 5s\tremaining: 3m 11s\n",
            "768:\tlearn: 102.6469346\ttotal: 1m 5s\tremaining: 3m 11s\n",
            "769:\tlearn: 102.6408404\ttotal: 1m 6s\tremaining: 3m 11s\n",
            "770:\tlearn: 102.6403071\ttotal: 1m 6s\tremaining: 3m 11s\n",
            "771:\tlearn: 102.6349513\ttotal: 1m 6s\tremaining: 3m 11s\n",
            "772:\tlearn: 102.6335103\ttotal: 1m 6s\tremaining: 3m 11s\n",
            "773:\tlearn: 102.6261781\ttotal: 1m 6s\tremaining: 3m 11s\n",
            "774:\tlearn: 102.6098825\ttotal: 1m 6s\tremaining: 3m 10s\n",
            "775:\tlearn: 102.6012772\ttotal: 1m 6s\tremaining: 3m 10s\n",
            "776:\tlearn: 102.5972223\ttotal: 1m 6s\tremaining: 3m 10s\n",
            "777:\tlearn: 102.5937600\ttotal: 1m 6s\tremaining: 3m 10s\n",
            "778:\tlearn: 102.5877068\ttotal: 1m 6s\tremaining: 3m 10s\n",
            "779:\tlearn: 102.5834145\ttotal: 1m 6s\tremaining: 3m 10s\n",
            "780:\tlearn: 102.5822229\ttotal: 1m 7s\tremaining: 3m 10s\n",
            "781:\tlearn: 102.5723350\ttotal: 1m 7s\tremaining: 3m 10s\n",
            "782:\tlearn: 102.5647230\ttotal: 1m 7s\tremaining: 3m 10s\n",
            "783:\tlearn: 102.5586879\ttotal: 1m 7s\tremaining: 3m 10s\n",
            "784:\tlearn: 102.5515984\ttotal: 1m 7s\tremaining: 3m 10s\n",
            "785:\tlearn: 102.5372424\ttotal: 1m 7s\tremaining: 3m 10s\n",
            "786:\tlearn: 102.5364041\ttotal: 1m 7s\tremaining: 3m 9s\n",
            "787:\tlearn: 102.5276482\ttotal: 1m 7s\tremaining: 3m 9s\n",
            "788:\tlearn: 102.5205966\ttotal: 1m 7s\tremaining: 3m 9s\n",
            "789:\tlearn: 102.5197608\ttotal: 1m 7s\tremaining: 3m 9s\n",
            "790:\tlearn: 102.5170279\ttotal: 1m 7s\tremaining: 3m 9s\n",
            "791:\tlearn: 102.5118952\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "792:\tlearn: 102.4963204\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "793:\tlearn: 102.4948435\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "794:\tlearn: 102.4860620\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "795:\tlearn: 102.4846980\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "796:\tlearn: 102.4767397\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "797:\tlearn: 102.4744082\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "798:\tlearn: 102.4738396\ttotal: 1m 8s\tremaining: 3m 8s\n",
            "799:\tlearn: 102.4635707\ttotal: 1m 8s\tremaining: 3m 8s\n",
            "800:\tlearn: 102.4602729\ttotal: 1m 8s\tremaining: 3m 8s\n",
            "801:\tlearn: 102.4503022\ttotal: 1m 8s\tremaining: 3m 8s\n",
            "802:\tlearn: 102.4468500\ttotal: 1m 8s\tremaining: 3m 8s\n",
            "803:\tlearn: 102.4356546\ttotal: 1m 9s\tremaining: 3m 8s\n",
            "804:\tlearn: 102.4313472\ttotal: 1m 9s\tremaining: 3m 8s\n",
            "805:\tlearn: 102.4280713\ttotal: 1m 9s\tremaining: 3m 8s\n",
            "806:\tlearn: 102.4248636\ttotal: 1m 9s\tremaining: 3m 8s\n",
            "807:\tlearn: 102.4224511\ttotal: 1m 9s\tremaining: 3m 8s\n",
            "808:\tlearn: 102.4213678\ttotal: 1m 9s\tremaining: 3m 8s\n",
            "809:\tlearn: 102.4122359\ttotal: 1m 9s\tremaining: 3m 8s\n",
            "810:\tlearn: 102.3987653\ttotal: 1m 9s\tremaining: 3m 7s\n",
            "811:\tlearn: 102.3983119\ttotal: 1m 9s\tremaining: 3m 7s\n",
            "812:\tlearn: 102.3969307\ttotal: 1m 9s\tremaining: 3m 7s\n",
            "813:\tlearn: 102.3840751\ttotal: 1m 9s\tremaining: 3m 7s\n",
            "814:\tlearn: 102.3808383\ttotal: 1m 9s\tremaining: 3m 7s\n",
            "815:\tlearn: 102.3776418\ttotal: 1m 10s\tremaining: 3m 7s\n",
            "816:\tlearn: 102.3754660\ttotal: 1m 10s\tremaining: 3m 7s\n",
            "817:\tlearn: 102.3728225\ttotal: 1m 10s\tremaining: 3m 7s\n",
            "818:\tlearn: 102.3644777\ttotal: 1m 10s\tremaining: 3m 7s\n",
            "819:\tlearn: 102.3551168\ttotal: 1m 10s\tremaining: 3m 7s\n",
            "820:\tlearn: 102.3548354\ttotal: 1m 10s\tremaining: 3m 7s\n",
            "821:\tlearn: 102.3522201\ttotal: 1m 10s\tremaining: 3m 7s\n",
            "822:\tlearn: 102.3513563\ttotal: 1m 10s\tremaining: 3m 6s\n",
            "823:\tlearn: 102.3486888\ttotal: 1m 10s\tremaining: 3m 6s\n",
            "824:\tlearn: 102.3469935\ttotal: 1m 10s\tremaining: 3m 6s\n",
            "825:\tlearn: 102.3456691\ttotal: 1m 10s\tremaining: 3m 6s\n",
            "826:\tlearn: 102.3435283\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "827:\tlearn: 102.3429493\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "828:\tlearn: 102.3426597\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "829:\tlearn: 102.3332074\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "830:\tlearn: 102.3315642\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "831:\tlearn: 102.3231727\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "832:\tlearn: 102.3203122\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "833:\tlearn: 102.3154845\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "834:\tlearn: 102.3076249\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "835:\tlearn: 102.3067168\ttotal: 1m 11s\tremaining: 3m 6s\n",
            "836:\tlearn: 102.2930410\ttotal: 1m 11s\tremaining: 3m 5s\n",
            "837:\tlearn: 102.2817682\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "838:\tlearn: 102.2804214\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "839:\tlearn: 102.2794255\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "840:\tlearn: 102.2787406\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "841:\tlearn: 102.2745155\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "842:\tlearn: 102.2697448\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "843:\tlearn: 102.2639749\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "844:\tlearn: 102.2607584\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "845:\tlearn: 102.2590424\ttotal: 1m 12s\tremaining: 3m 5s\n",
            "846:\tlearn: 102.2568297\ttotal: 1m 12s\tremaining: 3m 4s\n",
            "847:\tlearn: 102.2531751\ttotal: 1m 12s\tremaining: 3m 4s\n",
            "848:\tlearn: 102.2502362\ttotal: 1m 12s\tremaining: 3m 4s\n",
            "849:\tlearn: 102.2472788\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "850:\tlearn: 102.2397375\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "851:\tlearn: 102.2271911\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "852:\tlearn: 102.2106608\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "853:\tlearn: 102.2085789\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "854:\tlearn: 102.2011544\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "855:\tlearn: 102.1957475\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "856:\tlearn: 102.1933614\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "857:\tlearn: 102.1902277\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "858:\tlearn: 102.1865204\ttotal: 1m 13s\tremaining: 3m 4s\n",
            "859:\tlearn: 102.1800753\ttotal: 1m 13s\tremaining: 3m 3s\n",
            "860:\tlearn: 102.1773946\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "861:\tlearn: 102.1754336\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "862:\tlearn: 102.1693244\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "863:\tlearn: 102.1602832\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "864:\tlearn: 102.1541991\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "865:\tlearn: 102.1510284\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "866:\tlearn: 102.1490398\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "867:\tlearn: 102.1453526\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "868:\tlearn: 102.1372824\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "869:\tlearn: 102.1363422\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "870:\tlearn: 102.1316962\ttotal: 1m 14s\tremaining: 3m 3s\n",
            "871:\tlearn: 102.1263982\ttotal: 1m 14s\tremaining: 3m 2s\n",
            "872:\tlearn: 102.1203720\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "873:\tlearn: 102.1187182\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "874:\tlearn: 102.1140879\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "875:\tlearn: 102.1061675\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "876:\tlearn: 102.1030231\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "877:\tlearn: 102.1018573\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "878:\tlearn: 102.0940560\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "879:\tlearn: 102.0728509\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "880:\tlearn: 102.0663217\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "881:\tlearn: 102.0527384\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "882:\tlearn: 102.0523498\ttotal: 1m 15s\tremaining: 3m 2s\n",
            "883:\tlearn: 102.0414992\ttotal: 1m 16s\tremaining: 3m 2s\n",
            "884:\tlearn: 102.0398950\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "885:\tlearn: 102.0331352\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "886:\tlearn: 102.0096530\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "887:\tlearn: 102.0062138\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "888:\tlearn: 101.9983744\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "889:\tlearn: 101.9875905\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "890:\tlearn: 101.9847984\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "891:\tlearn: 101.9784848\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "892:\tlearn: 101.9687480\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "893:\tlearn: 101.9672227\ttotal: 1m 16s\tremaining: 3m 1s\n",
            "894:\tlearn: 101.9664975\ttotal: 1m 17s\tremaining: 3m 1s\n",
            "895:\tlearn: 101.9608566\ttotal: 1m 17s\tremaining: 3m 1s\n",
            "896:\tlearn: 101.9598730\ttotal: 1m 17s\tremaining: 3m\n",
            "897:\tlearn: 101.9583023\ttotal: 1m 17s\tremaining: 3m\n",
            "898:\tlearn: 101.9465095\ttotal: 1m 17s\tremaining: 3m\n",
            "899:\tlearn: 101.9402124\ttotal: 1m 17s\tremaining: 3m\n",
            "900:\tlearn: 101.9298435\ttotal: 1m 17s\tremaining: 3m\n",
            "901:\tlearn: 101.9259431\ttotal: 1m 17s\tremaining: 3m\n",
            "902:\tlearn: 101.9133920\ttotal: 1m 17s\tremaining: 3m\n",
            "903:\tlearn: 101.9044961\ttotal: 1m 17s\tremaining: 3m\n",
            "904:\tlearn: 101.8978757\ttotal: 1m 17s\tremaining: 3m\n",
            "905:\tlearn: 101.8956226\ttotal: 1m 17s\tremaining: 3m\n",
            "906:\tlearn: 101.8932537\ttotal: 1m 18s\tremaining: 3m\n",
            "907:\tlearn: 101.8899685\ttotal: 1m 18s\tremaining: 3m\n",
            "908:\tlearn: 101.8868796\ttotal: 1m 18s\tremaining: 3m\n",
            "909:\tlearn: 101.8840435\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "910:\tlearn: 101.8773736\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "911:\tlearn: 101.8769889\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "912:\tlearn: 101.8751647\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "913:\tlearn: 101.8727921\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "914:\tlearn: 101.8624748\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "915:\tlearn: 101.8597798\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "916:\tlearn: 101.8561494\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "917:\tlearn: 101.8469553\ttotal: 1m 18s\tremaining: 2m 59s\n",
            "918:\tlearn: 101.8454266\ttotal: 1m 19s\tremaining: 2m 59s\n",
            "919:\tlearn: 101.8402819\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "920:\tlearn: 101.8336085\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "921:\tlearn: 101.8278129\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "922:\tlearn: 101.8243783\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "923:\tlearn: 101.8197308\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "924:\tlearn: 101.8167826\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "925:\tlearn: 101.8075804\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "926:\tlearn: 101.8008807\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "927:\tlearn: 101.7971478\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "928:\tlearn: 101.7923975\ttotal: 1m 19s\tremaining: 2m 58s\n",
            "929:\tlearn: 101.7882914\ttotal: 1m 20s\tremaining: 2m 58s\n",
            "930:\tlearn: 101.7861578\ttotal: 1m 20s\tremaining: 2m 58s\n",
            "931:\tlearn: 101.7809571\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "932:\tlearn: 101.7499178\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "933:\tlearn: 101.7419727\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "934:\tlearn: 101.7405017\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "935:\tlearn: 101.7333421\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "936:\tlearn: 101.7330779\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "937:\tlearn: 101.7247087\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "938:\tlearn: 101.7187978\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "939:\tlearn: 101.7165486\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "940:\tlearn: 101.7128874\ttotal: 1m 20s\tremaining: 2m 57s\n",
            "941:\tlearn: 101.7093484\ttotal: 1m 21s\tremaining: 2m 57s\n",
            "942:\tlearn: 101.6903869\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "943:\tlearn: 101.6880436\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "944:\tlearn: 101.6866891\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "945:\tlearn: 101.6708460\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "946:\tlearn: 101.6704900\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "947:\tlearn: 101.6699070\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "948:\tlearn: 101.6693651\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "949:\tlearn: 101.6415309\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "950:\tlearn: 101.6348472\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "951:\tlearn: 101.6218436\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "952:\tlearn: 101.6196188\ttotal: 1m 21s\tremaining: 2m 56s\n",
            "953:\tlearn: 101.6152250\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "954:\tlearn: 101.6142389\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "955:\tlearn: 101.6136002\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "956:\tlearn: 101.6050678\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "957:\tlearn: 101.5999870\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "958:\tlearn: 101.5987341\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "959:\tlearn: 101.5972440\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "960:\tlearn: 101.5896052\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "961:\tlearn: 101.5875599\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "962:\tlearn: 101.5864882\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "963:\tlearn: 101.5831980\ttotal: 1m 22s\tremaining: 2m 55s\n",
            "964:\tlearn: 101.5826119\ttotal: 1m 22s\tremaining: 2m 54s\n",
            "965:\tlearn: 101.5745748\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "966:\tlearn: 101.5729546\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "967:\tlearn: 101.5721206\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "968:\tlearn: 101.5705857\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "969:\tlearn: 101.5700460\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "970:\tlearn: 101.5683291\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "971:\tlearn: 101.5645317\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "972:\tlearn: 101.5505169\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "973:\tlearn: 101.5475056\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "974:\tlearn: 101.5435859\ttotal: 1m 23s\tremaining: 2m 54s\n",
            "975:\tlearn: 101.5434032\ttotal: 1m 23s\tremaining: 2m 53s\n",
            "976:\tlearn: 101.5410788\ttotal: 1m 23s\tremaining: 2m 53s\n",
            "977:\tlearn: 101.5356785\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "978:\tlearn: 101.5335277\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "979:\tlearn: 101.5293634\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "980:\tlearn: 101.5260025\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "981:\tlearn: 101.5223005\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "982:\tlearn: 101.5183219\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "983:\tlearn: 101.5153430\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "984:\tlearn: 101.5004352\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "985:\tlearn: 101.4937942\ttotal: 1m 24s\tremaining: 2m 53s\n",
            "986:\tlearn: 101.4813873\ttotal: 1m 24s\tremaining: 2m 52s\n",
            "987:\tlearn: 101.4776027\ttotal: 1m 24s\tremaining: 2m 52s\n",
            "988:\tlearn: 101.4739747\ttotal: 1m 24s\tremaining: 2m 52s\n",
            "989:\tlearn: 101.4716066\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "990:\tlearn: 101.4598500\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "991:\tlearn: 101.4567140\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "992:\tlearn: 101.4552865\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "993:\tlearn: 101.4515910\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "994:\tlearn: 101.4469803\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "995:\tlearn: 101.4444568\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "996:\tlearn: 101.4431914\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "997:\tlearn: 101.4369178\ttotal: 1m 25s\tremaining: 2m 52s\n",
            "998:\tlearn: 101.4325501\ttotal: 1m 25s\tremaining: 2m 51s\n",
            "999:\tlearn: 101.4290670\ttotal: 1m 25s\tremaining: 2m 51s\n",
            "1000:\tlearn: 101.4266317\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1001:\tlearn: 101.4215426\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1002:\tlearn: 101.4192516\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1003:\tlearn: 101.4147242\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1004:\tlearn: 101.4139134\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1005:\tlearn: 101.4114688\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1006:\tlearn: 101.4008316\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1007:\tlearn: 101.3937730\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1008:\tlearn: 101.3931727\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1009:\tlearn: 101.3904908\ttotal: 1m 26s\tremaining: 2m 51s\n",
            "1010:\tlearn: 101.3882278\ttotal: 1m 26s\tremaining: 2m 50s\n",
            "1011:\tlearn: 101.3853487\ttotal: 1m 26s\tremaining: 2m 50s\n",
            "1012:\tlearn: 101.3818031\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1013:\tlearn: 101.3789093\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1014:\tlearn: 101.3658271\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1015:\tlearn: 101.3645334\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1016:\tlearn: 101.3617238\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1017:\tlearn: 101.3572357\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1018:\tlearn: 101.3543556\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1019:\tlearn: 101.3524784\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1020:\tlearn: 101.3493410\ttotal: 1m 27s\tremaining: 2m 50s\n",
            "1021:\tlearn: 101.3487491\ttotal: 1m 27s\tremaining: 2m 49s\n",
            "1022:\tlearn: 101.3478703\ttotal: 1m 27s\tremaining: 2m 49s\n",
            "1023:\tlearn: 101.3376558\ttotal: 1m 27s\tremaining: 2m 49s\n",
            "1024:\tlearn: 101.3293208\ttotal: 1m 28s\tremaining: 2m 49s\n",
            "1025:\tlearn: 101.3276225\ttotal: 1m 28s\tremaining: 2m 49s\n",
            "1026:\tlearn: 101.3257874\ttotal: 1m 28s\tremaining: 2m 49s\n",
            "1027:\tlearn: 101.3129058\ttotal: 1m 28s\tremaining: 2m 49s\n",
            "1028:\tlearn: 101.3086903\ttotal: 1m 28s\tremaining: 2m 49s\n",
            "1029:\tlearn: 101.3052847\ttotal: 1m 28s\tremaining: 2m 49s\n",
            "1030:\tlearn: 101.3038135\ttotal: 1m 28s\tremaining: 2m 49s\n",
            "1031:\tlearn: 101.3030102\ttotal: 1m 28s\tremaining: 2m 49s\n",
            "1032:\tlearn: 101.2989136\ttotal: 1m 28s\tremaining: 2m 48s\n",
            "1033:\tlearn: 101.2962763\ttotal: 1m 28s\tremaining: 2m 48s\n",
            "1034:\tlearn: 101.2928223\ttotal: 1m 28s\tremaining: 2m 48s\n",
            "1035:\tlearn: 101.2886251\ttotal: 1m 29s\tremaining: 2m 48s\n",
            "1036:\tlearn: 101.2878164\ttotal: 1m 29s\tremaining: 2m 48s\n",
            "1037:\tlearn: 101.2859293\ttotal: 1m 29s\tremaining: 2m 48s\n",
            "1038:\tlearn: 101.2803115\ttotal: 1m 29s\tremaining: 2m 48s\n",
            "1039:\tlearn: 101.2780371\ttotal: 1m 29s\tremaining: 2m 48s\n",
            "1040:\tlearn: 101.2658812\ttotal: 1m 29s\tremaining: 2m 48s\n",
            "1041:\tlearn: 101.2628060\ttotal: 1m 29s\tremaining: 2m 48s\n",
            "1042:\tlearn: 101.2607787\ttotal: 1m 29s\tremaining: 2m 48s\n",
            "1043:\tlearn: 101.2600863\ttotal: 1m 29s\tremaining: 2m 47s\n",
            "1044:\tlearn: 101.2570825\ttotal: 1m 29s\tremaining: 2m 47s\n",
            "1045:\tlearn: 101.2539833\ttotal: 1m 29s\tremaining: 2m 47s\n",
            "1046:\tlearn: 101.2522298\ttotal: 1m 29s\tremaining: 2m 47s\n",
            "1047:\tlearn: 101.2479729\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1048:\tlearn: 101.2460096\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1049:\tlearn: 101.2279996\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1050:\tlearn: 101.2196544\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1051:\tlearn: 101.2116592\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1052:\tlearn: 101.2090742\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1053:\tlearn: 101.2030615\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1054:\tlearn: 101.1920756\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1055:\tlearn: 101.1833896\ttotal: 1m 30s\tremaining: 2m 47s\n",
            "1056:\tlearn: 101.1802242\ttotal: 1m 30s\tremaining: 2m 46s\n",
            "1057:\tlearn: 101.1771381\ttotal: 1m 30s\tremaining: 2m 46s\n",
            "1058:\tlearn: 101.1754817\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1059:\tlearn: 101.1666099\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1060:\tlearn: 101.1653340\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1061:\tlearn: 101.1614312\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1062:\tlearn: 101.1605200\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1063:\tlearn: 101.1591589\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1064:\tlearn: 101.1584597\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1065:\tlearn: 101.1579497\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1066:\tlearn: 101.1569674\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1067:\tlearn: 101.1505261\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1068:\tlearn: 101.1484170\ttotal: 1m 31s\tremaining: 2m 46s\n",
            "1069:\tlearn: 101.1442120\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1070:\tlearn: 101.1422067\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1071:\tlearn: 101.1372953\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1072:\tlearn: 101.1353151\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1073:\tlearn: 101.1333570\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1074:\tlearn: 101.1302174\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1075:\tlearn: 101.1231303\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1076:\tlearn: 101.1201752\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1077:\tlearn: 101.1166764\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1078:\tlearn: 101.1106622\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1079:\tlearn: 101.1051474\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1080:\tlearn: 101.0928144\ttotal: 1m 32s\tremaining: 2m 45s\n",
            "1081:\tlearn: 101.0766509\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1082:\tlearn: 101.0694482\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1083:\tlearn: 101.0680126\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1084:\tlearn: 101.0660351\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1085:\tlearn: 101.0600947\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1086:\tlearn: 101.0568205\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1087:\tlearn: 101.0495816\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1088:\tlearn: 101.0443108\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1089:\tlearn: 101.0347968\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1090:\tlearn: 101.0312440\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1091:\tlearn: 101.0270051\ttotal: 1m 33s\tremaining: 2m 44s\n",
            "1092:\tlearn: 101.0205071\ttotal: 1m 33s\tremaining: 2m 43s\n",
            "1093:\tlearn: 101.0091737\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1094:\tlearn: 101.0080353\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1095:\tlearn: 101.0054306\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1096:\tlearn: 100.9991830\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1097:\tlearn: 100.9966179\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1098:\tlearn: 100.9917236\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1099:\tlearn: 100.9903691\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1100:\tlearn: 100.9876474\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1101:\tlearn: 100.9825865\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1102:\tlearn: 100.9800631\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1103:\tlearn: 100.9760703\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "1104:\tlearn: 100.9740100\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1105:\tlearn: 100.9733879\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1106:\tlearn: 100.9711732\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1107:\tlearn: 100.9663496\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1108:\tlearn: 100.9637912\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1109:\tlearn: 100.9611753\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1110:\tlearn: 100.9603335\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1111:\tlearn: 100.9581595\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1112:\tlearn: 100.9532062\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1113:\tlearn: 100.9513262\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1114:\tlearn: 100.9477267\ttotal: 1m 35s\tremaining: 2m 42s\n",
            "1115:\tlearn: 100.9389664\ttotal: 1m 36s\tremaining: 2m 42s\n",
            "1116:\tlearn: 100.9349211\ttotal: 1m 36s\tremaining: 2m 42s\n",
            "1117:\tlearn: 100.9340656\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1118:\tlearn: 100.9263371\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1119:\tlearn: 100.9233876\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1120:\tlearn: 100.9208409\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1121:\tlearn: 100.9125183\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1122:\tlearn: 100.9120044\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1123:\tlearn: 100.9084313\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1124:\tlearn: 100.9040384\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1125:\tlearn: 100.9010584\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1126:\tlearn: 100.8999564\ttotal: 1m 36s\tremaining: 2m 41s\n",
            "1127:\tlearn: 100.8984681\ttotal: 1m 37s\tremaining: 2m 41s\n",
            "1128:\tlearn: 100.8872194\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1129:\tlearn: 100.8850257\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1130:\tlearn: 100.8771239\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1131:\tlearn: 100.8743435\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1132:\tlearn: 100.8722716\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1133:\tlearn: 100.8667117\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1134:\tlearn: 100.8659534\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1135:\tlearn: 100.8568871\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1136:\tlearn: 100.8543845\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1137:\tlearn: 100.8472587\ttotal: 1m 37s\tremaining: 2m 40s\n",
            "1138:\tlearn: 100.8459800\ttotal: 1m 38s\tremaining: 2m 40s\n",
            "1139:\tlearn: 100.8436597\ttotal: 1m 38s\tremaining: 2m 40s\n",
            "1140:\tlearn: 100.8427600\ttotal: 1m 38s\tremaining: 2m 40s\n",
            "1141:\tlearn: 100.8416058\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1142:\tlearn: 100.8342675\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1143:\tlearn: 100.8334430\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1144:\tlearn: 100.8307958\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1145:\tlearn: 100.8176399\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1146:\tlearn: 100.8131489\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1147:\tlearn: 100.8106728\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1148:\tlearn: 100.8098734\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1149:\tlearn: 100.8085090\ttotal: 1m 38s\tremaining: 2m 39s\n",
            "1150:\tlearn: 100.7979246\ttotal: 1m 39s\tremaining: 2m 39s\n",
            "1151:\tlearn: 100.7959157\ttotal: 1m 39s\tremaining: 2m 39s\n",
            "1152:\tlearn: 100.7915234\ttotal: 1m 39s\tremaining: 2m 39s\n",
            "1153:\tlearn: 100.7877140\ttotal: 1m 39s\tremaining: 2m 38s\n",
            "1154:\tlearn: 100.7847189\ttotal: 1m 39s\tremaining: 2m 38s\n",
            "1155:\tlearn: 100.7762212\ttotal: 1m 39s\tremaining: 2m 38s\n",
            "1156:\tlearn: 100.7728537\ttotal: 1m 39s\tremaining: 2m 38s\n",
            "1157:\tlearn: 100.7717164\ttotal: 1m 39s\tremaining: 2m 38s\n",
            "1158:\tlearn: 100.7566870\ttotal: 1m 39s\tremaining: 2m 38s\n",
            "1159:\tlearn: 100.7565201\ttotal: 1m 39s\tremaining: 2m 38s\n",
            "1160:\tlearn: 100.7454074\ttotal: 1m 39s\tremaining: 2m 38s\n",
            "1161:\tlearn: 100.7402114\ttotal: 1m 40s\tremaining: 2m 38s\n",
            "1162:\tlearn: 100.7365121\ttotal: 1m 40s\tremaining: 2m 38s\n",
            "1163:\tlearn: 100.7354087\ttotal: 1m 40s\tremaining: 2m 38s\n",
            "1164:\tlearn: 100.7340675\ttotal: 1m 40s\tremaining: 2m 38s\n",
            "1165:\tlearn: 100.7313127\ttotal: 1m 40s\tremaining: 2m 37s\n",
            "1166:\tlearn: 100.7267244\ttotal: 1m 40s\tremaining: 2m 37s\n",
            "1167:\tlearn: 100.7259104\ttotal: 1m 40s\tremaining: 2m 37s\n",
            "1168:\tlearn: 100.7197050\ttotal: 1m 40s\tremaining: 2m 37s\n",
            "1169:\tlearn: 100.7136594\ttotal: 1m 40s\tremaining: 2m 37s\n",
            "1170:\tlearn: 100.7082126\ttotal: 1m 40s\tremaining: 2m 37s\n",
            "1171:\tlearn: 100.6959248\ttotal: 1m 40s\tremaining: 2m 37s\n",
            "1172:\tlearn: 100.6950374\ttotal: 1m 41s\tremaining: 2m 37s\n",
            "1173:\tlearn: 100.6856850\ttotal: 1m 41s\tremaining: 2m 37s\n",
            "1174:\tlearn: 100.6832140\ttotal: 1m 41s\tremaining: 2m 37s\n",
            "1175:\tlearn: 100.6774495\ttotal: 1m 41s\tremaining: 2m 37s\n",
            "1176:\tlearn: 100.6734491\ttotal: 1m 41s\tremaining: 2m 37s\n",
            "1177:\tlearn: 100.6675456\ttotal: 1m 41s\tremaining: 2m 36s\n",
            "1178:\tlearn: 100.6553433\ttotal: 1m 41s\tremaining: 2m 36s\n",
            "1179:\tlearn: 100.6480181\ttotal: 1m 41s\tremaining: 2m 36s\n",
            "1180:\tlearn: 100.6437494\ttotal: 1m 41s\tremaining: 2m 36s\n",
            "1181:\tlearn: 100.6410716\ttotal: 1m 41s\tremaining: 2m 36s\n",
            "1182:\tlearn: 100.6402194\ttotal: 1m 41s\tremaining: 2m 36s\n",
            "1183:\tlearn: 100.6385327\ttotal: 1m 41s\tremaining: 2m 36s\n",
            "1184:\tlearn: 100.6281756\ttotal: 1m 42s\tremaining: 2m 36s\n",
            "1185:\tlearn: 100.6273253\ttotal: 1m 42s\tremaining: 2m 36s\n",
            "1186:\tlearn: 100.6231336\ttotal: 1m 42s\tremaining: 2m 36s\n",
            "1187:\tlearn: 100.6189799\ttotal: 1m 42s\tremaining: 2m 36s\n",
            "1188:\tlearn: 100.6104375\ttotal: 1m 42s\tremaining: 2m 36s\n",
            "1189:\tlearn: 100.6094796\ttotal: 1m 42s\tremaining: 2m 35s\n",
            "1190:\tlearn: 100.6084722\ttotal: 1m 42s\tremaining: 2m 35s\n",
            "1191:\tlearn: 100.6053757\ttotal: 1m 42s\tremaining: 2m 35s\n",
            "1192:\tlearn: 100.5839623\ttotal: 1m 42s\tremaining: 2m 35s\n",
            "1193:\tlearn: 100.5762170\ttotal: 1m 42s\tremaining: 2m 35s\n",
            "1194:\tlearn: 100.5734425\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "1195:\tlearn: 100.5728912\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "1196:\tlearn: 100.5708090\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "1197:\tlearn: 100.5688925\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "1198:\tlearn: 100.5679470\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "1199:\tlearn: 100.5669688\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "1200:\tlearn: 100.5628419\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "1201:\tlearn: 100.5611316\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "1202:\tlearn: 100.5573035\ttotal: 1m 43s\tremaining: 2m 34s\n",
            "1203:\tlearn: 100.5514310\ttotal: 1m 43s\tremaining: 2m 34s\n",
            "1204:\tlearn: 100.5408453\ttotal: 1m 43s\tremaining: 2m 34s\n",
            "1205:\tlearn: 100.5251037\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1206:\tlearn: 100.5223552\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1207:\tlearn: 100.5073405\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1208:\tlearn: 100.5029131\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1209:\tlearn: 100.4973224\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1210:\tlearn: 100.4934120\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1211:\tlearn: 100.4925010\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1212:\tlearn: 100.4731666\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1213:\tlearn: 100.4714281\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1214:\tlearn: 100.4699031\ttotal: 1m 44s\tremaining: 2m 34s\n",
            "1215:\tlearn: 100.4670824\ttotal: 1m 44s\tremaining: 2m 33s\n",
            "1216:\tlearn: 100.4590281\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1217:\tlearn: 100.4479188\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1218:\tlearn: 100.4429599\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1219:\tlearn: 100.4399580\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1220:\tlearn: 100.4373662\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1221:\tlearn: 100.4341566\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1222:\tlearn: 100.4287488\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1223:\tlearn: 100.4224305\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1224:\tlearn: 100.4134590\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1225:\tlearn: 100.4120008\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1226:\tlearn: 100.4104254\ttotal: 1m 45s\tremaining: 2m 33s\n",
            "1227:\tlearn: 100.4062010\ttotal: 1m 45s\tremaining: 2m 32s\n",
            "1228:\tlearn: 100.3935263\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1229:\tlearn: 100.3884467\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1230:\tlearn: 100.3870195\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1231:\tlearn: 100.3863546\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1232:\tlearn: 100.3793981\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1233:\tlearn: 100.3777966\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1234:\tlearn: 100.3699676\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1235:\tlearn: 100.3673949\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1236:\tlearn: 100.3668848\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1237:\tlearn: 100.3626908\ttotal: 1m 46s\tremaining: 2m 32s\n",
            "1238:\tlearn: 100.3622937\ttotal: 1m 46s\tremaining: 2m 31s\n",
            "1239:\tlearn: 100.3608115\ttotal: 1m 46s\tremaining: 2m 31s\n",
            "1240:\tlearn: 100.3551591\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1241:\tlearn: 100.3543353\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1242:\tlearn: 100.3525487\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1243:\tlearn: 100.3476084\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1244:\tlearn: 100.3469203\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1245:\tlearn: 100.3415142\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1246:\tlearn: 100.3385627\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1247:\tlearn: 100.3320909\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1248:\tlearn: 100.3295715\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1249:\tlearn: 100.3223373\ttotal: 1m 47s\tremaining: 2m 31s\n",
            "1250:\tlearn: 100.3150904\ttotal: 1m 47s\tremaining: 2m 30s\n",
            "1251:\tlearn: 100.3108230\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1252:\tlearn: 100.3069138\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1253:\tlearn: 100.3029933\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1254:\tlearn: 100.2994723\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1255:\tlearn: 100.2948232\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1256:\tlearn: 100.2904974\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1257:\tlearn: 100.2845004\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1258:\tlearn: 100.2797295\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1259:\tlearn: 100.2730912\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1260:\tlearn: 100.2722110\ttotal: 1m 48s\tremaining: 2m 30s\n",
            "1261:\tlearn: 100.2678283\ttotal: 1m 48s\tremaining: 2m 29s\n",
            "1262:\tlearn: 100.2664846\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1263:\tlearn: 100.2647917\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1264:\tlearn: 100.2626248\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1265:\tlearn: 100.2621751\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1266:\tlearn: 100.2569975\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1267:\tlearn: 100.2494332\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1268:\tlearn: 100.2487924\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1269:\tlearn: 100.2397716\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1270:\tlearn: 100.2343265\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1271:\tlearn: 100.2290158\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1272:\tlearn: 100.2252682\ttotal: 1m 49s\tremaining: 2m 29s\n",
            "1273:\tlearn: 100.2233368\ttotal: 1m 49s\tremaining: 2m 28s\n",
            "1274:\tlearn: 100.2228732\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1275:\tlearn: 100.2224149\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1276:\tlearn: 100.2187454\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1277:\tlearn: 100.2179516\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1278:\tlearn: 100.2132089\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1279:\tlearn: 100.2086492\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1280:\tlearn: 100.2083912\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1281:\tlearn: 100.2016935\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1282:\tlearn: 100.2001096\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1283:\tlearn: 100.1993773\ttotal: 1m 50s\tremaining: 2m 28s\n",
            "1284:\tlearn: 100.1978055\ttotal: 1m 50s\tremaining: 2m 27s\n",
            "1285:\tlearn: 100.1971426\ttotal: 1m 50s\tremaining: 2m 27s\n",
            "1286:\tlearn: 100.1918904\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1287:\tlearn: 100.1896056\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1288:\tlearn: 100.1878107\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1289:\tlearn: 100.1843747\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1290:\tlearn: 100.1832672\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1291:\tlearn: 100.1827576\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1292:\tlearn: 100.1774232\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1293:\tlearn: 100.1672733\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1294:\tlearn: 100.1578941\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1295:\tlearn: 100.1542799\ttotal: 1m 51s\tremaining: 2m 27s\n",
            "1296:\tlearn: 100.1479086\ttotal: 1m 51s\tremaining: 2m 26s\n",
            "1297:\tlearn: 100.1396469\ttotal: 1m 51s\tremaining: 2m 26s\n",
            "1298:\tlearn: 100.1372393\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1299:\tlearn: 100.1338074\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1300:\tlearn: 100.1317502\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1301:\tlearn: 100.1293689\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1302:\tlearn: 100.1203882\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1303:\tlearn: 100.1139392\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1304:\tlearn: 100.1083890\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1305:\tlearn: 100.1000651\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1306:\tlearn: 100.0982960\ttotal: 1m 52s\tremaining: 2m 26s\n",
            "1307:\tlearn: 100.0963334\ttotal: 1m 52s\tremaining: 2m 25s\n",
            "1308:\tlearn: 100.0933247\ttotal: 1m 52s\tremaining: 2m 25s\n",
            "1309:\tlearn: 100.0905169\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1310:\tlearn: 100.0868627\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1311:\tlearn: 100.0838840\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1312:\tlearn: 100.0820822\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1313:\tlearn: 100.0794099\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1314:\tlearn: 100.0748251\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1315:\tlearn: 100.0743245\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1316:\tlearn: 100.0637110\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1317:\tlearn: 100.0606918\ttotal: 1m 53s\tremaining: 2m 25s\n",
            "1318:\tlearn: 100.0603097\ttotal: 1m 53s\tremaining: 2m 24s\n",
            "1319:\tlearn: 100.0558355\ttotal: 1m 53s\tremaining: 2m 24s\n",
            "1320:\tlearn: 100.0493287\ttotal: 1m 53s\tremaining: 2m 24s\n",
            "1321:\tlearn: 100.0460052\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1322:\tlearn: 100.0452191\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1323:\tlearn: 100.0447624\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1324:\tlearn: 100.0413024\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1325:\tlearn: 100.0409843\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1326:\tlearn: 100.0383919\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1327:\tlearn: 100.0326688\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1328:\tlearn: 100.0301800\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1329:\tlearn: 100.0269107\ttotal: 1m 54s\tremaining: 2m 24s\n",
            "1330:\tlearn: 100.0199945\ttotal: 1m 54s\tremaining: 2m 23s\n",
            "1331:\tlearn: 100.0161204\ttotal: 1m 54s\tremaining: 2m 23s\n",
            "1332:\tlearn: 100.0109087\ttotal: 1m 54s\tremaining: 2m 23s\n",
            "1333:\tlearn: 100.0059520\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1334:\tlearn: 100.0047403\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1335:\tlearn: 100.0031843\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1336:\tlearn: 100.0015261\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1337:\tlearn: 99.9982243\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1338:\tlearn: 99.9938313\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1339:\tlearn: 99.9901183\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1340:\tlearn: 99.9848500\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1341:\tlearn: 99.9798157\ttotal: 1m 55s\tremaining: 2m 23s\n",
            "1342:\tlearn: 99.9755383\ttotal: 1m 55s\tremaining: 2m 22s\n",
            "1343:\tlearn: 99.9691492\ttotal: 1m 55s\tremaining: 2m 22s\n",
            "1344:\tlearn: 99.9593606\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1345:\tlearn: 99.9536446\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1346:\tlearn: 99.9518681\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1347:\tlearn: 99.9514448\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1348:\tlearn: 99.9491974\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1349:\tlearn: 99.9450056\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1350:\tlearn: 99.9424511\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1351:\tlearn: 99.9393814\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1352:\tlearn: 99.9385721\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1353:\tlearn: 99.9362762\ttotal: 1m 56s\tremaining: 2m 22s\n",
            "1354:\tlearn: 99.9308553\ttotal: 1m 56s\tremaining: 2m 21s\n",
            "1355:\tlearn: 99.9304198\ttotal: 1m 56s\tremaining: 2m 21s\n",
            "1356:\tlearn: 99.9285343\ttotal: 1m 57s\tremaining: 2m 21s\n",
            "1357:\tlearn: 99.9251772\ttotal: 1m 57s\tremaining: 2m 21s\n",
            "1358:\tlearn: 99.9222479\ttotal: 1m 57s\tremaining: 2m 21s\n",
            "1359:\tlearn: 99.9201277\ttotal: 1m 57s\tremaining: 2m 21s\n",
            "1360:\tlearn: 99.9154651\ttotal: 1m 57s\tremaining: 2m 21s\n",
            "1361:\tlearn: 99.9147878\ttotal: 1m 57s\tremaining: 2m 21s\n",
            "1362:\tlearn: 99.9118857\ttotal: 1m 57s\tremaining: 2m 21s\n",
            "1363:\tlearn: 99.9065513\ttotal: 1m 57s\tremaining: 2m 21s\n",
            "1364:\tlearn: 99.9040013\ttotal: 1m 57s\tremaining: 2m 20s\n",
            "1365:\tlearn: 99.9036850\ttotal: 1m 57s\tremaining: 2m 20s\n",
            "1366:\tlearn: 99.9006196\ttotal: 1m 57s\tremaining: 2m 20s\n",
            "1367:\tlearn: 99.8958029\ttotal: 1m 57s\tremaining: 2m 20s\n",
            "1368:\tlearn: 99.8938408\ttotal: 1m 58s\tremaining: 2m 20s\n",
            "1369:\tlearn: 99.8886225\ttotal: 1m 58s\tremaining: 2m 20s\n",
            "1370:\tlearn: 99.8816917\ttotal: 1m 58s\tremaining: 2m 20s\n",
            "1371:\tlearn: 99.8742109\ttotal: 1m 58s\tremaining: 2m 20s\n",
            "1372:\tlearn: 99.8713860\ttotal: 1m 58s\tremaining: 2m 20s\n",
            "1373:\tlearn: 99.8668494\ttotal: 1m 58s\tremaining: 2m 20s\n",
            "1374:\tlearn: 99.8664012\ttotal: 1m 58s\tremaining: 2m 20s\n",
            "1375:\tlearn: 99.8647180\ttotal: 1m 58s\tremaining: 2m 20s\n",
            "1376:\tlearn: 99.8574872\ttotal: 1m 58s\tremaining: 2m 19s\n",
            "1377:\tlearn: 99.8552180\ttotal: 1m 58s\tremaining: 2m 19s\n",
            "1378:\tlearn: 99.8503408\ttotal: 1m 58s\tremaining: 2m 19s\n",
            "1379:\tlearn: 99.8491143\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1380:\tlearn: 99.8474416\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1381:\tlearn: 99.8445624\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1382:\tlearn: 99.8371757\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1383:\tlearn: 99.8362241\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1384:\tlearn: 99.8337823\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1385:\tlearn: 99.8325758\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1386:\tlearn: 99.8275615\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1387:\tlearn: 99.8250397\ttotal: 1m 59s\tremaining: 2m 19s\n",
            "1388:\tlearn: 99.8225266\ttotal: 1m 59s\tremaining: 2m 18s\n",
            "1389:\tlearn: 99.8201205\ttotal: 1m 59s\tremaining: 2m 18s\n",
            "1390:\tlearn: 99.8178593\ttotal: 1m 59s\tremaining: 2m 18s\n",
            "1391:\tlearn: 99.8112929\ttotal: 2m\tremaining: 2m 18s\n",
            "1392:\tlearn: 99.8086066\ttotal: 2m\tremaining: 2m 18s\n",
            "1393:\tlearn: 99.8061538\ttotal: 2m\tremaining: 2m 18s\n",
            "1394:\tlearn: 99.8007264\ttotal: 2m\tremaining: 2m 18s\n",
            "1395:\tlearn: 99.7966575\ttotal: 2m\tremaining: 2m 18s\n",
            "1396:\tlearn: 99.7945660\ttotal: 2m\tremaining: 2m 18s\n",
            "1397:\tlearn: 99.7932278\ttotal: 2m\tremaining: 2m 18s\n",
            "1398:\tlearn: 99.7889616\ttotal: 2m\tremaining: 2m 18s\n",
            "1399:\tlearn: 99.7855138\ttotal: 2m\tremaining: 2m 17s\n",
            "1400:\tlearn: 99.7740392\ttotal: 2m\tremaining: 2m 17s\n",
            "1401:\tlearn: 99.7707191\ttotal: 2m\tremaining: 2m 17s\n",
            "1402:\tlearn: 99.7666839\ttotal: 2m\tremaining: 2m 17s\n",
            "1403:\tlearn: 99.7657888\ttotal: 2m 1s\tremaining: 2m 17s\n",
            "1404:\tlearn: 99.7621160\ttotal: 2m 1s\tremaining: 2m 17s\n",
            "1405:\tlearn: 99.7604591\ttotal: 2m 1s\tremaining: 2m 17s\n",
            "1406:\tlearn: 99.7593714\ttotal: 2m 1s\tremaining: 2m 17s\n",
            "1407:\tlearn: 99.7521418\ttotal: 2m 1s\tremaining: 2m 17s\n",
            "1408:\tlearn: 99.7488710\ttotal: 2m 1s\tremaining: 2m 17s\n",
            "1409:\tlearn: 99.7468706\ttotal: 2m 1s\tremaining: 2m 17s\n",
            "1410:\tlearn: 99.7457063\ttotal: 2m 1s\tremaining: 2m 17s\n",
            "1411:\tlearn: 99.7409671\ttotal: 2m 1s\tremaining: 2m 16s\n",
            "1412:\tlearn: 99.7340211\ttotal: 2m 1s\tremaining: 2m 16s\n",
            "1413:\tlearn: 99.7328726\ttotal: 2m 1s\tremaining: 2m 16s\n",
            "1414:\tlearn: 99.7316969\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1415:\tlearn: 99.7306101\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1416:\tlearn: 99.7291368\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1417:\tlearn: 99.7243809\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1418:\tlearn: 99.7150723\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1419:\tlearn: 99.7097012\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1420:\tlearn: 99.7090226\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1421:\tlearn: 99.7085963\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1422:\tlearn: 99.7023577\ttotal: 2m 2s\tremaining: 2m 16s\n",
            "1423:\tlearn: 99.7004704\ttotal: 2m 2s\tremaining: 2m 15s\n",
            "1424:\tlearn: 99.6985907\ttotal: 2m 2s\tremaining: 2m 15s\n",
            "1425:\tlearn: 99.6958590\ttotal: 2m 2s\tremaining: 2m 15s\n",
            "1426:\tlearn: 99.6847513\ttotal: 2m 3s\tremaining: 2m 15s\n",
            "1427:\tlearn: 99.6835052\ttotal: 2m 3s\tremaining: 2m 15s\n",
            "1428:\tlearn: 99.6808859\ttotal: 2m 3s\tremaining: 2m 15s\n",
            "1429:\tlearn: 99.6782304\ttotal: 2m 3s\tremaining: 2m 15s\n",
            "1430:\tlearn: 99.6681515\ttotal: 2m 3s\tremaining: 2m 15s\n",
            "1431:\tlearn: 99.6673478\ttotal: 2m 3s\tremaining: 2m 15s\n",
            "1432:\tlearn: 99.6610609\ttotal: 2m 3s\tremaining: 2m 15s\n",
            "1433:\tlearn: 99.6599940\ttotal: 2m 3s\tremaining: 2m 15s\n",
            "1434:\tlearn: 99.6567908\ttotal: 2m 3s\tremaining: 2m 14s\n",
            "1435:\tlearn: 99.6500910\ttotal: 2m 3s\tremaining: 2m 14s\n",
            "1436:\tlearn: 99.6430462\ttotal: 2m 3s\tremaining: 2m 14s\n",
            "1437:\tlearn: 99.6381298\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1438:\tlearn: 99.6352889\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1439:\tlearn: 99.6351982\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1440:\tlearn: 99.6339769\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1441:\tlearn: 99.6242671\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1442:\tlearn: 99.6227261\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1443:\tlearn: 99.6217579\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1444:\tlearn: 99.6131622\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1445:\tlearn: 99.6119529\ttotal: 2m 4s\tremaining: 2m 14s\n",
            "1446:\tlearn: 99.6102003\ttotal: 2m 4s\tremaining: 2m 13s\n",
            "1447:\tlearn: 99.6038442\ttotal: 2m 4s\tremaining: 2m 13s\n",
            "1448:\tlearn: 99.6008243\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1449:\tlearn: 99.5937941\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1450:\tlearn: 99.5928969\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1451:\tlearn: 99.5847489\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1452:\tlearn: 99.5833609\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1453:\tlearn: 99.5807619\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1454:\tlearn: 99.5797124\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1455:\tlearn: 99.5763640\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1456:\tlearn: 99.5715637\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1457:\tlearn: 99.5630235\ttotal: 2m 5s\tremaining: 2m 13s\n",
            "1458:\tlearn: 99.5580855\ttotal: 2m 5s\tremaining: 2m 12s\n",
            "1459:\tlearn: 99.5555675\ttotal: 2m 5s\tremaining: 2m 12s\n",
            "1460:\tlearn: 99.5488211\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1461:\tlearn: 99.5429627\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1462:\tlearn: 99.5418294\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1463:\tlearn: 99.5354188\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1464:\tlearn: 99.5352762\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1465:\tlearn: 99.5345398\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1466:\tlearn: 99.5306848\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1467:\tlearn: 99.5242167\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1468:\tlearn: 99.5182903\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1469:\tlearn: 99.5078528\ttotal: 2m 6s\tremaining: 2m 12s\n",
            "1470:\tlearn: 99.5033346\ttotal: 2m 7s\tremaining: 2m 12s\n",
            "1471:\tlearn: 99.4969774\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1472:\tlearn: 99.4907155\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1473:\tlearn: 99.4869693\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1474:\tlearn: 99.4867228\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1475:\tlearn: 99.4855256\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1476:\tlearn: 99.4840001\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1477:\tlearn: 99.4824907\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1478:\tlearn: 99.4821783\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1479:\tlearn: 99.4795925\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1480:\tlearn: 99.4768174\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1481:\tlearn: 99.4757619\ttotal: 2m 7s\tremaining: 2m 11s\n",
            "1482:\tlearn: 99.4694717\ttotal: 2m 8s\tremaining: 2m 11s\n",
            "1483:\tlearn: 99.4656996\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1484:\tlearn: 99.4632334\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1485:\tlearn: 99.4592856\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1486:\tlearn: 99.4571831\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1487:\tlearn: 99.4560357\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1488:\tlearn: 99.4536441\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1489:\tlearn: 99.4509679\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1490:\tlearn: 99.4444475\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1491:\tlearn: 99.4435848\ttotal: 2m 8s\tremaining: 2m 10s\n",
            "1492:\tlearn: 99.4367748\ttotal: 2m 9s\tremaining: 2m 10s\n",
            "1493:\tlearn: 99.4344505\ttotal: 2m 9s\tremaining: 2m 10s\n",
            "1494:\tlearn: 99.4288734\ttotal: 2m 9s\tremaining: 2m 10s\n",
            "1495:\tlearn: 99.4240243\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1496:\tlearn: 99.4209084\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1497:\tlearn: 99.4196019\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1498:\tlearn: 99.4181431\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1499:\tlearn: 99.4152247\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1500:\tlearn: 99.4128055\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1501:\tlearn: 99.4028033\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1502:\tlearn: 99.4001765\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1503:\tlearn: 99.3984197\ttotal: 2m 9s\tremaining: 2m 9s\n",
            "1504:\tlearn: 99.3908045\ttotal: 2m 10s\tremaining: 2m 9s\n",
            "1505:\tlearn: 99.3873202\ttotal: 2m 10s\tremaining: 2m 9s\n",
            "1506:\tlearn: 99.3859151\ttotal: 2m 10s\tremaining: 2m 9s\n",
            "1507:\tlearn: 99.3791635\ttotal: 2m 10s\tremaining: 2m 8s\n",
            "1508:\tlearn: 99.3779443\ttotal: 2m 10s\tremaining: 2m 8s\n",
            "1509:\tlearn: 99.3777208\ttotal: 2m 10s\tremaining: 2m 8s\n",
            "1510:\tlearn: 99.3761976\ttotal: 2m 10s\tremaining: 2m 8s\n",
            "1511:\tlearn: 99.3761385\ttotal: 2m 10s\tremaining: 2m 8s\n",
            "1512:\tlearn: 99.3739462\ttotal: 2m 10s\tremaining: 2m 8s\n",
            "1513:\tlearn: 99.3671133\ttotal: 2m 10s\tremaining: 2m 8s\n",
            "1514:\tlearn: 99.3622403\ttotal: 2m 10s\tremaining: 2m 8s\n",
            "1515:\tlearn: 99.3555682\ttotal: 2m 11s\tremaining: 2m 8s\n",
            "1516:\tlearn: 99.3547720\ttotal: 2m 11s\tremaining: 2m 8s\n",
            "1517:\tlearn: 99.3520303\ttotal: 2m 11s\tremaining: 2m 8s\n",
            "1518:\tlearn: 99.3468643\ttotal: 2m 11s\tremaining: 2m 8s\n",
            "1519:\tlearn: 99.3445302\ttotal: 2m 11s\tremaining: 2m 7s\n",
            "1520:\tlearn: 99.3413029\ttotal: 2m 11s\tremaining: 2m 7s\n",
            "1521:\tlearn: 99.3370995\ttotal: 2m 11s\tremaining: 2m 7s\n",
            "1522:\tlearn: 99.3369891\ttotal: 2m 11s\tremaining: 2m 7s\n",
            "1523:\tlearn: 99.3349541\ttotal: 2m 11s\tremaining: 2m 7s\n",
            "1524:\tlearn: 99.3341192\ttotal: 2m 11s\tremaining: 2m 7s\n",
            "1525:\tlearn: 99.3276165\ttotal: 2m 11s\tremaining: 2m 7s\n",
            "1526:\tlearn: 99.3272336\ttotal: 2m 11s\tremaining: 2m 7s\n",
            "1527:\tlearn: 99.3230040\ttotal: 2m 12s\tremaining: 2m 7s\n",
            "1528:\tlearn: 99.3206756\ttotal: 2m 12s\tremaining: 2m 7s\n",
            "1529:\tlearn: 99.3175696\ttotal: 2m 12s\tremaining: 2m 7s\n",
            "1530:\tlearn: 99.3172166\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1531:\tlearn: 99.3077240\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1532:\tlearn: 99.3054004\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1533:\tlearn: 99.2992936\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1534:\tlearn: 99.2985709\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1535:\tlearn: 99.2924507\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1536:\tlearn: 99.2920080\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1537:\tlearn: 99.2907021\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1538:\tlearn: 99.2880716\ttotal: 2m 12s\tremaining: 2m 6s\n",
            "1539:\tlearn: 99.2859070\ttotal: 2m 13s\tremaining: 2m 6s\n",
            "1540:\tlearn: 99.2758411\ttotal: 2m 13s\tremaining: 2m 6s\n",
            "1541:\tlearn: 99.2731370\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1542:\tlearn: 99.2709570\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1543:\tlearn: 99.2661294\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1544:\tlearn: 99.2660495\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1545:\tlearn: 99.2655766\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1546:\tlearn: 99.2639872\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1547:\tlearn: 99.2615256\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1548:\tlearn: 99.2612913\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1549:\tlearn: 99.2541819\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1550:\tlearn: 99.2470826\ttotal: 2m 13s\tremaining: 2m 5s\n",
            "1551:\tlearn: 99.2437924\ttotal: 2m 14s\tremaining: 2m 5s\n",
            "1552:\tlearn: 99.2410158\ttotal: 2m 14s\tremaining: 2m 5s\n",
            "1553:\tlearn: 99.2361483\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1554:\tlearn: 99.2349067\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1555:\tlearn: 99.2329176\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1556:\tlearn: 99.2326938\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1557:\tlearn: 99.2252606\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1558:\tlearn: 99.2233612\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1559:\tlearn: 99.2205601\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1560:\tlearn: 99.2170369\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1561:\tlearn: 99.2076762\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1562:\tlearn: 99.2057397\ttotal: 2m 14s\tremaining: 2m 4s\n",
            "1563:\tlearn: 99.2052260\ttotal: 2m 15s\tremaining: 2m 4s\n",
            "1564:\tlearn: 99.1970839\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1565:\tlearn: 99.1966204\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1566:\tlearn: 99.1929478\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1567:\tlearn: 99.1908385\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1568:\tlearn: 99.1885755\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1569:\tlearn: 99.1842033\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1570:\tlearn: 99.1799562\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1571:\tlearn: 99.1772425\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1572:\tlearn: 99.1742523\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1573:\tlearn: 99.1718927\ttotal: 2m 15s\tremaining: 2m 3s\n",
            "1574:\tlearn: 99.1690559\ttotal: 2m 16s\tremaining: 2m 3s\n",
            "1575:\tlearn: 99.1683536\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1576:\tlearn: 99.1640318\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1577:\tlearn: 99.1621250\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1578:\tlearn: 99.1609374\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1579:\tlearn: 99.1583828\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1580:\tlearn: 99.1572467\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1581:\tlearn: 99.1514780\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1582:\tlearn: 99.1482896\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1583:\tlearn: 99.1416418\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1584:\tlearn: 99.1404508\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1585:\tlearn: 99.1352300\ttotal: 2m 16s\tremaining: 2m 2s\n",
            "1586:\tlearn: 99.1350161\ttotal: 2m 17s\tremaining: 2m 2s\n",
            "1587:\tlearn: 99.1301512\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1588:\tlearn: 99.1227050\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1589:\tlearn: 99.1184409\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1590:\tlearn: 99.1164342\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1591:\tlearn: 99.1163403\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1592:\tlearn: 99.1155873\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1593:\tlearn: 99.1139955\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1594:\tlearn: 99.1129950\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1595:\tlearn: 99.1044031\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1596:\tlearn: 99.1026205\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1597:\tlearn: 99.1025137\ttotal: 2m 17s\tremaining: 2m 1s\n",
            "1598:\tlearn: 99.0999923\ttotal: 2m 18s\tremaining: 2m\n",
            "1599:\tlearn: 99.0990910\ttotal: 2m 18s\tremaining: 2m\n",
            "1600:\tlearn: 99.0952436\ttotal: 2m 18s\tremaining: 2m\n",
            "1601:\tlearn: 99.0923857\ttotal: 2m 18s\tremaining: 2m\n",
            "1602:\tlearn: 99.0898985\ttotal: 2m 18s\tremaining: 2m\n",
            "1603:\tlearn: 99.0879298\ttotal: 2m 18s\tremaining: 2m\n",
            "1604:\tlearn: 99.0870691\ttotal: 2m 18s\tremaining: 2m\n",
            "1605:\tlearn: 99.0799670\ttotal: 2m 18s\tremaining: 2m\n",
            "1606:\tlearn: 99.0773077\ttotal: 2m 18s\tremaining: 2m\n",
            "1607:\tlearn: 99.0752953\ttotal: 2m 18s\tremaining: 2m\n",
            "1608:\tlearn: 99.0692926\ttotal: 2m 18s\tremaining: 2m\n",
            "1609:\tlearn: 99.0685095\ttotal: 2m 18s\tremaining: 2m\n",
            "1610:\tlearn: 99.0592931\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1611:\tlearn: 99.0496706\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1612:\tlearn: 99.0492319\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1613:\tlearn: 99.0458240\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1614:\tlearn: 99.0442382\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1615:\tlearn: 99.0434804\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1616:\tlearn: 99.0403126\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1617:\tlearn: 99.0393879\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1618:\tlearn: 99.0370797\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1619:\tlearn: 99.0339072\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1620:\tlearn: 99.0326432\ttotal: 2m 19s\tremaining: 1m 59s\n",
            "1621:\tlearn: 99.0320439\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1622:\tlearn: 99.0292974\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1623:\tlearn: 99.0282956\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1624:\tlearn: 99.0282657\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1625:\tlearn: 99.0254465\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1626:\tlearn: 99.0216253\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1627:\tlearn: 99.0196957\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1628:\tlearn: 99.0159068\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1629:\tlearn: 99.0144200\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1630:\tlearn: 99.0130085\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1631:\tlearn: 99.0083590\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1632:\tlearn: 99.0072187\ttotal: 2m 20s\tremaining: 1m 58s\n",
            "1633:\tlearn: 99.0048609\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1634:\tlearn: 99.0041499\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1635:\tlearn: 99.0003443\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1636:\tlearn: 98.9961842\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1637:\tlearn: 98.9919210\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1638:\tlearn: 98.9881988\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1639:\tlearn: 98.9856570\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1640:\tlearn: 98.9839257\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1641:\tlearn: 98.9741882\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1642:\tlearn: 98.9737493\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1643:\tlearn: 98.9733707\ttotal: 2m 21s\tremaining: 1m 57s\n",
            "1644:\tlearn: 98.9731822\ttotal: 2m 21s\tremaining: 1m 56s\n",
            "1645:\tlearn: 98.9716915\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1646:\tlearn: 98.9703145\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1647:\tlearn: 98.9691963\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1648:\tlearn: 98.9689410\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1649:\tlearn: 98.9659396\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1650:\tlearn: 98.9635740\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1651:\tlearn: 98.9611822\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1652:\tlearn: 98.9608340\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1653:\tlearn: 98.9544757\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1654:\tlearn: 98.9513881\ttotal: 2m 22s\tremaining: 1m 56s\n",
            "1655:\tlearn: 98.9512236\ttotal: 2m 22s\tremaining: 1m 55s\n",
            "1656:\tlearn: 98.9510752\ttotal: 2m 22s\tremaining: 1m 55s\n",
            "1657:\tlearn: 98.9494275\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1658:\tlearn: 98.9490345\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1659:\tlearn: 98.9459732\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1660:\tlearn: 98.9439859\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1661:\tlearn: 98.9374319\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1662:\tlearn: 98.9358369\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1663:\tlearn: 98.9290384\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1664:\tlearn: 98.9197592\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1665:\tlearn: 98.9175907\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1666:\tlearn: 98.9141853\ttotal: 2m 23s\tremaining: 1m 55s\n",
            "1667:\tlearn: 98.9119974\ttotal: 2m 23s\tremaining: 1m 54s\n",
            "1668:\tlearn: 98.9106044\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1669:\tlearn: 98.9091118\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1670:\tlearn: 98.9083414\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1671:\tlearn: 98.9057110\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1672:\tlearn: 98.9025683\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1673:\tlearn: 98.8968712\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1674:\tlearn: 98.8884394\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1675:\tlearn: 98.8878932\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1676:\tlearn: 98.8843128\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1677:\tlearn: 98.8723551\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1678:\tlearn: 98.8664993\ttotal: 2m 24s\tremaining: 1m 54s\n",
            "1679:\tlearn: 98.8638943\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1680:\tlearn: 98.8630721\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1681:\tlearn: 98.8581275\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1682:\tlearn: 98.8572295\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1683:\tlearn: 98.8533746\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1684:\tlearn: 98.8489889\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1685:\tlearn: 98.8476963\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1686:\tlearn: 98.8464012\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1687:\tlearn: 98.8433580\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1688:\tlearn: 98.8406772\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1689:\tlearn: 98.8386072\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1690:\tlearn: 98.8326673\ttotal: 2m 25s\tremaining: 1m 53s\n",
            "1691:\tlearn: 98.8312510\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1692:\tlearn: 98.8300018\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1693:\tlearn: 98.8276395\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1694:\tlearn: 98.8251009\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1695:\tlearn: 98.8151167\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1696:\tlearn: 98.8090567\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1697:\tlearn: 98.8071941\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1698:\tlearn: 98.8059377\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1699:\tlearn: 98.8013318\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1700:\tlearn: 98.7978577\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1701:\tlearn: 98.7964980\ttotal: 2m 26s\tremaining: 1m 52s\n",
            "1702:\tlearn: 98.7961639\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1703:\tlearn: 98.7901295\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1704:\tlearn: 98.7771477\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1705:\tlearn: 98.7727918\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1706:\tlearn: 98.7671156\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1707:\tlearn: 98.7632163\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1708:\tlearn: 98.7599340\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1709:\tlearn: 98.7586047\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1710:\tlearn: 98.7579250\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1711:\tlearn: 98.7573067\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1712:\tlearn: 98.7554525\ttotal: 2m 27s\tremaining: 1m 51s\n",
            "1713:\tlearn: 98.7531329\ttotal: 2m 28s\tremaining: 1m 51s\n",
            "1714:\tlearn: 98.7526351\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1715:\tlearn: 98.7486441\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1716:\tlearn: 98.7483139\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1717:\tlearn: 98.7439568\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1718:\tlearn: 98.7403093\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1719:\tlearn: 98.7400145\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1720:\tlearn: 98.7308985\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1721:\tlearn: 98.7269902\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1722:\tlearn: 98.7254790\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1723:\tlearn: 98.7225576\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1724:\tlearn: 98.7177952\ttotal: 2m 28s\tremaining: 1m 50s\n",
            "1725:\tlearn: 98.7152297\ttotal: 2m 29s\tremaining: 1m 50s\n",
            "1726:\tlearn: 98.7149164\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1727:\tlearn: 98.7122041\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1728:\tlearn: 98.7066758\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1729:\tlearn: 98.7055564\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1730:\tlearn: 98.7043336\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1731:\tlearn: 98.7035307\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1732:\tlearn: 98.7033467\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1733:\tlearn: 98.7027272\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1734:\tlearn: 98.6882435\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1735:\tlearn: 98.6859012\ttotal: 2m 29s\tremaining: 1m 49s\n",
            "1736:\tlearn: 98.6848878\ttotal: 2m 30s\tremaining: 1m 49s\n",
            "1737:\tlearn: 98.6804280\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1738:\tlearn: 98.6792750\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1739:\tlearn: 98.6745985\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1740:\tlearn: 98.6646667\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1741:\tlearn: 98.6624265\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1742:\tlearn: 98.6594845\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1743:\tlearn: 98.6524960\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1744:\tlearn: 98.6523243\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1745:\tlearn: 98.6512275\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1746:\tlearn: 98.6504185\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1747:\tlearn: 98.6497081\ttotal: 2m 30s\tremaining: 1m 48s\n",
            "1748:\tlearn: 98.6452483\ttotal: 2m 31s\tremaining: 1m 48s\n",
            "1749:\tlearn: 98.6421239\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1750:\tlearn: 98.6392375\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1751:\tlearn: 98.6377061\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1752:\tlearn: 98.6354421\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1753:\tlearn: 98.6332079\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1754:\tlearn: 98.6280184\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1755:\tlearn: 98.6278917\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1756:\tlearn: 98.6262311\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1757:\tlearn: 98.6238046\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1758:\tlearn: 98.6236426\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1759:\tlearn: 98.6229071\ttotal: 2m 31s\tremaining: 1m 47s\n",
            "1760:\tlearn: 98.6219210\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1761:\tlearn: 98.6182090\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1762:\tlearn: 98.6178203\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1763:\tlearn: 98.6160995\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1764:\tlearn: 98.6103956\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1765:\tlearn: 98.6024082\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1766:\tlearn: 98.5993337\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1767:\tlearn: 98.5950826\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1768:\tlearn: 98.5926472\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1769:\tlearn: 98.5920282\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1770:\tlearn: 98.5917238\ttotal: 2m 32s\tremaining: 1m 46s\n",
            "1771:\tlearn: 98.5895655\ttotal: 2m 32s\tremaining: 1m 45s\n",
            "1772:\tlearn: 98.5809385\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1773:\tlearn: 98.5789447\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1774:\tlearn: 98.5768385\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1775:\tlearn: 98.5753270\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1776:\tlearn: 98.5748869\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1777:\tlearn: 98.5744933\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1778:\tlearn: 98.5710678\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1779:\tlearn: 98.5698195\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1780:\tlearn: 98.5658598\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1781:\tlearn: 98.5645066\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1782:\tlearn: 98.5588898\ttotal: 2m 33s\tremaining: 1m 45s\n",
            "1783:\tlearn: 98.5587937\ttotal: 2m 33s\tremaining: 1m 44s\n",
            "1784:\tlearn: 98.5583297\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1785:\tlearn: 98.5569403\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1786:\tlearn: 98.5532162\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1787:\tlearn: 98.5513566\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1788:\tlearn: 98.5479788\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1789:\tlearn: 98.5471083\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1790:\tlearn: 98.5465010\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1791:\tlearn: 98.5402389\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1792:\tlearn: 98.5390090\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1793:\tlearn: 98.5381731\ttotal: 2m 34s\tremaining: 1m 44s\n",
            "1794:\tlearn: 98.5370742\ttotal: 2m 34s\tremaining: 1m 43s\n",
            "1795:\tlearn: 98.5365734\ttotal: 2m 34s\tremaining: 1m 43s\n",
            "1796:\tlearn: 98.5342440\ttotal: 2m 34s\tremaining: 1m 43s\n",
            "1797:\tlearn: 98.5310234\ttotal: 2m 35s\tremaining: 1m 43s\n",
            "1798:\tlearn: 98.5271872\ttotal: 2m 35s\tremaining: 1m 43s\n",
            "1799:\tlearn: 98.5231728\ttotal: 2m 35s\tremaining: 1m 43s\n",
            "1800:\tlearn: 98.5214737\ttotal: 2m 35s\tremaining: 1m 43s\n",
            "1801:\tlearn: 98.5167021\ttotal: 2m 35s\tremaining: 1m 43s\n",
            "1802:\tlearn: 98.5037673\ttotal: 2m 35s\tremaining: 1m 43s\n",
            "1803:\tlearn: 98.5023314\ttotal: 2m 35s\tremaining: 1m 43s\n",
            "1804:\tlearn: 98.4989262\ttotal: 2m 35s\tremaining: 1m 43s\n",
            "1805:\tlearn: 98.4975645\ttotal: 2m 35s\tremaining: 1m 42s\n",
            "1806:\tlearn: 98.4932070\ttotal: 2m 35s\tremaining: 1m 42s\n",
            "1807:\tlearn: 98.4918522\ttotal: 2m 35s\tremaining: 1m 42s\n",
            "1808:\tlearn: 98.4852184\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1809:\tlearn: 98.4838942\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1810:\tlearn: 98.4813553\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1811:\tlearn: 98.4775102\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1812:\tlearn: 98.4752968\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1813:\tlearn: 98.4725370\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1814:\tlearn: 98.4667909\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1815:\tlearn: 98.4649667\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1816:\tlearn: 98.4637533\ttotal: 2m 36s\tremaining: 1m 42s\n",
            "1817:\tlearn: 98.4623789\ttotal: 2m 36s\tremaining: 1m 41s\n",
            "1818:\tlearn: 98.4620366\ttotal: 2m 36s\tremaining: 1m 41s\n",
            "1819:\tlearn: 98.4590487\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1820:\tlearn: 98.4589399\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1821:\tlearn: 98.4583615\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1822:\tlearn: 98.4578979\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1823:\tlearn: 98.4568308\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1824:\tlearn: 98.4560928\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1825:\tlearn: 98.4533740\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1826:\tlearn: 98.4521426\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1827:\tlearn: 98.4429539\ttotal: 2m 37s\tremaining: 1m 41s\n",
            "1828:\tlearn: 98.4403067\ttotal: 2m 37s\tremaining: 1m 40s\n",
            "1829:\tlearn: 98.4388789\ttotal: 2m 37s\tremaining: 1m 40s\n",
            "1830:\tlearn: 98.4371410\ttotal: 2m 37s\tremaining: 1m 40s\n",
            "1831:\tlearn: 98.4342203\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1832:\tlearn: 98.4330417\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1833:\tlearn: 98.4310149\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1834:\tlearn: 98.4270601\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1835:\tlearn: 98.4255460\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1836:\tlearn: 98.4210135\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1837:\tlearn: 98.4142521\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1838:\tlearn: 98.4122837\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1839:\tlearn: 98.4120005\ttotal: 2m 38s\tremaining: 1m 40s\n",
            "1840:\tlearn: 98.4119124\ttotal: 2m 38s\tremaining: 1m 39s\n",
            "1841:\tlearn: 98.4094259\ttotal: 2m 38s\tremaining: 1m 39s\n",
            "1842:\tlearn: 98.4076164\ttotal: 2m 38s\tremaining: 1m 39s\n",
            "1843:\tlearn: 98.4033722\ttotal: 2m 39s\tremaining: 1m 39s\n",
            "1844:\tlearn: 98.3978072\ttotal: 2m 39s\tremaining: 1m 39s\n",
            "1845:\tlearn: 98.3939626\ttotal: 2m 39s\tremaining: 1m 39s\n",
            "1846:\tlearn: 98.3917715\ttotal: 2m 39s\tremaining: 1m 39s\n",
            "1847:\tlearn: 98.3915359\ttotal: 2m 39s\tremaining: 1m 39s\n",
            "1848:\tlearn: 98.3898189\ttotal: 2m 39s\tremaining: 1m 39s\n",
            "1849:\tlearn: 98.3882894\ttotal: 2m 39s\tremaining: 1m 39s\n",
            "1850:\tlearn: 98.3873086\ttotal: 2m 39s\tremaining: 1m 39s\n",
            "1851:\tlearn: 98.3857160\ttotal: 2m 39s\tremaining: 1m 38s\n",
            "1852:\tlearn: 98.3836022\ttotal: 2m 39s\tremaining: 1m 38s\n",
            "1853:\tlearn: 98.3769579\ttotal: 2m 39s\tremaining: 1m 38s\n",
            "1854:\tlearn: 98.3755591\ttotal: 2m 39s\tremaining: 1m 38s\n",
            "1855:\tlearn: 98.3735048\ttotal: 2m 40s\tremaining: 1m 38s\n",
            "1856:\tlearn: 98.3683013\ttotal: 2m 40s\tremaining: 1m 38s\n",
            "1857:\tlearn: 98.3635121\ttotal: 2m 40s\tremaining: 1m 38s\n",
            "1858:\tlearn: 98.3607483\ttotal: 2m 40s\tremaining: 1m 38s\n",
            "1859:\tlearn: 98.3562556\ttotal: 2m 40s\tremaining: 1m 38s\n",
            "1860:\tlearn: 98.3519399\ttotal: 2m 40s\tremaining: 1m 38s\n",
            "1861:\tlearn: 98.3456078\ttotal: 2m 40s\tremaining: 1m 38s\n",
            "1862:\tlearn: 98.3421587\ttotal: 2m 40s\tremaining: 1m 38s\n",
            "1863:\tlearn: 98.3373390\ttotal: 2m 40s\tremaining: 1m 37s\n",
            "1864:\tlearn: 98.3359328\ttotal: 2m 40s\tremaining: 1m 37s\n",
            "1865:\tlearn: 98.3346063\ttotal: 2m 40s\tremaining: 1m 37s\n",
            "1866:\tlearn: 98.3338420\ttotal: 2m 40s\tremaining: 1m 37s\n",
            "1867:\tlearn: 98.3289407\ttotal: 2m 41s\tremaining: 1m 37s\n",
            "1868:\tlearn: 98.3218447\ttotal: 2m 41s\tremaining: 1m 37s\n",
            "1869:\tlearn: 98.3206895\ttotal: 2m 41s\tremaining: 1m 37s\n",
            "1870:\tlearn: 98.3204124\ttotal: 2m 41s\tremaining: 1m 37s\n",
            "1871:\tlearn: 98.3169537\ttotal: 2m 41s\tremaining: 1m 37s\n",
            "1872:\tlearn: 98.3157494\ttotal: 2m 41s\tremaining: 1m 37s\n",
            "1873:\tlearn: 98.3147537\ttotal: 2m 41s\tremaining: 1m 37s\n",
            "1874:\tlearn: 98.3079059\ttotal: 2m 41s\tremaining: 1m 37s\n",
            "1875:\tlearn: 98.3065414\ttotal: 2m 41s\tremaining: 1m 36s\n",
            "1876:\tlearn: 98.3002896\ttotal: 2m 41s\tremaining: 1m 36s\n",
            "1877:\tlearn: 98.2986655\ttotal: 2m 41s\tremaining: 1m 36s\n",
            "1878:\tlearn: 98.2967430\ttotal: 2m 42s\tremaining: 1m 36s\n",
            "1879:\tlearn: 98.2954594\ttotal: 2m 42s\tremaining: 1m 36s\n",
            "1880:\tlearn: 98.2944960\ttotal: 2m 42s\tremaining: 1m 36s\n",
            "1881:\tlearn: 98.2924957\ttotal: 2m 42s\tremaining: 1m 36s\n",
            "1882:\tlearn: 98.2919843\ttotal: 2m 42s\tremaining: 1m 36s\n",
            "1883:\tlearn: 98.2871216\ttotal: 2m 42s\tremaining: 1m 36s\n",
            "1884:\tlearn: 98.2852742\ttotal: 2m 42s\tremaining: 1m 36s\n",
            "1885:\tlearn: 98.2850473\ttotal: 2m 42s\tremaining: 1m 36s\n",
            "1886:\tlearn: 98.2830320\ttotal: 2m 42s\tremaining: 1m 35s\n",
            "1887:\tlearn: 98.2801096\ttotal: 2m 42s\tremaining: 1m 35s\n",
            "1888:\tlearn: 98.2754330\ttotal: 2m 42s\tremaining: 1m 35s\n",
            "1889:\tlearn: 98.2749532\ttotal: 2m 42s\tremaining: 1m 35s\n",
            "1890:\tlearn: 98.2725482\ttotal: 2m 43s\tremaining: 1m 35s\n",
            "1891:\tlearn: 98.2642116\ttotal: 2m 43s\tremaining: 1m 35s\n",
            "1892:\tlearn: 98.2622658\ttotal: 2m 43s\tremaining: 1m 35s\n",
            "1893:\tlearn: 98.2604414\ttotal: 2m 43s\tremaining: 1m 35s\n",
            "1894:\tlearn: 98.2497099\ttotal: 2m 43s\tremaining: 1m 35s\n",
            "1895:\tlearn: 98.2469842\ttotal: 2m 43s\tremaining: 1m 35s\n",
            "1896:\tlearn: 98.2453164\ttotal: 2m 43s\tremaining: 1m 35s\n",
            "1897:\tlearn: 98.2448689\ttotal: 2m 43s\tremaining: 1m 34s\n",
            "1898:\tlearn: 98.2433279\ttotal: 2m 43s\tremaining: 1m 34s\n",
            "1899:\tlearn: 98.2431144\ttotal: 2m 43s\tremaining: 1m 34s\n",
            "1900:\tlearn: 98.2421708\ttotal: 2m 43s\tremaining: 1m 34s\n",
            "1901:\tlearn: 98.2383193\ttotal: 2m 43s\tremaining: 1m 34s\n",
            "1902:\tlearn: 98.2335224\ttotal: 2m 44s\tremaining: 1m 34s\n",
            "1903:\tlearn: 98.2265715\ttotal: 2m 44s\tremaining: 1m 34s\n",
            "1904:\tlearn: 98.2193270\ttotal: 2m 44s\tremaining: 1m 34s\n",
            "1905:\tlearn: 98.2085282\ttotal: 2m 44s\tremaining: 1m 34s\n",
            "1906:\tlearn: 98.2063361\ttotal: 2m 44s\tremaining: 1m 34s\n",
            "1907:\tlearn: 98.2048248\ttotal: 2m 44s\tremaining: 1m 34s\n",
            "1908:\tlearn: 98.2032856\ttotal: 2m 44s\tremaining: 1m 34s\n",
            "1909:\tlearn: 98.1980937\ttotal: 2m 44s\tremaining: 1m 33s\n",
            "1910:\tlearn: 98.1955557\ttotal: 2m 44s\tremaining: 1m 33s\n",
            "1911:\tlearn: 98.1894809\ttotal: 2m 44s\tremaining: 1m 33s\n",
            "1912:\tlearn: 98.1874176\ttotal: 2m 44s\tremaining: 1m 33s\n",
            "1913:\tlearn: 98.1795742\ttotal: 2m 45s\tremaining: 1m 33s\n",
            "1914:\tlearn: 98.1753844\ttotal: 2m 45s\tremaining: 1m 33s\n",
            "1915:\tlearn: 98.1734605\ttotal: 2m 45s\tremaining: 1m 33s\n",
            "1916:\tlearn: 98.1729191\ttotal: 2m 45s\tremaining: 1m 33s\n",
            "1917:\tlearn: 98.1721490\ttotal: 2m 45s\tremaining: 1m 33s\n",
            "1918:\tlearn: 98.1649928\ttotal: 2m 45s\tremaining: 1m 33s\n",
            "1919:\tlearn: 98.1613846\ttotal: 2m 45s\tremaining: 1m 33s\n",
            "1920:\tlearn: 98.1597256\ttotal: 2m 45s\tremaining: 1m 33s\n",
            "1921:\tlearn: 98.1525021\ttotal: 2m 45s\tremaining: 1m 32s\n",
            "1922:\tlearn: 98.1516148\ttotal: 2m 45s\tremaining: 1m 32s\n",
            "1923:\tlearn: 98.1482589\ttotal: 2m 45s\tremaining: 1m 32s\n",
            "1924:\tlearn: 98.1463934\ttotal: 2m 45s\tremaining: 1m 32s\n",
            "1925:\tlearn: 98.1443732\ttotal: 2m 46s\tremaining: 1m 32s\n",
            "1926:\tlearn: 98.1414523\ttotal: 2m 46s\tremaining: 1m 32s\n",
            "1927:\tlearn: 98.1408460\ttotal: 2m 46s\tremaining: 1m 32s\n",
            "1928:\tlearn: 98.1390150\ttotal: 2m 46s\tremaining: 1m 32s\n",
            "1929:\tlearn: 98.1370609\ttotal: 2m 46s\tremaining: 1m 32s\n",
            "1930:\tlearn: 98.1368626\ttotal: 2m 46s\tremaining: 1m 32s\n",
            "1931:\tlearn: 98.1340607\ttotal: 2m 46s\tremaining: 1m 32s\n",
            "1932:\tlearn: 98.1339562\ttotal: 2m 46s\tremaining: 1m 31s\n",
            "1933:\tlearn: 98.1295643\ttotal: 2m 46s\tremaining: 1m 31s\n",
            "1934:\tlearn: 98.1277232\ttotal: 2m 46s\tremaining: 1m 31s\n",
            "1935:\tlearn: 98.1260343\ttotal: 2m 46s\tremaining: 1m 31s\n",
            "1936:\tlearn: 98.1244847\ttotal: 2m 46s\tremaining: 1m 31s\n",
            "1937:\tlearn: 98.1201866\ttotal: 2m 47s\tremaining: 1m 31s\n",
            "1938:\tlearn: 98.1193018\ttotal: 2m 47s\tremaining: 1m 31s\n",
            "1939:\tlearn: 98.1179753\ttotal: 2m 47s\tremaining: 1m 31s\n",
            "1940:\tlearn: 98.1140242\ttotal: 2m 47s\tremaining: 1m 31s\n",
            "1941:\tlearn: 98.1117526\ttotal: 2m 47s\tremaining: 1m 31s\n",
            "1942:\tlearn: 98.1089469\ttotal: 2m 47s\tremaining: 1m 31s\n",
            "1943:\tlearn: 98.1073634\ttotal: 2m 47s\tremaining: 1m 31s\n",
            "1944:\tlearn: 98.1044780\ttotal: 2m 47s\tremaining: 1m 30s\n",
            "1945:\tlearn: 98.1002350\ttotal: 2m 47s\tremaining: 1m 30s\n",
            "1946:\tlearn: 98.0992132\ttotal: 2m 47s\tremaining: 1m 30s\n",
            "1947:\tlearn: 98.0977278\ttotal: 2m 47s\tremaining: 1m 30s\n",
            "1948:\tlearn: 98.0936959\ttotal: 2m 48s\tremaining: 1m 30s\n",
            "1949:\tlearn: 98.0915499\ttotal: 2m 48s\tremaining: 1m 30s\n",
            "1950:\tlearn: 98.0856671\ttotal: 2m 48s\tremaining: 1m 30s\n",
            "1951:\tlearn: 98.0847985\ttotal: 2m 48s\tremaining: 1m 30s\n",
            "1952:\tlearn: 98.0834065\ttotal: 2m 48s\tremaining: 1m 30s\n",
            "1953:\tlearn: 98.0822718\ttotal: 2m 48s\tremaining: 1m 30s\n",
            "1954:\tlearn: 98.0791736\ttotal: 2m 48s\tremaining: 1m 30s\n",
            "1955:\tlearn: 98.0767868\ttotal: 2m 48s\tremaining: 1m 30s\n",
            "1956:\tlearn: 98.0732423\ttotal: 2m 48s\tremaining: 1m 29s\n",
            "1957:\tlearn: 98.0703229\ttotal: 2m 48s\tremaining: 1m 29s\n",
            "1958:\tlearn: 98.0673275\ttotal: 2m 48s\tremaining: 1m 29s\n",
            "1959:\tlearn: 98.0639136\ttotal: 2m 48s\tremaining: 1m 29s\n",
            "1960:\tlearn: 98.0594221\ttotal: 2m 49s\tremaining: 1m 29s\n",
            "1961:\tlearn: 98.0566385\ttotal: 2m 49s\tremaining: 1m 29s\n",
            "1962:\tlearn: 98.0526143\ttotal: 2m 49s\tremaining: 1m 29s\n",
            "1963:\tlearn: 98.0502447\ttotal: 2m 49s\tremaining: 1m 29s\n",
            "1964:\tlearn: 98.0473251\ttotal: 2m 49s\tremaining: 1m 29s\n",
            "1965:\tlearn: 98.0431610\ttotal: 2m 49s\tremaining: 1m 29s\n",
            "1966:\tlearn: 98.0386475\ttotal: 2m 49s\tremaining: 1m 29s\n",
            "1967:\tlearn: 98.0366140\ttotal: 2m 49s\tremaining: 1m 28s\n",
            "1968:\tlearn: 98.0310452\ttotal: 2m 49s\tremaining: 1m 28s\n",
            "1969:\tlearn: 98.0259616\ttotal: 2m 49s\tremaining: 1m 28s\n",
            "1970:\tlearn: 98.0202433\ttotal: 2m 49s\tremaining: 1m 28s\n",
            "1971:\tlearn: 98.0152596\ttotal: 2m 50s\tremaining: 1m 28s\n",
            "1972:\tlearn: 98.0142787\ttotal: 2m 50s\tremaining: 1m 28s\n",
            "1973:\tlearn: 98.0120844\ttotal: 2m 50s\tremaining: 1m 28s\n",
            "1974:\tlearn: 98.0085054\ttotal: 2m 50s\tremaining: 1m 28s\n",
            "1975:\tlearn: 98.0075441\ttotal: 2m 50s\tremaining: 1m 28s\n",
            "1976:\tlearn: 98.0064334\ttotal: 2m 50s\tremaining: 1m 28s\n",
            "1977:\tlearn: 98.0050547\ttotal: 2m 50s\tremaining: 1m 28s\n",
            "1978:\tlearn: 97.9954465\ttotal: 2m 50s\tremaining: 1m 28s\n",
            "1979:\tlearn: 97.9910018\ttotal: 2m 50s\tremaining: 1m 27s\n",
            "1980:\tlearn: 97.9815021\ttotal: 2m 50s\tremaining: 1m 27s\n",
            "1981:\tlearn: 97.9792376\ttotal: 2m 50s\tremaining: 1m 27s\n",
            "1982:\tlearn: 97.9790165\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1983:\tlearn: 97.9781115\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1984:\tlearn: 97.9726945\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1985:\tlearn: 97.9715991\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1986:\tlearn: 97.9686012\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1987:\tlearn: 97.9674461\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1988:\tlearn: 97.9653413\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1989:\tlearn: 97.9542403\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1990:\tlearn: 97.9494395\ttotal: 2m 51s\tremaining: 1m 27s\n",
            "1991:\tlearn: 97.9476581\ttotal: 2m 51s\tremaining: 1m 26s\n",
            "1992:\tlearn: 97.9453818\ttotal: 2m 51s\tremaining: 1m 26s\n",
            "1993:\tlearn: 97.9422781\ttotal: 2m 51s\tremaining: 1m 26s\n",
            "1994:\tlearn: 97.9396202\ttotal: 2m 52s\tremaining: 1m 26s\n",
            "1995:\tlearn: 97.9349677\ttotal: 2m 52s\tremaining: 1m 26s\n",
            "1996:\tlearn: 97.9330703\ttotal: 2m 52s\tremaining: 1m 26s\n",
            "1997:\tlearn: 97.9316519\ttotal: 2m 52s\tremaining: 1m 26s\n",
            "1998:\tlearn: 97.9277496\ttotal: 2m 52s\tremaining: 1m 26s\n",
            "1999:\tlearn: 97.9270717\ttotal: 2m 52s\tremaining: 1m 26s\n",
            "2000:\tlearn: 97.9219060\ttotal: 2m 52s\tremaining: 1m 26s\n",
            "2001:\tlearn: 97.9175917\ttotal: 2m 52s\tremaining: 1m 26s\n",
            "2002:\tlearn: 97.9171556\ttotal: 2m 52s\tremaining: 1m 25s\n",
            "2003:\tlearn: 97.9170336\ttotal: 2m 52s\tremaining: 1m 25s\n",
            "2004:\tlearn: 97.9154182\ttotal: 2m 52s\tremaining: 1m 25s\n",
            "2005:\tlearn: 97.9139796\ttotal: 2m 52s\tremaining: 1m 25s\n",
            "2006:\tlearn: 97.9112613\ttotal: 2m 53s\tremaining: 1m 25s\n",
            "2007:\tlearn: 97.9083419\ttotal: 2m 53s\tremaining: 1m 25s\n",
            "2008:\tlearn: 97.9069104\ttotal: 2m 53s\tremaining: 1m 25s\n",
            "2009:\tlearn: 97.9058487\ttotal: 2m 53s\tremaining: 1m 25s\n",
            "2010:\tlearn: 97.8995703\ttotal: 2m 53s\tremaining: 1m 25s\n",
            "2011:\tlearn: 97.8925833\ttotal: 2m 53s\tremaining: 1m 25s\n",
            "2012:\tlearn: 97.8853312\ttotal: 2m 53s\tremaining: 1m 25s\n",
            "2013:\tlearn: 97.8817604\ttotal: 2m 53s\tremaining: 1m 25s\n",
            "2014:\tlearn: 97.8700589\ttotal: 2m 53s\tremaining: 1m 24s\n",
            "2015:\tlearn: 97.8683045\ttotal: 2m 53s\tremaining: 1m 24s\n",
            "2016:\tlearn: 97.8604763\ttotal: 2m 53s\tremaining: 1m 24s\n",
            "2017:\tlearn: 97.8578783\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2018:\tlearn: 97.8416328\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2019:\tlearn: 97.8393099\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2020:\tlearn: 97.8389096\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2021:\tlearn: 97.8336215\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2022:\tlearn: 97.8312603\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2023:\tlearn: 97.8295467\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2024:\tlearn: 97.8292687\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2025:\tlearn: 97.8235159\ttotal: 2m 54s\tremaining: 1m 24s\n",
            "2026:\tlearn: 97.8202733\ttotal: 2m 54s\tremaining: 1m 23s\n",
            "2027:\tlearn: 97.8193706\ttotal: 2m 54s\tremaining: 1m 23s\n",
            "2028:\tlearn: 97.8180079\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2029:\tlearn: 97.8164279\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2030:\tlearn: 97.8111074\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2031:\tlearn: 97.8108186\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2032:\tlearn: 97.7864768\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2033:\tlearn: 97.7801623\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2034:\tlearn: 97.7788550\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2035:\tlearn: 97.7758712\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2036:\tlearn: 97.7728110\ttotal: 2m 55s\tremaining: 1m 23s\n",
            "2037:\tlearn: 97.7700168\ttotal: 2m 55s\tremaining: 1m 22s\n",
            "2038:\tlearn: 97.7663567\ttotal: 2m 55s\tremaining: 1m 22s\n",
            "2039:\tlearn: 97.7584718\ttotal: 2m 55s\tremaining: 1m 22s\n",
            "2040:\tlearn: 97.7564551\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2041:\tlearn: 97.7510616\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2042:\tlearn: 97.7508975\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2043:\tlearn: 97.7371616\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2044:\tlearn: 97.7353556\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2045:\tlearn: 97.7225757\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2046:\tlearn: 97.7185184\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2047:\tlearn: 97.7148413\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2048:\tlearn: 97.7124549\ttotal: 2m 56s\tremaining: 1m 22s\n",
            "2049:\tlearn: 97.7115676\ttotal: 2m 56s\tremaining: 1m 21s\n",
            "2050:\tlearn: 97.7063220\ttotal: 2m 56s\tremaining: 1m 21s\n",
            "2051:\tlearn: 97.7054453\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2052:\tlearn: 97.6976854\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2053:\tlearn: 97.6853349\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2054:\tlearn: 97.6837657\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2055:\tlearn: 97.6833654\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2056:\tlearn: 97.6826914\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2057:\tlearn: 97.6816639\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2058:\tlearn: 97.6757373\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2059:\tlearn: 97.6716032\ttotal: 2m 57s\tremaining: 1m 21s\n",
            "2060:\tlearn: 97.6706201\ttotal: 2m 57s\tremaining: 1m 20s\n",
            "2061:\tlearn: 97.6689297\ttotal: 2m 57s\tremaining: 1m 20s\n",
            "2062:\tlearn: 97.6676659\ttotal: 2m 57s\tremaining: 1m 20s\n",
            "2063:\tlearn: 97.6653854\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2064:\tlearn: 97.6640832\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2065:\tlearn: 97.6633449\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2066:\tlearn: 97.6613456\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2067:\tlearn: 97.6607482\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2068:\tlearn: 97.6561047\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2069:\tlearn: 97.6559478\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2070:\tlearn: 97.6554221\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2071:\tlearn: 97.6334838\ttotal: 2m 58s\tremaining: 1m 20s\n",
            "2072:\tlearn: 97.6269389\ttotal: 2m 58s\tremaining: 1m 19s\n",
            "2073:\tlearn: 97.6264933\ttotal: 2m 58s\tremaining: 1m 19s\n",
            "2074:\tlearn: 97.6187822\ttotal: 2m 58s\tremaining: 1m 19s\n",
            "2075:\tlearn: 97.6173406\ttotal: 2m 59s\tremaining: 1m 19s\n",
            "2076:\tlearn: 97.6162950\ttotal: 2m 59s\tremaining: 1m 19s\n",
            "2077:\tlearn: 97.6145430\ttotal: 2m 59s\tremaining: 1m 19s\n",
            "2078:\tlearn: 97.6141989\ttotal: 2m 59s\tremaining: 1m 19s\n",
            "2079:\tlearn: 97.6129813\ttotal: 2m 59s\tremaining: 1m 19s\n",
            "2080:\tlearn: 97.6058085\ttotal: 2m 59s\tremaining: 1m 19s\n",
            "2081:\tlearn: 97.6004957\ttotal: 2m 59s\tremaining: 1m 19s\n",
            "2082:\tlearn: 97.5994738\ttotal: 2m 59s\tremaining: 1m 19s\n",
            "2083:\tlearn: 97.5934291\ttotal: 2m 59s\tremaining: 1m 18s\n",
            "2084:\tlearn: 97.5886145\ttotal: 2m 59s\tremaining: 1m 18s\n",
            "2085:\tlearn: 97.5884651\ttotal: 2m 59s\tremaining: 1m 18s\n",
            "2086:\tlearn: 97.5868002\ttotal: 2m 59s\tremaining: 1m 18s\n",
            "2087:\tlearn: 97.5861616\ttotal: 3m\tremaining: 1m 18s\n",
            "2088:\tlearn: 97.5855854\ttotal: 3m\tremaining: 1m 18s\n",
            "2089:\tlearn: 97.5813360\ttotal: 3m\tremaining: 1m 18s\n",
            "2090:\tlearn: 97.5809089\ttotal: 3m\tremaining: 1m 18s\n",
            "2091:\tlearn: 97.5800367\ttotal: 3m\tremaining: 1m 18s\n",
            "2092:\tlearn: 97.5795337\ttotal: 3m\tremaining: 1m 18s\n",
            "2093:\tlearn: 97.5774056\ttotal: 3m\tremaining: 1m 18s\n",
            "2094:\tlearn: 97.5714548\ttotal: 3m\tremaining: 1m 18s\n",
            "2095:\tlearn: 97.5681454\ttotal: 3m\tremaining: 1m 17s\n",
            "2096:\tlearn: 97.5675521\ttotal: 3m\tremaining: 1m 17s\n",
            "2097:\tlearn: 97.5674455\ttotal: 3m\tremaining: 1m 17s\n",
            "2098:\tlearn: 97.5655510\ttotal: 3m\tremaining: 1m 17s\n",
            "2099:\tlearn: 97.5619278\ttotal: 3m 1s\tremaining: 1m 17s\n",
            "2100:\tlearn: 97.5598508\ttotal: 3m 1s\tremaining: 1m 17s\n",
            "2101:\tlearn: 97.5581754\ttotal: 3m 1s\tremaining: 1m 17s\n",
            "2102:\tlearn: 97.5526780\ttotal: 3m 1s\tremaining: 1m 17s\n",
            "2103:\tlearn: 97.5498482\ttotal: 3m 1s\tremaining: 1m 17s\n",
            "2104:\tlearn: 97.5495360\ttotal: 3m 1s\tremaining: 1m 17s\n",
            "2105:\tlearn: 97.5438229\ttotal: 3m 1s\tremaining: 1m 17s\n",
            "2106:\tlearn: 97.5430877\ttotal: 3m 1s\tremaining: 1m 17s\n",
            "2107:\tlearn: 97.5423140\ttotal: 3m 1s\tremaining: 1m 16s\n",
            "2108:\tlearn: 97.5409285\ttotal: 3m 1s\tremaining: 1m 16s\n",
            "2109:\tlearn: 97.5385077\ttotal: 3m 1s\tremaining: 1m 16s\n",
            "2110:\tlearn: 97.5379391\ttotal: 3m 2s\tremaining: 1m 16s\n",
            "2111:\tlearn: 97.5316344\ttotal: 3m 2s\tremaining: 1m 16s\n",
            "2112:\tlearn: 97.5305278\ttotal: 3m 2s\tremaining: 1m 16s\n",
            "2113:\tlearn: 97.5236548\ttotal: 3m 2s\tremaining: 1m 16s\n",
            "2114:\tlearn: 97.5136330\ttotal: 3m 2s\tremaining: 1m 16s\n",
            "2115:\tlearn: 97.5122978\ttotal: 3m 2s\tremaining: 1m 16s\n",
            "2116:\tlearn: 97.5081959\ttotal: 3m 2s\tremaining: 1m 16s\n",
            "2117:\tlearn: 97.5049125\ttotal: 3m 2s\tremaining: 1m 16s\n",
            "2118:\tlearn: 97.5014177\ttotal: 3m 2s\tremaining: 1m 15s\n",
            "2119:\tlearn: 97.4910967\ttotal: 3m 2s\tremaining: 1m 15s\n",
            "2120:\tlearn: 97.4885871\ttotal: 3m 2s\tremaining: 1m 15s\n",
            "2121:\tlearn: 97.4866901\ttotal: 3m 2s\tremaining: 1m 15s\n",
            "2122:\tlearn: 97.4850163\ttotal: 3m 3s\tremaining: 1m 15s\n",
            "2123:\tlearn: 97.4827670\ttotal: 3m 3s\tremaining: 1m 15s\n",
            "2124:\tlearn: 97.4821810\ttotal: 3m 3s\tremaining: 1m 15s\n",
            "2125:\tlearn: 97.4797017\ttotal: 3m 3s\tremaining: 1m 15s\n",
            "2126:\tlearn: 97.4795642\ttotal: 3m 3s\tremaining: 1m 15s\n",
            "2127:\tlearn: 97.4767416\ttotal: 3m 3s\tremaining: 1m 15s\n",
            "2128:\tlearn: 97.4672198\ttotal: 3m 3s\tremaining: 1m 15s\n",
            "2129:\tlearn: 97.4656292\ttotal: 3m 3s\tremaining: 1m 15s\n",
            "2130:\tlearn: 97.4655008\ttotal: 3m 3s\tremaining: 1m 14s\n",
            "2131:\tlearn: 97.4583434\ttotal: 3m 3s\tremaining: 1m 14s\n",
            "2132:\tlearn: 97.4550232\ttotal: 3m 3s\tremaining: 1m 14s\n",
            "2133:\tlearn: 97.4520988\ttotal: 3m 4s\tremaining: 1m 14s\n",
            "2134:\tlearn: 97.4513523\ttotal: 3m 4s\tremaining: 1m 14s\n",
            "2135:\tlearn: 97.4480294\ttotal: 3m 4s\tremaining: 1m 14s\n",
            "2136:\tlearn: 97.4468327\ttotal: 3m 4s\tremaining: 1m 14s\n",
            "2137:\tlearn: 97.4373869\ttotal: 3m 4s\tremaining: 1m 14s\n",
            "2138:\tlearn: 97.4362402\ttotal: 3m 4s\tremaining: 1m 14s\n",
            "2139:\tlearn: 97.4331210\ttotal: 3m 4s\tremaining: 1m 14s\n",
            "2140:\tlearn: 97.4260830\ttotal: 3m 4s\tremaining: 1m 14s\n",
            "2141:\tlearn: 97.4204096\ttotal: 3m 4s\tremaining: 1m 13s\n",
            "2142:\tlearn: 97.4102983\ttotal: 3m 4s\tremaining: 1m 13s\n",
            "2143:\tlearn: 97.4076570\ttotal: 3m 4s\tremaining: 1m 13s\n",
            "2144:\tlearn: 97.3985366\ttotal: 3m 4s\tremaining: 1m 13s\n",
            "2145:\tlearn: 97.3968171\ttotal: 3m 5s\tremaining: 1m 13s\n",
            "2146:\tlearn: 97.3876460\ttotal: 3m 5s\tremaining: 1m 13s\n",
            "2147:\tlearn: 97.3873600\ttotal: 3m 5s\tremaining: 1m 13s\n",
            "2148:\tlearn: 97.3825369\ttotal: 3m 5s\tremaining: 1m 13s\n",
            "2149:\tlearn: 97.3809819\ttotal: 3m 5s\tremaining: 1m 13s\n",
            "2150:\tlearn: 97.3794258\ttotal: 3m 5s\tremaining: 1m 13s\n",
            "2151:\tlearn: 97.3767531\ttotal: 3m 5s\tremaining: 1m 13s\n",
            "2152:\tlearn: 97.3707821\ttotal: 3m 5s\tremaining: 1m 13s\n",
            "2153:\tlearn: 97.3704867\ttotal: 3m 5s\tremaining: 1m 12s\n",
            "2154:\tlearn: 97.3700277\ttotal: 3m 5s\tremaining: 1m 12s\n",
            "2155:\tlearn: 97.3641884\ttotal: 3m 5s\tremaining: 1m 12s\n",
            "2156:\tlearn: 97.3637670\ttotal: 3m 5s\tremaining: 1m 12s\n",
            "2157:\tlearn: 97.3539887\ttotal: 3m 6s\tremaining: 1m 12s\n",
            "2158:\tlearn: 97.3481030\ttotal: 3m 6s\tremaining: 1m 12s\n",
            "2159:\tlearn: 97.3469510\ttotal: 3m 6s\tremaining: 1m 12s\n",
            "2160:\tlearn: 97.3402105\ttotal: 3m 6s\tremaining: 1m 12s\n",
            "2161:\tlearn: 97.3392385\ttotal: 3m 6s\tremaining: 1m 12s\n",
            "2162:\tlearn: 97.3374509\ttotal: 3m 6s\tremaining: 1m 12s\n",
            "2163:\tlearn: 97.3365722\ttotal: 3m 6s\tremaining: 1m 12s\n",
            "2164:\tlearn: 97.3363853\ttotal: 3m 6s\tremaining: 1m 12s\n",
            "2165:\tlearn: 97.3323846\ttotal: 3m 6s\tremaining: 1m 11s\n",
            "2166:\tlearn: 97.3304937\ttotal: 3m 6s\tremaining: 1m 11s\n",
            "2167:\tlearn: 97.3291545\ttotal: 3m 6s\tremaining: 1m 11s\n",
            "2168:\tlearn: 97.3283686\ttotal: 3m 7s\tremaining: 1m 11s\n",
            "2169:\tlearn: 97.3272663\ttotal: 3m 7s\tremaining: 1m 11s\n",
            "2170:\tlearn: 97.3267473\ttotal: 3m 7s\tremaining: 1m 11s\n",
            "2171:\tlearn: 97.3237178\ttotal: 3m 7s\tremaining: 1m 11s\n",
            "2172:\tlearn: 97.3214108\ttotal: 3m 7s\tremaining: 1m 11s\n",
            "2173:\tlearn: 97.3174587\ttotal: 3m 7s\tremaining: 1m 11s\n",
            "2174:\tlearn: 97.3159667\ttotal: 3m 7s\tremaining: 1m 11s\n",
            "2175:\tlearn: 97.3146976\ttotal: 3m 7s\tremaining: 1m 11s\n",
            "2176:\tlearn: 97.3144619\ttotal: 3m 7s\tremaining: 1m 10s\n",
            "2177:\tlearn: 97.3100849\ttotal: 3m 7s\tremaining: 1m 10s\n",
            "2178:\tlearn: 97.3052137\ttotal: 3m 7s\tremaining: 1m 10s\n",
            "2179:\tlearn: 97.3011184\ttotal: 3m 7s\tremaining: 1m 10s\n",
            "2180:\tlearn: 97.2985299\ttotal: 3m 7s\tremaining: 1m 10s\n",
            "2181:\tlearn: 97.2963665\ttotal: 3m 8s\tremaining: 1m 10s\n",
            "2182:\tlearn: 97.2954446\ttotal: 3m 8s\tremaining: 1m 10s\n",
            "2183:\tlearn: 97.2918649\ttotal: 3m 8s\tremaining: 1m 10s\n",
            "2184:\tlearn: 97.2876407\ttotal: 3m 8s\tremaining: 1m 10s\n",
            "2185:\tlearn: 97.2858792\ttotal: 3m 8s\tremaining: 1m 10s\n",
            "2186:\tlearn: 97.2838895\ttotal: 3m 8s\tremaining: 1m 10s\n",
            "2187:\tlearn: 97.2781078\ttotal: 3m 8s\tremaining: 1m 10s\n",
            "2188:\tlearn: 97.2735364\ttotal: 3m 8s\tremaining: 1m 9s\n",
            "2189:\tlearn: 97.2713499\ttotal: 3m 8s\tremaining: 1m 9s\n",
            "2190:\tlearn: 97.2710074\ttotal: 3m 8s\tremaining: 1m 9s\n",
            "2191:\tlearn: 97.2676698\ttotal: 3m 8s\tremaining: 1m 9s\n",
            "2192:\tlearn: 97.2560429\ttotal: 3m 9s\tremaining: 1m 9s\n",
            "2193:\tlearn: 97.2543300\ttotal: 3m 9s\tremaining: 1m 9s\n",
            "2194:\tlearn: 97.2494427\ttotal: 3m 9s\tremaining: 1m 9s\n",
            "2195:\tlearn: 97.2493636\ttotal: 3m 9s\tremaining: 1m 9s\n",
            "2196:\tlearn: 97.2489947\ttotal: 3m 9s\tremaining: 1m 9s\n",
            "2197:\tlearn: 97.2482875\ttotal: 3m 9s\tremaining: 1m 9s\n",
            "2198:\tlearn: 97.2469114\ttotal: 3m 9s\tremaining: 1m 9s\n",
            "2199:\tlearn: 97.2435736\ttotal: 3m 9s\tremaining: 1m 8s\n",
            "2200:\tlearn: 97.2384901\ttotal: 3m 9s\tremaining: 1m 8s\n",
            "2201:\tlearn: 97.2319913\ttotal: 3m 9s\tremaining: 1m 8s\n",
            "2202:\tlearn: 97.2306882\ttotal: 3m 9s\tremaining: 1m 8s\n",
            "2203:\tlearn: 97.2217309\ttotal: 3m 10s\tremaining: 1m 8s\n",
            "2204:\tlearn: 97.2214876\ttotal: 3m 10s\tremaining: 1m 8s\n",
            "2205:\tlearn: 97.2106273\ttotal: 3m 10s\tremaining: 1m 8s\n",
            "2206:\tlearn: 97.2056649\ttotal: 3m 10s\tremaining: 1m 8s\n",
            "2207:\tlearn: 97.2046027\ttotal: 3m 10s\tremaining: 1m 8s\n",
            "2208:\tlearn: 97.2040600\ttotal: 3m 10s\tremaining: 1m 8s\n",
            "2209:\tlearn: 97.2026404\ttotal: 3m 10s\tremaining: 1m 8s\n",
            "2210:\tlearn: 97.1974933\ttotal: 3m 10s\tremaining: 1m 8s\n",
            "2211:\tlearn: 97.1929422\ttotal: 3m 10s\tremaining: 1m 7s\n",
            "2212:\tlearn: 97.1879693\ttotal: 3m 10s\tremaining: 1m 7s\n",
            "2213:\tlearn: 97.1840524\ttotal: 3m 10s\tremaining: 1m 7s\n",
            "2214:\tlearn: 97.1837385\ttotal: 3m 10s\tremaining: 1m 7s\n",
            "2215:\tlearn: 97.1819935\ttotal: 3m 11s\tremaining: 1m 7s\n",
            "2216:\tlearn: 97.1780328\ttotal: 3m 11s\tremaining: 1m 7s\n",
            "2217:\tlearn: 97.1774488\ttotal: 3m 11s\tremaining: 1m 7s\n",
            "2218:\tlearn: 97.1715768\ttotal: 3m 11s\tremaining: 1m 7s\n",
            "2219:\tlearn: 97.1688435\ttotal: 3m 11s\tremaining: 1m 7s\n",
            "2220:\tlearn: 97.1669035\ttotal: 3m 11s\tremaining: 1m 7s\n",
            "2221:\tlearn: 97.1647660\ttotal: 3m 11s\tremaining: 1m 7s\n",
            "2222:\tlearn: 97.1643832\ttotal: 3m 11s\tremaining: 1m 6s\n",
            "2223:\tlearn: 97.1627509\ttotal: 3m 11s\tremaining: 1m 6s\n",
            "2224:\tlearn: 97.1621377\ttotal: 3m 11s\tremaining: 1m 6s\n",
            "2225:\tlearn: 97.1604126\ttotal: 3m 11s\tremaining: 1m 6s\n",
            "2226:\tlearn: 97.1577741\ttotal: 3m 12s\tremaining: 1m 6s\n",
            "2227:\tlearn: 97.1497439\ttotal: 3m 12s\tremaining: 1m 6s\n",
            "2228:\tlearn: 97.1477906\ttotal: 3m 12s\tremaining: 1m 6s\n",
            "2229:\tlearn: 97.1436281\ttotal: 3m 12s\tremaining: 1m 6s\n",
            "2230:\tlearn: 97.1375163\ttotal: 3m 12s\tremaining: 1m 6s\n",
            "2231:\tlearn: 97.1350740\ttotal: 3m 12s\tremaining: 1m 6s\n",
            "2232:\tlearn: 97.1346281\ttotal: 3m 12s\tremaining: 1m 6s\n",
            "2233:\tlearn: 97.1310982\ttotal: 3m 12s\tremaining: 1m 6s\n",
            "2234:\tlearn: 97.1307630\ttotal: 3m 12s\tremaining: 1m 5s\n",
            "2235:\tlearn: 97.1287643\ttotal: 3m 12s\tremaining: 1m 5s\n",
            "2236:\tlearn: 97.1263997\ttotal: 3m 12s\tremaining: 1m 5s\n",
            "2237:\tlearn: 97.1217381\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2238:\tlearn: 97.1193287\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2239:\tlearn: 97.1139764\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2240:\tlearn: 97.1132945\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2241:\tlearn: 97.1124623\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2242:\tlearn: 97.1014795\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2243:\tlearn: 97.1009714\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2244:\tlearn: 97.0994943\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2245:\tlearn: 97.0949707\ttotal: 3m 13s\tremaining: 1m 5s\n",
            "2246:\tlearn: 97.0918806\ttotal: 3m 13s\tremaining: 1m 4s\n",
            "2247:\tlearn: 97.0914629\ttotal: 3m 13s\tremaining: 1m 4s\n",
            "2248:\tlearn: 97.0899444\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2249:\tlearn: 97.0861841\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2250:\tlearn: 97.0847086\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2251:\tlearn: 97.0816274\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2252:\tlearn: 97.0787924\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2253:\tlearn: 97.0769620\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2254:\tlearn: 97.0768341\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2255:\tlearn: 97.0757097\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2256:\tlearn: 97.0731670\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2257:\tlearn: 97.0715459\ttotal: 3m 14s\tremaining: 1m 4s\n",
            "2258:\tlearn: 97.0712550\ttotal: 3m 14s\tremaining: 1m 3s\n",
            "2259:\tlearn: 97.0706754\ttotal: 3m 14s\tremaining: 1m 3s\n",
            "2260:\tlearn: 97.0682878\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2261:\tlearn: 97.0673836\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2262:\tlearn: 97.0637460\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2263:\tlearn: 97.0583173\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2264:\tlearn: 97.0570549\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2265:\tlearn: 97.0560478\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2266:\tlearn: 97.0533490\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2267:\tlearn: 97.0522058\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2268:\tlearn: 97.0499878\ttotal: 3m 15s\tremaining: 1m 3s\n",
            "2269:\tlearn: 97.0470232\ttotal: 3m 15s\tremaining: 1m 2s\n",
            "2270:\tlearn: 97.0446926\ttotal: 3m 15s\tremaining: 1m 2s\n",
            "2271:\tlearn: 97.0416818\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2272:\tlearn: 97.0387837\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2273:\tlearn: 97.0382906\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2274:\tlearn: 97.0306016\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2275:\tlearn: 97.0239941\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2276:\tlearn: 97.0232388\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2277:\tlearn: 97.0153458\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2278:\tlearn: 97.0135941\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2279:\tlearn: 97.0134979\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2280:\tlearn: 97.0124883\ttotal: 3m 16s\tremaining: 1m 2s\n",
            "2281:\tlearn: 97.0043276\ttotal: 3m 16s\tremaining: 1m 1s\n",
            "2282:\tlearn: 97.0006268\ttotal: 3m 16s\tremaining: 1m 1s\n",
            "2283:\tlearn: 96.9992400\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2284:\tlearn: 96.9958915\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2285:\tlearn: 96.9956767\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2286:\tlearn: 96.9936290\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2287:\tlearn: 96.9909838\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2288:\tlearn: 96.9858244\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2289:\tlearn: 96.9797664\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2290:\tlearn: 96.9785793\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2291:\tlearn: 96.9785227\ttotal: 3m 17s\tremaining: 1m 1s\n",
            "2292:\tlearn: 96.9773924\ttotal: 3m 17s\tremaining: 1m\n",
            "2293:\tlearn: 96.9759707\ttotal: 3m 17s\tremaining: 1m\n",
            "2294:\tlearn: 96.9698611\ttotal: 3m 17s\tremaining: 1m\n",
            "2295:\tlearn: 96.9552885\ttotal: 3m 18s\tremaining: 1m\n",
            "2296:\tlearn: 96.9513429\ttotal: 3m 18s\tremaining: 1m\n",
            "2297:\tlearn: 96.9495501\ttotal: 3m 18s\tremaining: 1m\n",
            "2298:\tlearn: 96.9492955\ttotal: 3m 18s\tremaining: 1m\n",
            "2299:\tlearn: 96.9485637\ttotal: 3m 18s\tremaining: 1m\n",
            "2300:\tlearn: 96.9479944\ttotal: 3m 18s\tremaining: 1m\n",
            "2301:\tlearn: 96.9398766\ttotal: 3m 18s\tremaining: 1m\n",
            "2302:\tlearn: 96.9389956\ttotal: 3m 18s\tremaining: 1m\n",
            "2303:\tlearn: 96.9383039\ttotal: 3m 18s\tremaining: 1m\n",
            "2304:\tlearn: 96.9302955\ttotal: 3m 18s\tremaining: 59.9s\n",
            "2305:\tlearn: 96.9263393\ttotal: 3m 18s\tremaining: 59.9s\n",
            "2306:\tlearn: 96.9183815\ttotal: 3m 18s\tremaining: 59.8s\n",
            "2307:\tlearn: 96.9166665\ttotal: 3m 19s\tremaining: 59.7s\n",
            "2308:\tlearn: 96.9137627\ttotal: 3m 19s\tremaining: 59.6s\n",
            "2309:\tlearn: 96.9081809\ttotal: 3m 19s\tremaining: 59.5s\n",
            "2310:\tlearn: 96.9073993\ttotal: 3m 19s\tremaining: 59.4s\n",
            "2311:\tlearn: 96.9051026\ttotal: 3m 19s\tremaining: 59.3s\n",
            "2312:\tlearn: 96.9039578\ttotal: 3m 19s\tremaining: 59.3s\n",
            "2313:\tlearn: 96.9026305\ttotal: 3m 19s\tremaining: 59.2s\n",
            "2314:\tlearn: 96.8960336\ttotal: 3m 19s\tremaining: 59.1s\n",
            "2315:\tlearn: 96.8938799\ttotal: 3m 19s\tremaining: 59s\n",
            "2316:\tlearn: 96.8937791\ttotal: 3m 19s\tremaining: 58.9s\n",
            "2317:\tlearn: 96.8856592\ttotal: 3m 19s\tremaining: 58.8s\n",
            "2318:\tlearn: 96.8844941\ttotal: 3m 19s\tremaining: 58.7s\n",
            "2319:\tlearn: 96.8811306\ttotal: 3m 20s\tremaining: 58.6s\n",
            "2320:\tlearn: 96.8796523\ttotal: 3m 20s\tremaining: 58.6s\n",
            "2321:\tlearn: 96.8795872\ttotal: 3m 20s\tremaining: 58.5s\n",
            "2322:\tlearn: 96.8787561\ttotal: 3m 20s\tremaining: 58.4s\n",
            "2323:\tlearn: 96.8777793\ttotal: 3m 20s\tremaining: 58.3s\n",
            "2324:\tlearn: 96.8767717\ttotal: 3m 20s\tremaining: 58.2s\n",
            "2325:\tlearn: 96.8693408\ttotal: 3m 20s\tremaining: 58.1s\n",
            "2326:\tlearn: 96.8663603\ttotal: 3m 20s\tremaining: 58s\n",
            "2327:\tlearn: 96.8651409\ttotal: 3m 20s\tremaining: 57.9s\n",
            "2328:\tlearn: 96.8650668\ttotal: 3m 20s\tremaining: 57.9s\n",
            "2329:\tlearn: 96.8635462\ttotal: 3m 20s\tremaining: 57.8s\n",
            "2330:\tlearn: 96.8625998\ttotal: 3m 21s\tremaining: 57.7s\n",
            "2331:\tlearn: 96.8584300\ttotal: 3m 21s\tremaining: 57.6s\n",
            "2332:\tlearn: 96.8574422\ttotal: 3m 21s\tremaining: 57.5s\n",
            "2333:\tlearn: 96.8542168\ttotal: 3m 21s\tremaining: 57.4s\n",
            "2334:\tlearn: 96.8531747\ttotal: 3m 21s\tremaining: 57.3s\n",
            "2335:\tlearn: 96.8504516\ttotal: 3m 21s\tremaining: 57.3s\n",
            "2336:\tlearn: 96.8477308\ttotal: 3m 21s\tremaining: 57.2s\n",
            "2337:\tlearn: 96.8471142\ttotal: 3m 21s\tremaining: 57.1s\n",
            "2338:\tlearn: 96.8433500\ttotal: 3m 21s\tremaining: 57s\n",
            "2339:\tlearn: 96.8396822\ttotal: 3m 21s\tremaining: 56.9s\n",
            "2340:\tlearn: 96.8376459\ttotal: 3m 21s\tremaining: 56.8s\n",
            "2341:\tlearn: 96.8302768\ttotal: 3m 21s\tremaining: 56.7s\n",
            "2342:\tlearn: 96.8284230\ttotal: 3m 22s\tremaining: 56.6s\n",
            "2343:\tlearn: 96.8204409\ttotal: 3m 22s\tremaining: 56.6s\n",
            "2344:\tlearn: 96.8184349\ttotal: 3m 22s\tremaining: 56.5s\n",
            "2345:\tlearn: 96.8163121\ttotal: 3m 22s\tremaining: 56.4s\n",
            "2346:\tlearn: 96.8142043\ttotal: 3m 22s\tremaining: 56.3s\n",
            "2347:\tlearn: 96.8050878\ttotal: 3m 22s\tremaining: 56.2s\n",
            "2348:\tlearn: 96.8029760\ttotal: 3m 22s\tremaining: 56.1s\n",
            "2349:\tlearn: 96.7921047\ttotal: 3m 22s\tremaining: 56s\n",
            "2350:\tlearn: 96.7908425\ttotal: 3m 22s\tremaining: 56s\n",
            "2351:\tlearn: 96.7873355\ttotal: 3m 22s\tremaining: 55.9s\n",
            "2352:\tlearn: 96.7838069\ttotal: 3m 22s\tremaining: 55.8s\n",
            "2353:\tlearn: 96.7832700\ttotal: 3m 22s\tremaining: 55.7s\n",
            "2354:\tlearn: 96.7828782\ttotal: 3m 23s\tremaining: 55.6s\n",
            "2355:\tlearn: 96.7824063\ttotal: 3m 23s\tremaining: 55.5s\n",
            "2356:\tlearn: 96.7820710\ttotal: 3m 23s\tremaining: 55.4s\n",
            "2357:\tlearn: 96.7806120\ttotal: 3m 23s\tremaining: 55.3s\n",
            "2358:\tlearn: 96.7776883\ttotal: 3m 23s\tremaining: 55.3s\n",
            "2359:\tlearn: 96.7764343\ttotal: 3m 23s\tremaining: 55.2s\n",
            "2360:\tlearn: 96.7737614\ttotal: 3m 23s\tremaining: 55.1s\n",
            "2361:\tlearn: 96.7683488\ttotal: 3m 23s\tremaining: 55s\n",
            "2362:\tlearn: 96.7675344\ttotal: 3m 23s\tremaining: 54.9s\n",
            "2363:\tlearn: 96.7672445\ttotal: 3m 23s\tremaining: 54.8s\n",
            "2364:\tlearn: 96.7672185\ttotal: 3m 23s\tremaining: 54.7s\n",
            "2365:\tlearn: 96.7658845\ttotal: 3m 23s\tremaining: 54.7s\n",
            "2366:\tlearn: 96.7631314\ttotal: 3m 24s\tremaining: 54.6s\n",
            "2367:\tlearn: 96.7600994\ttotal: 3m 24s\tremaining: 54.5s\n",
            "2368:\tlearn: 96.7546383\ttotal: 3m 24s\tremaining: 54.4s\n",
            "2369:\tlearn: 96.7530230\ttotal: 3m 24s\tremaining: 54.3s\n",
            "2370:\tlearn: 96.7516208\ttotal: 3m 24s\tremaining: 54.2s\n",
            "2371:\tlearn: 96.7500000\ttotal: 3m 24s\tremaining: 54.1s\n",
            "2372:\tlearn: 96.7473468\ttotal: 3m 24s\tremaining: 54s\n",
            "2373:\tlearn: 96.7425377\ttotal: 3m 24s\tremaining: 54s\n",
            "2374:\tlearn: 96.7406318\ttotal: 3m 24s\tremaining: 53.9s\n",
            "2375:\tlearn: 96.7397051\ttotal: 3m 24s\tremaining: 53.8s\n",
            "2376:\tlearn: 96.7305700\ttotal: 3m 24s\tremaining: 53.7s\n",
            "2377:\tlearn: 96.7278972\ttotal: 3m 24s\tremaining: 53.6s\n",
            "2378:\tlearn: 96.7273974\ttotal: 3m 25s\tremaining: 53.5s\n",
            "2379:\tlearn: 96.7224187\ttotal: 3m 25s\tremaining: 53.4s\n",
            "2380:\tlearn: 96.7209416\ttotal: 3m 25s\tremaining: 53.4s\n",
            "2381:\tlearn: 96.7118816\ttotal: 3m 25s\tremaining: 53.3s\n",
            "2382:\tlearn: 96.7104624\ttotal: 3m 25s\tremaining: 53.2s\n",
            "2383:\tlearn: 96.7067473\ttotal: 3m 25s\tremaining: 53.1s\n",
            "2384:\tlearn: 96.7047518\ttotal: 3m 25s\tremaining: 53s\n",
            "2385:\tlearn: 96.6990801\ttotal: 3m 25s\tremaining: 52.9s\n",
            "2386:\tlearn: 96.6972647\ttotal: 3m 25s\tremaining: 52.8s\n",
            "2387:\tlearn: 96.6925485\ttotal: 3m 25s\tremaining: 52.8s\n",
            "2388:\tlearn: 96.6859321\ttotal: 3m 25s\tremaining: 52.7s\n",
            "2389:\tlearn: 96.6819136\ttotal: 3m 26s\tremaining: 52.6s\n",
            "2390:\tlearn: 96.6809431\ttotal: 3m 26s\tremaining: 52.5s\n",
            "2391:\tlearn: 96.6802062\ttotal: 3m 26s\tremaining: 52.4s\n",
            "2392:\tlearn: 96.6797546\ttotal: 3m 26s\tremaining: 52.3s\n",
            "2393:\tlearn: 96.6784824\ttotal: 3m 26s\tremaining: 52.2s\n",
            "2394:\tlearn: 96.6730838\ttotal: 3m 26s\tremaining: 52.2s\n",
            "2395:\tlearn: 96.6723405\ttotal: 3m 26s\tremaining: 52.1s\n",
            "2396:\tlearn: 96.6702068\ttotal: 3m 26s\tremaining: 52s\n",
            "2397:\tlearn: 96.6642839\ttotal: 3m 26s\tremaining: 51.9s\n",
            "2398:\tlearn: 96.6588427\ttotal: 3m 26s\tremaining: 51.8s\n",
            "2399:\tlearn: 96.6581955\ttotal: 3m 26s\tremaining: 51.7s\n",
            "2400:\tlearn: 96.6539174\ttotal: 3m 27s\tremaining: 51.6s\n",
            "2401:\tlearn: 96.6501455\ttotal: 3m 27s\tremaining: 51.6s\n",
            "2402:\tlearn: 96.6481136\ttotal: 3m 27s\tremaining: 51.5s\n",
            "2403:\tlearn: 96.6465174\ttotal: 3m 27s\tremaining: 51.4s\n",
            "2404:\tlearn: 96.6428381\ttotal: 3m 27s\tremaining: 51.3s\n",
            "2405:\tlearn: 96.6411722\ttotal: 3m 27s\tremaining: 51.2s\n",
            "2406:\tlearn: 96.6359667\ttotal: 3m 27s\tremaining: 51.1s\n",
            "2407:\tlearn: 96.6339021\ttotal: 3m 27s\tremaining: 51s\n",
            "2408:\tlearn: 96.6336883\ttotal: 3m 27s\tremaining: 51s\n",
            "2409:\tlearn: 96.6328138\ttotal: 3m 27s\tremaining: 50.9s\n",
            "2410:\tlearn: 96.6306514\ttotal: 3m 27s\tremaining: 50.8s\n",
            "2411:\tlearn: 96.6305900\ttotal: 3m 27s\tremaining: 50.7s\n",
            "2412:\tlearn: 96.6292636\ttotal: 3m 28s\tremaining: 50.6s\n",
            "2413:\tlearn: 96.6273260\ttotal: 3m 28s\tremaining: 50.5s\n",
            "2414:\tlearn: 96.6244521\ttotal: 3m 28s\tremaining: 50.4s\n",
            "2415:\tlearn: 96.6228449\ttotal: 3m 28s\tremaining: 50.4s\n",
            "2416:\tlearn: 96.6218696\ttotal: 3m 28s\tremaining: 50.3s\n",
            "2417:\tlearn: 96.6187501\ttotal: 3m 28s\tremaining: 50.2s\n",
            "2418:\tlearn: 96.6175260\ttotal: 3m 28s\tremaining: 50.1s\n",
            "2419:\tlearn: 96.6166764\ttotal: 3m 28s\tremaining: 50s\n",
            "2420:\tlearn: 96.6164634\ttotal: 3m 28s\tremaining: 49.9s\n",
            "2421:\tlearn: 96.6153900\ttotal: 3m 28s\tremaining: 49.8s\n",
            "2422:\tlearn: 96.6149859\ttotal: 3m 28s\tremaining: 49.8s\n",
            "2423:\tlearn: 96.6128807\ttotal: 3m 29s\tremaining: 49.7s\n",
            "2424:\tlearn: 96.5990219\ttotal: 3m 29s\tremaining: 49.6s\n",
            "2425:\tlearn: 96.5932311\ttotal: 3m 29s\tremaining: 49.5s\n",
            "2426:\tlearn: 96.5910949\ttotal: 3m 29s\tremaining: 49.4s\n",
            "2427:\tlearn: 96.5872037\ttotal: 3m 29s\tremaining: 49.3s\n",
            "2428:\tlearn: 96.5863614\ttotal: 3m 29s\tremaining: 49.2s\n",
            "2429:\tlearn: 96.5818878\ttotal: 3m 29s\tremaining: 49.2s\n",
            "2430:\tlearn: 96.5815298\ttotal: 3m 29s\tremaining: 49.1s\n",
            "2431:\tlearn: 96.5814535\ttotal: 3m 29s\tremaining: 49s\n",
            "2432:\tlearn: 96.5798012\ttotal: 3m 29s\tremaining: 48.9s\n",
            "2433:\tlearn: 96.5760922\ttotal: 3m 29s\tremaining: 48.8s\n",
            "2434:\tlearn: 96.5720277\ttotal: 3m 30s\tremaining: 48.7s\n",
            "2435:\tlearn: 96.5715770\ttotal: 3m 30s\tremaining: 48.6s\n",
            "2436:\tlearn: 96.5681791\ttotal: 3m 30s\tremaining: 48.6s\n",
            "2437:\tlearn: 96.5670901\ttotal: 3m 30s\tremaining: 48.5s\n",
            "2438:\tlearn: 96.5665185\ttotal: 3m 30s\tremaining: 48.4s\n",
            "2439:\tlearn: 96.5604606\ttotal: 3m 30s\tremaining: 48.3s\n",
            "2440:\tlearn: 96.5586349\ttotal: 3m 30s\tremaining: 48.2s\n",
            "2441:\tlearn: 96.5558272\ttotal: 3m 30s\tremaining: 48.1s\n",
            "2442:\tlearn: 96.5549447\ttotal: 3m 30s\tremaining: 48s\n",
            "2443:\tlearn: 96.5514122\ttotal: 3m 30s\tremaining: 48s\n",
            "2444:\tlearn: 96.5500411\ttotal: 3m 30s\tremaining: 47.9s\n",
            "2445:\tlearn: 96.5496685\ttotal: 3m 30s\tremaining: 47.8s\n",
            "2446:\tlearn: 96.5473016\ttotal: 3m 31s\tremaining: 47.7s\n",
            "2447:\tlearn: 96.5437176\ttotal: 3m 31s\tremaining: 47.6s\n",
            "2448:\tlearn: 96.5433379\ttotal: 3m 31s\tremaining: 47.5s\n",
            "2449:\tlearn: 96.5415766\ttotal: 3m 31s\tremaining: 47.4s\n",
            "2450:\tlearn: 96.5412973\ttotal: 3m 31s\tremaining: 47.4s\n",
            "2451:\tlearn: 96.5409329\ttotal: 3m 31s\tremaining: 47.3s\n",
            "2452:\tlearn: 96.5394908\ttotal: 3m 31s\tremaining: 47.2s\n",
            "2453:\tlearn: 96.5347685\ttotal: 3m 31s\tremaining: 47.1s\n",
            "2454:\tlearn: 96.5344937\ttotal: 3m 31s\tremaining: 47s\n",
            "2455:\tlearn: 96.5239995\ttotal: 3m 31s\tremaining: 46.9s\n",
            "2456:\tlearn: 96.5196999\ttotal: 3m 31s\tremaining: 46.8s\n",
            "2457:\tlearn: 96.5180886\ttotal: 3m 31s\tremaining: 46.7s\n",
            "2458:\tlearn: 96.5145904\ttotal: 3m 32s\tremaining: 46.6s\n",
            "2459:\tlearn: 96.5137868\ttotal: 3m 32s\tremaining: 46.6s\n",
            "2460:\tlearn: 96.5132542\ttotal: 3m 32s\tremaining: 46.5s\n",
            "2461:\tlearn: 96.5124661\ttotal: 3m 32s\tremaining: 46.4s\n",
            "2462:\tlearn: 96.5114911\ttotal: 3m 32s\tremaining: 46.3s\n",
            "2463:\tlearn: 96.5078565\ttotal: 3m 32s\tremaining: 46.2s\n",
            "2464:\tlearn: 96.5073636\ttotal: 3m 32s\tremaining: 46.1s\n",
            "2465:\tlearn: 96.5065192\ttotal: 3m 32s\tremaining: 46s\n",
            "2466:\tlearn: 96.5057863\ttotal: 3m 32s\tremaining: 46s\n",
            "2467:\tlearn: 96.5033440\ttotal: 3m 32s\tremaining: 45.9s\n",
            "2468:\tlearn: 96.5017913\ttotal: 3m 32s\tremaining: 45.8s\n",
            "2469:\tlearn: 96.5015020\ttotal: 3m 32s\tremaining: 45.7s\n",
            "2470:\tlearn: 96.5013546\ttotal: 3m 33s\tremaining: 45.6s\n",
            "2471:\tlearn: 96.4985961\ttotal: 3m 33s\tremaining: 45.5s\n",
            "2472:\tlearn: 96.4985283\ttotal: 3m 33s\tremaining: 45.4s\n",
            "2473:\tlearn: 96.4970592\ttotal: 3m 33s\tremaining: 45.4s\n",
            "2474:\tlearn: 96.4956780\ttotal: 3m 33s\tremaining: 45.3s\n",
            "2475:\tlearn: 96.4922543\ttotal: 3m 33s\tremaining: 45.2s\n",
            "2476:\tlearn: 96.4898507\ttotal: 3m 33s\tremaining: 45.1s\n",
            "2477:\tlearn: 96.4897695\ttotal: 3m 33s\tremaining: 45s\n",
            "2478:\tlearn: 96.4876173\ttotal: 3m 33s\tremaining: 44.9s\n",
            "2479:\tlearn: 96.4872294\ttotal: 3m 33s\tremaining: 44.8s\n",
            "2480:\tlearn: 96.4865823\ttotal: 3m 33s\tremaining: 44.8s\n",
            "2481:\tlearn: 96.4861468\ttotal: 3m 34s\tremaining: 44.7s\n",
            "2482:\tlearn: 96.4828087\ttotal: 3m 34s\tremaining: 44.6s\n",
            "2483:\tlearn: 96.4806197\ttotal: 3m 34s\tremaining: 44.5s\n",
            "2484:\tlearn: 96.4793551\ttotal: 3m 34s\tremaining: 44.4s\n",
            "2485:\tlearn: 96.4791169\ttotal: 3m 34s\tremaining: 44.3s\n",
            "2486:\tlearn: 96.4745057\ttotal: 3m 34s\tremaining: 44.2s\n",
            "2487:\tlearn: 96.4704408\ttotal: 3m 34s\tremaining: 44.1s\n",
            "2488:\tlearn: 96.4681101\ttotal: 3m 34s\tremaining: 44.1s\n",
            "2489:\tlearn: 96.4652155\ttotal: 3m 34s\tremaining: 44s\n",
            "2490:\tlearn: 96.4628848\ttotal: 3m 34s\tremaining: 43.9s\n",
            "2491:\tlearn: 96.4611157\ttotal: 3m 34s\tremaining: 43.8s\n",
            "2492:\tlearn: 96.4564827\ttotal: 3m 34s\tremaining: 43.7s\n",
            "2493:\tlearn: 96.4558107\ttotal: 3m 35s\tremaining: 43.6s\n",
            "2494:\tlearn: 96.4540739\ttotal: 3m 35s\tremaining: 43.5s\n",
            "2495:\tlearn: 96.4536736\ttotal: 3m 35s\tremaining: 43.5s\n",
            "2496:\tlearn: 96.4532366\ttotal: 3m 35s\tremaining: 43.4s\n",
            "2497:\tlearn: 96.4519852\ttotal: 3m 35s\tremaining: 43.3s\n",
            "2498:\tlearn: 96.4482648\ttotal: 3m 35s\tremaining: 43.2s\n",
            "2499:\tlearn: 96.4467808\ttotal: 3m 35s\tremaining: 43.1s\n",
            "2500:\tlearn: 96.4445037\ttotal: 3m 35s\tremaining: 43s\n",
            "2501:\tlearn: 96.4418879\ttotal: 3m 35s\tremaining: 42.9s\n",
            "2502:\tlearn: 96.4407267\ttotal: 3m 35s\tremaining: 42.9s\n",
            "2503:\tlearn: 96.4404192\ttotal: 3m 35s\tremaining: 42.8s\n",
            "2504:\tlearn: 96.4366759\ttotal: 3m 36s\tremaining: 42.7s\n",
            "2505:\tlearn: 96.4334040\ttotal: 3m 36s\tremaining: 42.6s\n",
            "2506:\tlearn: 96.4300837\ttotal: 3m 36s\tremaining: 42.5s\n",
            "2507:\tlearn: 96.4269087\ttotal: 3m 36s\tremaining: 42.4s\n",
            "2508:\tlearn: 96.4255290\ttotal: 3m 36s\tremaining: 42.3s\n",
            "2509:\tlearn: 96.4246616\ttotal: 3m 36s\tremaining: 42.2s\n",
            "2510:\tlearn: 96.4220103\ttotal: 3m 36s\tremaining: 42.2s\n",
            "2511:\tlearn: 96.4207094\ttotal: 3m 36s\tremaining: 42.1s\n",
            "2512:\tlearn: 96.4196921\ttotal: 3m 36s\tremaining: 42s\n",
            "2513:\tlearn: 96.4187210\ttotal: 3m 36s\tremaining: 41.9s\n",
            "2514:\tlearn: 96.4178811\ttotal: 3m 36s\tremaining: 41.8s\n",
            "2515:\tlearn: 96.4167140\ttotal: 3m 36s\tremaining: 41.7s\n",
            "2516:\tlearn: 96.4140413\ttotal: 3m 37s\tremaining: 41.6s\n",
            "2517:\tlearn: 96.4090260\ttotal: 3m 37s\tremaining: 41.6s\n",
            "2518:\tlearn: 96.4065749\ttotal: 3m 37s\tremaining: 41.5s\n",
            "2519:\tlearn: 96.4015507\ttotal: 3m 37s\tremaining: 41.4s\n",
            "2520:\tlearn: 96.3993967\ttotal: 3m 37s\tremaining: 41.3s\n",
            "2521:\tlearn: 96.3941462\ttotal: 3m 37s\tremaining: 41.2s\n",
            "2522:\tlearn: 96.3937399\ttotal: 3m 37s\tremaining: 41.1s\n",
            "2523:\tlearn: 96.3930751\ttotal: 3m 37s\tremaining: 41s\n",
            "2524:\tlearn: 96.3891519\ttotal: 3m 37s\tremaining: 41s\n",
            "2525:\tlearn: 96.3836490\ttotal: 3m 37s\tremaining: 40.9s\n",
            "2526:\tlearn: 96.3836270\ttotal: 3m 37s\tremaining: 40.8s\n",
            "2527:\tlearn: 96.3782251\ttotal: 3m 38s\tremaining: 40.7s\n",
            "2528:\tlearn: 96.3764798\ttotal: 3m 38s\tremaining: 40.6s\n",
            "2529:\tlearn: 96.3747121\ttotal: 3m 38s\tremaining: 40.5s\n",
            "2530:\tlearn: 96.3732290\ttotal: 3m 38s\tremaining: 40.4s\n",
            "2531:\tlearn: 96.3682126\ttotal: 3m 38s\tremaining: 40.4s\n",
            "2532:\tlearn: 96.3679125\ttotal: 3m 38s\tremaining: 40.3s\n",
            "2533:\tlearn: 96.3612023\ttotal: 3m 38s\tremaining: 40.2s\n",
            "2534:\tlearn: 96.3599839\ttotal: 3m 38s\tremaining: 40.1s\n",
            "2535:\tlearn: 96.3573140\ttotal: 3m 38s\tremaining: 40s\n",
            "2536:\tlearn: 96.3540807\ttotal: 3m 38s\tremaining: 39.9s\n",
            "2537:\tlearn: 96.3540594\ttotal: 3m 38s\tremaining: 39.9s\n",
            "2538:\tlearn: 96.3530207\ttotal: 3m 39s\tremaining: 39.8s\n",
            "2539:\tlearn: 96.3516498\ttotal: 3m 39s\tremaining: 39.7s\n",
            "2540:\tlearn: 96.3508271\ttotal: 3m 39s\tremaining: 39.6s\n",
            "2541:\tlearn: 96.3497030\ttotal: 3m 39s\tremaining: 39.5s\n",
            "2542:\tlearn: 96.3487082\ttotal: 3m 39s\tremaining: 39.4s\n",
            "2543:\tlearn: 96.3465055\ttotal: 3m 39s\tremaining: 39.3s\n",
            "2544:\tlearn: 96.3429531\ttotal: 3m 39s\tremaining: 39.2s\n",
            "2545:\tlearn: 96.3393508\ttotal: 3m 39s\tremaining: 39.2s\n",
            "2546:\tlearn: 96.3377223\ttotal: 3m 39s\tremaining: 39.1s\n",
            "2547:\tlearn: 96.3373319\ttotal: 3m 39s\tremaining: 39s\n",
            "2548:\tlearn: 96.3295427\ttotal: 3m 39s\tremaining: 38.9s\n",
            "2549:\tlearn: 96.3226542\ttotal: 3m 39s\tremaining: 38.8s\n",
            "2550:\tlearn: 96.3199954\ttotal: 3m 40s\tremaining: 38.7s\n",
            "2551:\tlearn: 96.3184897\ttotal: 3m 40s\tremaining: 38.6s\n",
            "2552:\tlearn: 96.3150181\ttotal: 3m 40s\tremaining: 38.6s\n",
            "2553:\tlearn: 96.3116419\ttotal: 3m 40s\tremaining: 38.5s\n",
            "2554:\tlearn: 96.3111787\ttotal: 3m 40s\tremaining: 38.4s\n",
            "2555:\tlearn: 96.3076493\ttotal: 3m 40s\tremaining: 38.3s\n",
            "2556:\tlearn: 96.3061982\ttotal: 3m 40s\tremaining: 38.2s\n",
            "2557:\tlearn: 96.2985458\ttotal: 3m 40s\tremaining: 38.1s\n",
            "2558:\tlearn: 96.2958515\ttotal: 3m 40s\tremaining: 38s\n",
            "2559:\tlearn: 96.2955698\ttotal: 3m 40s\tremaining: 38s\n",
            "2560:\tlearn: 96.2926586\ttotal: 3m 40s\tremaining: 37.9s\n",
            "2561:\tlearn: 96.2859999\ttotal: 3m 41s\tremaining: 37.8s\n",
            "2562:\tlearn: 96.2837176\ttotal: 3m 41s\tremaining: 37.7s\n",
            "2563:\tlearn: 96.2823593\ttotal: 3m 41s\tremaining: 37.6s\n",
            "2564:\tlearn: 96.2808093\ttotal: 3m 41s\tremaining: 37.5s\n",
            "2565:\tlearn: 96.2725359\ttotal: 3m 41s\tremaining: 37.4s\n",
            "2566:\tlearn: 96.2690886\ttotal: 3m 41s\tremaining: 37.4s\n",
            "2567:\tlearn: 96.2681183\ttotal: 3m 41s\tremaining: 37.3s\n",
            "2568:\tlearn: 96.2679296\ttotal: 3m 41s\tremaining: 37.2s\n",
            "2569:\tlearn: 96.2670494\ttotal: 3m 41s\tremaining: 37.1s\n",
            "2570:\tlearn: 96.2626400\ttotal: 3m 41s\tremaining: 37s\n",
            "2571:\tlearn: 96.2579683\ttotal: 3m 41s\tremaining: 36.9s\n",
            "2572:\tlearn: 96.2575243\ttotal: 3m 41s\tremaining: 36.8s\n",
            "2573:\tlearn: 96.2575022\ttotal: 3m 42s\tremaining: 36.7s\n",
            "2574:\tlearn: 96.2549738\ttotal: 3m 42s\tremaining: 36.7s\n",
            "2575:\tlearn: 96.2532196\ttotal: 3m 42s\tremaining: 36.6s\n",
            "2576:\tlearn: 96.2528347\ttotal: 3m 42s\tremaining: 36.5s\n",
            "2577:\tlearn: 96.2522338\ttotal: 3m 42s\tremaining: 36.4s\n",
            "2578:\tlearn: 96.2507054\ttotal: 3m 42s\tremaining: 36.3s\n",
            "2579:\tlearn: 96.2423713\ttotal: 3m 42s\tremaining: 36.2s\n",
            "2580:\tlearn: 96.2409894\ttotal: 3m 42s\tremaining: 36.1s\n",
            "2581:\tlearn: 96.2379482\ttotal: 3m 42s\tremaining: 36.1s\n",
            "2582:\tlearn: 96.2341120\ttotal: 3m 42s\tremaining: 36s\n",
            "2583:\tlearn: 96.2328284\ttotal: 3m 42s\tremaining: 35.9s\n",
            "2584:\tlearn: 96.2322679\ttotal: 3m 43s\tremaining: 35.8s\n",
            "2585:\tlearn: 96.2274339\ttotal: 3m 43s\tremaining: 35.7s\n",
            "2586:\tlearn: 96.2267805\ttotal: 3m 43s\tremaining: 35.6s\n",
            "2587:\tlearn: 96.2257258\ttotal: 3m 43s\tremaining: 35.5s\n",
            "2588:\tlearn: 96.2246391\ttotal: 3m 43s\tremaining: 35.5s\n",
            "2589:\tlearn: 96.2218723\ttotal: 3m 43s\tremaining: 35.4s\n",
            "2590:\tlearn: 96.2200705\ttotal: 3m 43s\tremaining: 35.3s\n",
            "2591:\tlearn: 96.2194730\ttotal: 3m 43s\tremaining: 35.2s\n",
            "2592:\tlearn: 96.2184270\ttotal: 3m 43s\tremaining: 35.1s\n",
            "2593:\tlearn: 96.2181964\ttotal: 3m 43s\tremaining: 35s\n",
            "2594:\tlearn: 96.2151870\ttotal: 3m 43s\tremaining: 34.9s\n",
            "2595:\tlearn: 96.2117639\ttotal: 3m 43s\tremaining: 34.9s\n",
            "2596:\tlearn: 96.2105779\ttotal: 3m 44s\tremaining: 34.8s\n",
            "2597:\tlearn: 96.2073175\ttotal: 3m 44s\tremaining: 34.7s\n",
            "2598:\tlearn: 96.2069705\ttotal: 3m 44s\tremaining: 34.6s\n",
            "2599:\tlearn: 96.2056735\ttotal: 3m 44s\tremaining: 34.5s\n",
            "2600:\tlearn: 96.2039945\ttotal: 3m 44s\tremaining: 34.4s\n",
            "2601:\tlearn: 96.2038963\ttotal: 3m 44s\tremaining: 34.3s\n",
            "2602:\tlearn: 96.2001767\ttotal: 3m 44s\tremaining: 34.3s\n",
            "2603:\tlearn: 96.1980914\ttotal: 3m 44s\tremaining: 34.2s\n",
            "2604:\tlearn: 96.1920025\ttotal: 3m 44s\tremaining: 34.1s\n",
            "2605:\tlearn: 96.1904302\ttotal: 3m 44s\tremaining: 34s\n",
            "2606:\tlearn: 96.1878114\ttotal: 3m 44s\tremaining: 33.9s\n",
            "2607:\tlearn: 96.1869297\ttotal: 3m 45s\tremaining: 33.8s\n",
            "2608:\tlearn: 96.1853012\ttotal: 3m 45s\tremaining: 33.7s\n",
            "2609:\tlearn: 96.1845649\ttotal: 3m 45s\tremaining: 33.7s\n",
            "2610:\tlearn: 96.1827581\ttotal: 3m 45s\tremaining: 33.6s\n",
            "2611:\tlearn: 96.1689864\ttotal: 3m 45s\tremaining: 33.5s\n",
            "2612:\tlearn: 96.1622895\ttotal: 3m 45s\tremaining: 33.4s\n",
            "2613:\tlearn: 96.1567965\ttotal: 3m 45s\tremaining: 33.3s\n",
            "2614:\tlearn: 96.1543297\ttotal: 3m 45s\tremaining: 33.2s\n",
            "2615:\tlearn: 96.1519601\ttotal: 3m 45s\tremaining: 33.1s\n",
            "2616:\tlearn: 96.1473353\ttotal: 3m 45s\tremaining: 33.1s\n",
            "2617:\tlearn: 96.1435781\ttotal: 3m 45s\tremaining: 33s\n",
            "2618:\tlearn: 96.1401702\ttotal: 3m 46s\tremaining: 32.9s\n",
            "2619:\tlearn: 96.1398695\ttotal: 3m 46s\tremaining: 32.8s\n",
            "2620:\tlearn: 96.1371680\ttotal: 3m 46s\tremaining: 32.7s\n",
            "2621:\tlearn: 96.1345997\ttotal: 3m 46s\tremaining: 32.6s\n",
            "2622:\tlearn: 96.1339158\ttotal: 3m 46s\tremaining: 32.5s\n",
            "2623:\tlearn: 96.1335364\ttotal: 3m 46s\tremaining: 32.5s\n",
            "2624:\tlearn: 96.1333332\ttotal: 3m 46s\tremaining: 32.4s\n",
            "2625:\tlearn: 96.1316345\ttotal: 3m 46s\tremaining: 32.3s\n",
            "2626:\tlearn: 96.1312341\ttotal: 3m 46s\tremaining: 32.2s\n",
            "2627:\tlearn: 96.1299096\ttotal: 3m 46s\tremaining: 32.1s\n",
            "2628:\tlearn: 96.1292260\ttotal: 3m 46s\tremaining: 32s\n",
            "2629:\tlearn: 96.1276302\ttotal: 3m 47s\tremaining: 31.9s\n",
            "2630:\tlearn: 96.1253528\ttotal: 3m 47s\tremaining: 31.9s\n",
            "2631:\tlearn: 96.1221781\ttotal: 3m 47s\tremaining: 31.8s\n",
            "2632:\tlearn: 96.1208616\ttotal: 3m 47s\tremaining: 31.7s\n",
            "2633:\tlearn: 96.1198634\ttotal: 3m 47s\tremaining: 31.6s\n",
            "2634:\tlearn: 96.1166498\ttotal: 3m 47s\tremaining: 31.5s\n",
            "2635:\tlearn: 96.1125545\ttotal: 3m 47s\tremaining: 31.4s\n",
            "2636:\tlearn: 96.1095835\ttotal: 3m 47s\tremaining: 31.3s\n",
            "2637:\tlearn: 96.1085971\ttotal: 3m 47s\tremaining: 31.2s\n",
            "2638:\tlearn: 96.1077803\ttotal: 3m 47s\tremaining: 31.2s\n",
            "2639:\tlearn: 96.1056088\ttotal: 3m 47s\tremaining: 31.1s\n",
            "2640:\tlearn: 96.1050221\ttotal: 3m 47s\tremaining: 31s\n",
            "2641:\tlearn: 96.1034572\ttotal: 3m 48s\tremaining: 30.9s\n",
            "2642:\tlearn: 96.1029447\ttotal: 3m 48s\tremaining: 30.8s\n",
            "2643:\tlearn: 96.0994280\ttotal: 3m 48s\tremaining: 30.7s\n",
            "2644:\tlearn: 96.0959085\ttotal: 3m 48s\tremaining: 30.6s\n",
            "2645:\tlearn: 96.0854824\ttotal: 3m 48s\tremaining: 30.6s\n",
            "2646:\tlearn: 96.0845140\ttotal: 3m 48s\tremaining: 30.5s\n",
            "2647:\tlearn: 96.0841221\ttotal: 3m 48s\tremaining: 30.4s\n",
            "2648:\tlearn: 96.0839137\ttotal: 3m 48s\tremaining: 30.3s\n",
            "2649:\tlearn: 96.0795984\ttotal: 3m 48s\tremaining: 30.2s\n",
            "2650:\tlearn: 96.0790749\ttotal: 3m 48s\tremaining: 30.1s\n",
            "2651:\tlearn: 96.0736979\ttotal: 3m 48s\tremaining: 30s\n",
            "2652:\tlearn: 96.0731025\ttotal: 3m 48s\tremaining: 29.9s\n",
            "2653:\tlearn: 96.0721533\ttotal: 3m 49s\tremaining: 29.9s\n",
            "2654:\tlearn: 96.0688205\ttotal: 3m 49s\tremaining: 29.8s\n",
            "2655:\tlearn: 96.0682326\ttotal: 3m 49s\tremaining: 29.7s\n",
            "2656:\tlearn: 96.0674106\ttotal: 3m 49s\tremaining: 29.6s\n",
            "2657:\tlearn: 96.0664847\ttotal: 3m 49s\tremaining: 29.5s\n",
            "2658:\tlearn: 96.0664231\ttotal: 3m 49s\tremaining: 29.4s\n",
            "2659:\tlearn: 96.0634455\ttotal: 3m 49s\tremaining: 29.3s\n",
            "2660:\tlearn: 96.0629813\ttotal: 3m 49s\tremaining: 29.3s\n",
            "2661:\tlearn: 96.0604348\ttotal: 3m 49s\tremaining: 29.2s\n",
            "2662:\tlearn: 96.0534348\ttotal: 3m 49s\tremaining: 29.1s\n",
            "2663:\tlearn: 96.0424647\ttotal: 3m 49s\tremaining: 29s\n",
            "2664:\tlearn: 96.0420564\ttotal: 3m 49s\tremaining: 28.9s\n",
            "2665:\tlearn: 96.0396728\ttotal: 3m 50s\tremaining: 28.8s\n",
            "2666:\tlearn: 96.0365725\ttotal: 3m 50s\tremaining: 28.7s\n",
            "2667:\tlearn: 96.0343324\ttotal: 3m 50s\tremaining: 28.7s\n",
            "2668:\tlearn: 96.0321292\ttotal: 3m 50s\tremaining: 28.6s\n",
            "2669:\tlearn: 96.0276924\ttotal: 3m 50s\tremaining: 28.5s\n",
            "2670:\tlearn: 96.0254386\ttotal: 3m 50s\tremaining: 28.4s\n",
            "2671:\tlearn: 96.0241923\ttotal: 3m 50s\tremaining: 28.3s\n",
            "2672:\tlearn: 96.0235919\ttotal: 3m 50s\tremaining: 28.2s\n",
            "2673:\tlearn: 96.0226966\ttotal: 3m 50s\tremaining: 28.1s\n",
            "2674:\tlearn: 96.0224986\ttotal: 3m 50s\tremaining: 28s\n",
            "2675:\tlearn: 96.0179512\ttotal: 3m 50s\tremaining: 28s\n",
            "2676:\tlearn: 96.0139976\ttotal: 3m 51s\tremaining: 27.9s\n",
            "2677:\tlearn: 96.0112452\ttotal: 3m 51s\tremaining: 27.8s\n",
            "2678:\tlearn: 96.0080949\ttotal: 3m 51s\tremaining: 27.7s\n",
            "2679:\tlearn: 96.0059137\ttotal: 3m 51s\tremaining: 27.6s\n",
            "2680:\tlearn: 96.0026307\ttotal: 3m 51s\tremaining: 27.5s\n",
            "2681:\tlearn: 95.9980249\ttotal: 3m 51s\tremaining: 27.4s\n",
            "2682:\tlearn: 95.9966506\ttotal: 3m 51s\tremaining: 27.4s\n",
            "2683:\tlearn: 95.9932528\ttotal: 3m 51s\tremaining: 27.3s\n",
            "2684:\tlearn: 95.9906598\ttotal: 3m 51s\tremaining: 27.2s\n",
            "2685:\tlearn: 95.9901479\ttotal: 3m 51s\tremaining: 27.1s\n",
            "2686:\tlearn: 95.9887799\ttotal: 3m 51s\tremaining: 27s\n",
            "2687:\tlearn: 95.9879451\ttotal: 3m 52s\tremaining: 26.9s\n",
            "2688:\tlearn: 95.9842045\ttotal: 3m 52s\tremaining: 26.8s\n",
            "2689:\tlearn: 95.9838926\ttotal: 3m 52s\tremaining: 26.8s\n",
            "2690:\tlearn: 95.9649618\ttotal: 3m 52s\tremaining: 26.7s\n",
            "2691:\tlearn: 95.9636925\ttotal: 3m 52s\tremaining: 26.6s\n",
            "2692:\tlearn: 95.9625542\ttotal: 3m 52s\tremaining: 26.5s\n",
            "2693:\tlearn: 95.9621947\ttotal: 3m 52s\tremaining: 26.4s\n",
            "2694:\tlearn: 95.9594238\ttotal: 3m 52s\tremaining: 26.3s\n",
            "2695:\tlearn: 95.9548526\ttotal: 3m 52s\tremaining: 26.2s\n",
            "2696:\tlearn: 95.9525940\ttotal: 3m 52s\tremaining: 26.2s\n",
            "2697:\tlearn: 95.9501837\ttotal: 3m 52s\tremaining: 26.1s\n",
            "2698:\tlearn: 95.9350609\ttotal: 3m 53s\tremaining: 26s\n",
            "2699:\tlearn: 95.9332542\ttotal: 3m 53s\tremaining: 25.9s\n",
            "2700:\tlearn: 95.9262405\ttotal: 3m 53s\tremaining: 25.8s\n",
            "2701:\tlearn: 95.9256017\ttotal: 3m 53s\tremaining: 25.7s\n",
            "2702:\tlearn: 95.9223865\ttotal: 3m 53s\tremaining: 25.6s\n",
            "2703:\tlearn: 95.9208264\ttotal: 3m 53s\tremaining: 25.6s\n",
            "2704:\tlearn: 95.9204669\ttotal: 3m 53s\tremaining: 25.5s\n",
            "2705:\tlearn: 95.9184192\ttotal: 3m 53s\tremaining: 25.4s\n",
            "2706:\tlearn: 95.9118358\ttotal: 3m 53s\tremaining: 25.3s\n",
            "2707:\tlearn: 95.9046289\ttotal: 3m 53s\tremaining: 25.2s\n",
            "2708:\tlearn: 95.9005090\ttotal: 3m 53s\tremaining: 25.1s\n",
            "2709:\tlearn: 95.8993865\ttotal: 3m 53s\tremaining: 25s\n",
            "2710:\tlearn: 95.8969032\ttotal: 3m 54s\tremaining: 25s\n",
            "2711:\tlearn: 95.8919918\ttotal: 3m 54s\tremaining: 24.9s\n",
            "2712:\tlearn: 95.8890990\ttotal: 3m 54s\tremaining: 24.8s\n",
            "2713:\tlearn: 95.8850357\ttotal: 3m 54s\tremaining: 24.7s\n",
            "2714:\tlearn: 95.8811485\ttotal: 3m 54s\tremaining: 24.6s\n",
            "2715:\tlearn: 95.8801699\ttotal: 3m 54s\tremaining: 24.5s\n",
            "2716:\tlearn: 95.8799798\ttotal: 3m 54s\tremaining: 24.4s\n",
            "2717:\tlearn: 95.8790739\ttotal: 3m 54s\tremaining: 24.3s\n",
            "2718:\tlearn: 95.8784771\ttotal: 3m 54s\tremaining: 24.3s\n",
            "2719:\tlearn: 95.8770363\ttotal: 3m 54s\tremaining: 24.2s\n",
            "2720:\tlearn: 95.8756096\ttotal: 3m 54s\tremaining: 24.1s\n",
            "2721:\tlearn: 95.8749192\ttotal: 3m 55s\tremaining: 24s\n",
            "2722:\tlearn: 95.8723084\ttotal: 3m 55s\tremaining: 23.9s\n",
            "2723:\tlearn: 95.8706183\ttotal: 3m 55s\tremaining: 23.8s\n",
            "2724:\tlearn: 95.8695964\ttotal: 3m 55s\tremaining: 23.7s\n",
            "2725:\tlearn: 95.8661301\ttotal: 3m 55s\tremaining: 23.7s\n",
            "2726:\tlearn: 95.8652140\ttotal: 3m 55s\tremaining: 23.6s\n",
            "2727:\tlearn: 95.8640070\ttotal: 3m 55s\tremaining: 23.5s\n",
            "2728:\tlearn: 95.8619574\ttotal: 3m 55s\tremaining: 23.4s\n",
            "2729:\tlearn: 95.8515506\ttotal: 3m 55s\tremaining: 23.3s\n",
            "2730:\tlearn: 95.8514492\ttotal: 3m 55s\tremaining: 23.2s\n",
            "2731:\tlearn: 95.8512160\ttotal: 3m 55s\tremaining: 23.1s\n",
            "2732:\tlearn: 95.8492882\ttotal: 3m 55s\tremaining: 23.1s\n",
            "2733:\tlearn: 95.8464405\ttotal: 3m 56s\tremaining: 23s\n",
            "2734:\tlearn: 95.8429990\ttotal: 3m 56s\tremaining: 22.9s\n",
            "2735:\tlearn: 95.8416817\ttotal: 3m 56s\tremaining: 22.8s\n",
            "2736:\tlearn: 95.8354315\ttotal: 3m 56s\tremaining: 22.7s\n",
            "2737:\tlearn: 95.8340845\ttotal: 3m 56s\tremaining: 22.6s\n",
            "2738:\tlearn: 95.8331789\ttotal: 3m 56s\tremaining: 22.5s\n",
            "2739:\tlearn: 95.8316266\ttotal: 3m 56s\tremaining: 22.4s\n",
            "2740:\tlearn: 95.8278344\ttotal: 3m 56s\tremaining: 22.4s\n",
            "2741:\tlearn: 95.8268829\ttotal: 3m 56s\tremaining: 22.3s\n",
            "2742:\tlearn: 95.8266372\ttotal: 3m 56s\tremaining: 22.2s\n",
            "2743:\tlearn: 95.8264667\ttotal: 3m 56s\tremaining: 22.1s\n",
            "2744:\tlearn: 95.8212451\ttotal: 3m 56s\tremaining: 22s\n",
            "2745:\tlearn: 95.8209954\ttotal: 3m 57s\tremaining: 21.9s\n",
            "2746:\tlearn: 95.8203674\ttotal: 3m 57s\tremaining: 21.8s\n",
            "2747:\tlearn: 95.8203485\ttotal: 3m 57s\tremaining: 21.8s\n",
            "2748:\tlearn: 95.8183258\ttotal: 3m 57s\tremaining: 21.7s\n",
            "2749:\tlearn: 95.8169109\ttotal: 3m 57s\tremaining: 21.6s\n",
            "2750:\tlearn: 95.8154110\ttotal: 3m 57s\tremaining: 21.5s\n",
            "2751:\tlearn: 95.8143544\ttotal: 3m 57s\tremaining: 21.4s\n",
            "2752:\tlearn: 95.8104790\ttotal: 3m 57s\tremaining: 21.3s\n",
            "2753:\tlearn: 95.8104220\ttotal: 3m 57s\tremaining: 21.2s\n",
            "2754:\tlearn: 95.8098878\ttotal: 3m 57s\tremaining: 21.2s\n",
            "2755:\tlearn: 95.8096280\ttotal: 3m 57s\tremaining: 21.1s\n",
            "2756:\tlearn: 95.8061054\ttotal: 3m 58s\tremaining: 21s\n",
            "2757:\tlearn: 95.8041652\ttotal: 3m 58s\tremaining: 20.9s\n",
            "2758:\tlearn: 95.8024032\ttotal: 3m 58s\tremaining: 20.8s\n",
            "2759:\tlearn: 95.8010973\ttotal: 3m 58s\tremaining: 20.7s\n",
            "2760:\tlearn: 95.7984132\ttotal: 3m 58s\tremaining: 20.6s\n",
            "2761:\tlearn: 95.7952590\ttotal: 3m 58s\tremaining: 20.5s\n",
            "2762:\tlearn: 95.7943775\ttotal: 3m 58s\tremaining: 20.5s\n",
            "2763:\tlearn: 95.7927406\ttotal: 3m 58s\tremaining: 20.4s\n",
            "2764:\tlearn: 95.7922088\ttotal: 3m 58s\tremaining: 20.3s\n",
            "2765:\tlearn: 95.7878679\ttotal: 3m 58s\tremaining: 20.2s\n",
            "2766:\tlearn: 95.7873986\ttotal: 3m 58s\tremaining: 20.1s\n",
            "2767:\tlearn: 95.7859168\ttotal: 3m 58s\tremaining: 20s\n",
            "2768:\tlearn: 95.7833341\ttotal: 3m 59s\tremaining: 19.9s\n",
            "2769:\tlearn: 95.7795210\ttotal: 3m 59s\tremaining: 19.9s\n",
            "2770:\tlearn: 95.7764942\ttotal: 3m 59s\tremaining: 19.8s\n",
            "2771:\tlearn: 95.7739158\ttotal: 3m 59s\tremaining: 19.7s\n",
            "2772:\tlearn: 95.7568170\ttotal: 3m 59s\tremaining: 19.6s\n",
            "2773:\tlearn: 95.7559090\ttotal: 3m 59s\tremaining: 19.5s\n",
            "2774:\tlearn: 95.7502538\ttotal: 3m 59s\tremaining: 19.4s\n",
            "2775:\tlearn: 95.7480802\ttotal: 3m 59s\tremaining: 19.3s\n",
            "2776:\tlearn: 95.7468403\ttotal: 3m 59s\tremaining: 19.3s\n",
            "2777:\tlearn: 95.7446598\ttotal: 3m 59s\tremaining: 19.2s\n",
            "2778:\tlearn: 95.7442392\ttotal: 3m 59s\tremaining: 19.1s\n",
            "2779:\tlearn: 95.7430786\ttotal: 4m\tremaining: 19s\n",
            "2780:\tlearn: 95.7430138\ttotal: 4m\tremaining: 18.9s\n",
            "2781:\tlearn: 95.7398347\ttotal: 4m\tremaining: 18.8s\n",
            "2782:\tlearn: 95.7387151\ttotal: 4m\tremaining: 18.7s\n",
            "2783:\tlearn: 95.7348106\ttotal: 4m\tremaining: 18.6s\n",
            "2784:\tlearn: 95.7313236\ttotal: 4m\tremaining: 18.6s\n",
            "2785:\tlearn: 95.7271700\ttotal: 4m\tremaining: 18.5s\n",
            "2786:\tlearn: 95.7246925\ttotal: 4m\tremaining: 18.4s\n",
            "2787:\tlearn: 95.7233597\ttotal: 4m\tremaining: 18.3s\n",
            "2788:\tlearn: 95.7180784\ttotal: 4m\tremaining: 18.2s\n",
            "2789:\tlearn: 95.7153294\ttotal: 4m\tremaining: 18.1s\n",
            "2790:\tlearn: 95.7149611\ttotal: 4m\tremaining: 18s\n",
            "2791:\tlearn: 95.7141040\ttotal: 4m 1s\tremaining: 18s\n",
            "2792:\tlearn: 95.7112566\ttotal: 4m 1s\tremaining: 17.9s\n",
            "2793:\tlearn: 95.7084672\ttotal: 4m 1s\tremaining: 17.8s\n",
            "2794:\tlearn: 95.7045248\ttotal: 4m 1s\tremaining: 17.7s\n",
            "2795:\tlearn: 95.7031119\ttotal: 4m 1s\tremaining: 17.6s\n",
            "2796:\tlearn: 95.7012580\ttotal: 4m 1s\tremaining: 17.5s\n",
            "2797:\tlearn: 95.6995706\ttotal: 4m 1s\tremaining: 17.4s\n",
            "2798:\tlearn: 95.6989103\ttotal: 4m 1s\tremaining: 17.4s\n",
            "2799:\tlearn: 95.6980691\ttotal: 4m 1s\tremaining: 17.3s\n",
            "2800:\tlearn: 95.6969103\ttotal: 4m 1s\tremaining: 17.2s\n",
            "2801:\tlearn: 95.6929529\ttotal: 4m 1s\tremaining: 17.1s\n",
            "2802:\tlearn: 95.6928913\ttotal: 4m 2s\tremaining: 17s\n",
            "2803:\tlearn: 95.6891304\ttotal: 4m 2s\tremaining: 16.9s\n",
            "2804:\tlearn: 95.6882988\ttotal: 4m 2s\tremaining: 16.8s\n",
            "2805:\tlearn: 95.6842172\ttotal: 4m 2s\tremaining: 16.8s\n",
            "2806:\tlearn: 95.6840554\ttotal: 4m 2s\tremaining: 16.7s\n",
            "2807:\tlearn: 95.6803956\ttotal: 4m 2s\tremaining: 16.6s\n",
            "2808:\tlearn: 95.6766981\ttotal: 4m 2s\tremaining: 16.5s\n",
            "2809:\tlearn: 95.6760437\ttotal: 4m 2s\tremaining: 16.4s\n",
            "2810:\tlearn: 95.6722024\ttotal: 4m 2s\tremaining: 16.3s\n",
            "2811:\tlearn: 95.6675721\ttotal: 4m 2s\tremaining: 16.2s\n",
            "2812:\tlearn: 95.6675193\ttotal: 4m 2s\tremaining: 16.1s\n",
            "2813:\tlearn: 95.6663107\ttotal: 4m 3s\tremaining: 16.1s\n",
            "2814:\tlearn: 95.6639850\ttotal: 4m 3s\tremaining: 16s\n",
            "2815:\tlearn: 95.6591356\ttotal: 4m 3s\tremaining: 15.9s\n",
            "2816:\tlearn: 95.6587294\ttotal: 4m 3s\tremaining: 15.8s\n",
            "2817:\tlearn: 95.6547879\ttotal: 4m 3s\tremaining: 15.7s\n",
            "2818:\tlearn: 95.6523399\ttotal: 4m 3s\tremaining: 15.6s\n",
            "2819:\tlearn: 95.6515513\ttotal: 4m 3s\tremaining: 15.5s\n",
            "2820:\tlearn: 95.6510267\ttotal: 4m 3s\tremaining: 15.5s\n",
            "2821:\tlearn: 95.6505407\ttotal: 4m 3s\tremaining: 15.4s\n",
            "2822:\tlearn: 95.6436951\ttotal: 4m 3s\tremaining: 15.3s\n",
            "2823:\tlearn: 95.6430615\ttotal: 4m 3s\tremaining: 15.2s\n",
            "2824:\tlearn: 95.6418249\ttotal: 4m 3s\tremaining: 15.1s\n",
            "2825:\tlearn: 95.6413132\ttotal: 4m 4s\tremaining: 15s\n",
            "2826:\tlearn: 95.6411631\ttotal: 4m 4s\tremaining: 14.9s\n",
            "2827:\tlearn: 95.6351940\ttotal: 4m 4s\tremaining: 14.9s\n",
            "2828:\tlearn: 95.6325255\ttotal: 4m 4s\tremaining: 14.8s\n",
            "2829:\tlearn: 95.6272584\ttotal: 4m 4s\tremaining: 14.7s\n",
            "2830:\tlearn: 95.6267089\ttotal: 4m 4s\tremaining: 14.6s\n",
            "2831:\tlearn: 95.6210267\ttotal: 4m 4s\tremaining: 14.5s\n",
            "2832:\tlearn: 95.6174472\ttotal: 4m 4s\tremaining: 14.4s\n",
            "2833:\tlearn: 95.6157311\ttotal: 4m 4s\tremaining: 14.3s\n",
            "2834:\tlearn: 95.6153450\ttotal: 4m 4s\tremaining: 14.2s\n",
            "2835:\tlearn: 95.6146325\ttotal: 4m 4s\tremaining: 14.2s\n",
            "2836:\tlearn: 95.6141873\ttotal: 4m 4s\tremaining: 14.1s\n",
            "2837:\tlearn: 95.6110074\ttotal: 4m 5s\tremaining: 14s\n",
            "2838:\tlearn: 95.6078153\ttotal: 4m 5s\tremaining: 13.9s\n",
            "2839:\tlearn: 95.6053182\ttotal: 4m 5s\tremaining: 13.8s\n",
            "2840:\tlearn: 95.6048365\ttotal: 4m 5s\tremaining: 13.7s\n",
            "2841:\tlearn: 95.6024447\ttotal: 4m 5s\tremaining: 13.6s\n",
            "2842:\tlearn: 95.6012903\ttotal: 4m 5s\tremaining: 13.6s\n",
            "2843:\tlearn: 95.5976869\ttotal: 4m 5s\tremaining: 13.5s\n",
            "2844:\tlearn: 95.5925882\ttotal: 4m 5s\tremaining: 13.4s\n",
            "2845:\tlearn: 95.5855477\ttotal: 4m 5s\tremaining: 13.3s\n",
            "2846:\tlearn: 95.5849482\ttotal: 4m 5s\tremaining: 13.2s\n",
            "2847:\tlearn: 95.5773727\ttotal: 4m 5s\tremaining: 13.1s\n",
            "2848:\tlearn: 95.5768808\ttotal: 4m 6s\tremaining: 13s\n",
            "2849:\tlearn: 95.5762868\ttotal: 4m 6s\tremaining: 13s\n",
            "2850:\tlearn: 95.5760142\ttotal: 4m 6s\tremaining: 12.9s\n",
            "2851:\tlearn: 95.5754362\ttotal: 4m 6s\tremaining: 12.8s\n",
            "2852:\tlearn: 95.5744146\ttotal: 4m 6s\tremaining: 12.7s\n",
            "2853:\tlearn: 95.5736063\ttotal: 4m 6s\tremaining: 12.6s\n",
            "2854:\tlearn: 95.5735336\ttotal: 4m 6s\tremaining: 12.5s\n",
            "2855:\tlearn: 95.5703751\ttotal: 4m 6s\tremaining: 12.4s\n",
            "2856:\tlearn: 95.5702186\ttotal: 4m 6s\tremaining: 12.3s\n",
            "2857:\tlearn: 95.5587879\ttotal: 4m 6s\tremaining: 12.3s\n",
            "2858:\tlearn: 95.5584305\ttotal: 4m 6s\tremaining: 12.2s\n",
            "2859:\tlearn: 95.5576778\ttotal: 4m 6s\tremaining: 12.1s\n",
            "2860:\tlearn: 95.5573238\ttotal: 4m 7s\tremaining: 12s\n",
            "2861:\tlearn: 95.5532677\ttotal: 4m 7s\tremaining: 11.9s\n",
            "2862:\tlearn: 95.5522932\ttotal: 4m 7s\tremaining: 11.8s\n",
            "2863:\tlearn: 95.5516996\ttotal: 4m 7s\tremaining: 11.7s\n",
            "2864:\tlearn: 95.5487198\ttotal: 4m 7s\tremaining: 11.7s\n",
            "2865:\tlearn: 95.5463368\ttotal: 4m 7s\tremaining: 11.6s\n",
            "2866:\tlearn: 95.5457430\ttotal: 4m 7s\tremaining: 11.5s\n",
            "2867:\tlearn: 95.5430294\ttotal: 4m 7s\tremaining: 11.4s\n",
            "2868:\tlearn: 95.5417053\ttotal: 4m 7s\tremaining: 11.3s\n",
            "2869:\tlearn: 95.5405476\ttotal: 4m 7s\tremaining: 11.2s\n",
            "2870:\tlearn: 95.5393604\ttotal: 4m 7s\tremaining: 11.1s\n",
            "2871:\tlearn: 95.5342341\ttotal: 4m 8s\tremaining: 11.1s\n",
            "2872:\tlearn: 95.5325547\ttotal: 4m 8s\tremaining: 11s\n",
            "2873:\tlearn: 95.5319488\ttotal: 4m 8s\tremaining: 10.9s\n",
            "2874:\tlearn: 95.5314106\ttotal: 4m 8s\tremaining: 10.8s\n",
            "2875:\tlearn: 95.5248221\ttotal: 4m 8s\tremaining: 10.7s\n",
            "2876:\tlearn: 95.5247890\ttotal: 4m 8s\tremaining: 10.6s\n",
            "2877:\tlearn: 95.5227453\ttotal: 4m 8s\tremaining: 10.5s\n",
            "2878:\tlearn: 95.5214602\ttotal: 4m 8s\tremaining: 10.4s\n",
            "2879:\tlearn: 95.5214344\ttotal: 4m 8s\tremaining: 10.4s\n",
            "2880:\tlearn: 95.5207605\ttotal: 4m 8s\tremaining: 10.3s\n",
            "2881:\tlearn: 95.5195416\ttotal: 4m 8s\tremaining: 10.2s\n",
            "2882:\tlearn: 95.5190936\ttotal: 4m 8s\tremaining: 10.1s\n",
            "2883:\tlearn: 95.5189023\ttotal: 4m 9s\tremaining: 10s\n",
            "2884:\tlearn: 95.5150239\ttotal: 4m 9s\tremaining: 9.93s\n",
            "2885:\tlearn: 95.5138116\ttotal: 4m 9s\tremaining: 9.84s\n",
            "2886:\tlearn: 95.5134925\ttotal: 4m 9s\tremaining: 9.76s\n",
            "2887:\tlearn: 95.5127457\ttotal: 4m 9s\tremaining: 9.67s\n",
            "2888:\tlearn: 95.5120719\ttotal: 4m 9s\tremaining: 9.58s\n",
            "2889:\tlearn: 95.5087114\ttotal: 4m 9s\tremaining: 9.5s\n",
            "2890:\tlearn: 95.5052942\ttotal: 4m 9s\tremaining: 9.41s\n",
            "2891:\tlearn: 95.4985752\ttotal: 4m 9s\tremaining: 9.32s\n",
            "2892:\tlearn: 95.4971119\ttotal: 4m 9s\tremaining: 9.24s\n",
            "2893:\tlearn: 95.4942497\ttotal: 4m 9s\tremaining: 9.15s\n",
            "2894:\tlearn: 95.4934086\ttotal: 4m 9s\tremaining: 9.07s\n",
            "2895:\tlearn: 95.4894820\ttotal: 4m 10s\tremaining: 8.98s\n",
            "2896:\tlearn: 95.4888972\ttotal: 4m 10s\tremaining: 8.89s\n",
            "2897:\tlearn: 95.4887162\ttotal: 4m 10s\tremaining: 8.81s\n",
            "2898:\tlearn: 95.4837369\ttotal: 4m 10s\tremaining: 8.72s\n",
            "2899:\tlearn: 95.4822116\ttotal: 4m 10s\tremaining: 8.63s\n",
            "2900:\tlearn: 95.4752593\ttotal: 4m 10s\tremaining: 8.55s\n",
            "2901:\tlearn: 95.4743739\ttotal: 4m 10s\tremaining: 8.46s\n",
            "2902:\tlearn: 95.4707520\ttotal: 4m 10s\tremaining: 8.38s\n",
            "2903:\tlearn: 95.4674956\ttotal: 4m 10s\tremaining: 8.29s\n",
            "2904:\tlearn: 95.4667281\ttotal: 4m 10s\tremaining: 8.2s\n",
            "2905:\tlearn: 95.4547430\ttotal: 4m 10s\tremaining: 8.12s\n",
            "2906:\tlearn: 95.4508087\ttotal: 4m 11s\tremaining: 8.03s\n",
            "2907:\tlearn: 95.4482426\ttotal: 4m 11s\tremaining: 7.94s\n",
            "2908:\tlearn: 95.4433123\ttotal: 4m 11s\tremaining: 7.86s\n",
            "2909:\tlearn: 95.4430419\ttotal: 4m 11s\tremaining: 7.77s\n",
            "2910:\tlearn: 95.4400625\ttotal: 4m 11s\tremaining: 7.68s\n",
            "2911:\tlearn: 95.4396024\ttotal: 4m 11s\tremaining: 7.6s\n",
            "2912:\tlearn: 95.4387299\ttotal: 4m 11s\tremaining: 7.51s\n",
            "2913:\tlearn: 95.4347683\ttotal: 4m 11s\tremaining: 7.43s\n",
            "2914:\tlearn: 95.4333218\ttotal: 4m 11s\tremaining: 7.34s\n",
            "2915:\tlearn: 95.4293027\ttotal: 4m 11s\tremaining: 7.25s\n",
            "2916:\tlearn: 95.4281657\ttotal: 4m 11s\tremaining: 7.17s\n",
            "2917:\tlearn: 95.4272749\ttotal: 4m 12s\tremaining: 7.08s\n",
            "2918:\tlearn: 95.4190280\ttotal: 4m 12s\tremaining: 7s\n",
            "2919:\tlearn: 95.4165972\ttotal: 4m 12s\tremaining: 6.91s\n",
            "2920:\tlearn: 95.4164849\ttotal: 4m 12s\tremaining: 6.82s\n",
            "2921:\tlearn: 95.4102895\ttotal: 4m 12s\tremaining: 6.74s\n",
            "2922:\tlearn: 95.4042968\ttotal: 4m 12s\tremaining: 6.65s\n",
            "2923:\tlearn: 95.4038820\ttotal: 4m 12s\tremaining: 6.56s\n",
            "2924:\tlearn: 95.3986180\ttotal: 4m 12s\tremaining: 6.48s\n",
            "2925:\tlearn: 95.3928691\ttotal: 4m 12s\tremaining: 6.39s\n",
            "2926:\tlearn: 95.3918184\ttotal: 4m 12s\tremaining: 6.3s\n",
            "2927:\tlearn: 95.3904366\ttotal: 4m 12s\tremaining: 6.22s\n",
            "2928:\tlearn: 95.3873817\ttotal: 4m 12s\tremaining: 6.13s\n",
            "2929:\tlearn: 95.3853519\ttotal: 4m 13s\tremaining: 6.04s\n",
            "2930:\tlearn: 95.3842118\ttotal: 4m 13s\tremaining: 5.96s\n",
            "2931:\tlearn: 95.3841890\ttotal: 4m 13s\tremaining: 5.87s\n",
            "2932:\tlearn: 95.3834516\ttotal: 4m 13s\tremaining: 5.79s\n",
            "2933:\tlearn: 95.3783227\ttotal: 4m 13s\tremaining: 5.7s\n",
            "2934:\tlearn: 95.3752385\ttotal: 4m 13s\tremaining: 5.61s\n",
            "2935:\tlearn: 95.3742760\ttotal: 4m 13s\tremaining: 5.53s\n",
            "2936:\tlearn: 95.3689569\ttotal: 4m 13s\tremaining: 5.44s\n",
            "2937:\tlearn: 95.3671335\ttotal: 4m 13s\tremaining: 5.35s\n",
            "2938:\tlearn: 95.3662338\ttotal: 4m 13s\tremaining: 5.27s\n",
            "2939:\tlearn: 95.3652159\ttotal: 4m 13s\tremaining: 5.18s\n",
            "2940:\tlearn: 95.3629185\ttotal: 4m 13s\tremaining: 5.09s\n",
            "2941:\tlearn: 95.3563418\ttotal: 4m 14s\tremaining: 5.01s\n",
            "2942:\tlearn: 95.3557116\ttotal: 4m 14s\tremaining: 4.92s\n",
            "2943:\tlearn: 95.3501561\ttotal: 4m 14s\tremaining: 4.83s\n",
            "2944:\tlearn: 95.3491615\ttotal: 4m 14s\tremaining: 4.75s\n",
            "2945:\tlearn: 95.3484518\ttotal: 4m 14s\tremaining: 4.66s\n",
            "2946:\tlearn: 95.3461423\ttotal: 4m 14s\tremaining: 4.58s\n",
            "2947:\tlearn: 95.3449121\ttotal: 4m 14s\tremaining: 4.49s\n",
            "2948:\tlearn: 95.3447439\ttotal: 4m 14s\tremaining: 4.4s\n",
            "2949:\tlearn: 95.3364687\ttotal: 4m 14s\tremaining: 4.32s\n",
            "2950:\tlearn: 95.3364003\ttotal: 4m 14s\tremaining: 4.23s\n",
            "2951:\tlearn: 95.3342594\ttotal: 4m 14s\tremaining: 4.14s\n",
            "2952:\tlearn: 95.3308814\ttotal: 4m 15s\tremaining: 4.06s\n",
            "2953:\tlearn: 95.3305887\ttotal: 4m 15s\tremaining: 3.97s\n",
            "2954:\tlearn: 95.3304247\ttotal: 4m 15s\tremaining: 3.89s\n",
            "2955:\tlearn: 95.3300956\ttotal: 4m 15s\tremaining: 3.8s\n",
            "2956:\tlearn: 95.3255328\ttotal: 4m 15s\tremaining: 3.71s\n",
            "2957:\tlearn: 95.3241190\ttotal: 4m 15s\tremaining: 3.63s\n",
            "2958:\tlearn: 95.3209088\ttotal: 4m 15s\tremaining: 3.54s\n",
            "2959:\tlearn: 95.3156061\ttotal: 4m 15s\tremaining: 3.45s\n",
            "2960:\tlearn: 95.3102676\ttotal: 4m 15s\tremaining: 3.37s\n",
            "2961:\tlearn: 95.3051746\ttotal: 4m 15s\tremaining: 3.28s\n",
            "2962:\tlearn: 95.3038217\ttotal: 4m 15s\tremaining: 3.19s\n",
            "2963:\tlearn: 95.2989535\ttotal: 4m 15s\tremaining: 3.11s\n",
            "2964:\tlearn: 95.2970485\ttotal: 4m 16s\tremaining: 3.02s\n",
            "2965:\tlearn: 95.2958080\ttotal: 4m 16s\tremaining: 2.94s\n",
            "2966:\tlearn: 95.2934959\ttotal: 4m 16s\tremaining: 2.85s\n",
            "2967:\tlearn: 95.2922661\ttotal: 4m 16s\tremaining: 2.76s\n",
            "2968:\tlearn: 95.2916866\ttotal: 4m 16s\tremaining: 2.68s\n",
            "2969:\tlearn: 95.2880327\ttotal: 4m 16s\tremaining: 2.59s\n",
            "2970:\tlearn: 95.2864555\ttotal: 4m 16s\tremaining: 2.5s\n",
            "2971:\tlearn: 95.2859019\ttotal: 4m 16s\tremaining: 2.42s\n",
            "2972:\tlearn: 95.2845243\ttotal: 4m 16s\tremaining: 2.33s\n",
            "2973:\tlearn: 95.2834758\ttotal: 4m 16s\tremaining: 2.25s\n",
            "2974:\tlearn: 95.2825792\ttotal: 4m 16s\tremaining: 2.16s\n",
            "2975:\tlearn: 95.2780250\ttotal: 4m 17s\tremaining: 2.07s\n",
            "2976:\tlearn: 95.2768241\ttotal: 4m 17s\tremaining: 1.99s\n",
            "2977:\tlearn: 95.2727517\ttotal: 4m 17s\tremaining: 1.9s\n",
            "2978:\tlearn: 95.2716302\ttotal: 4m 17s\tremaining: 1.81s\n",
            "2979:\tlearn: 95.2696259\ttotal: 4m 17s\tremaining: 1.73s\n",
            "2980:\tlearn: 95.2684803\ttotal: 4m 17s\tremaining: 1.64s\n",
            "2981:\tlearn: 95.2672948\ttotal: 4m 17s\tremaining: 1.55s\n",
            "2982:\tlearn: 95.2671063\ttotal: 4m 17s\tremaining: 1.47s\n",
            "2983:\tlearn: 95.2651657\ttotal: 4m 17s\tremaining: 1.38s\n",
            "2984:\tlearn: 95.2641412\ttotal: 4m 17s\tremaining: 1.29s\n",
            "2985:\tlearn: 95.2622974\ttotal: 4m 17s\tremaining: 1.21s\n",
            "2986:\tlearn: 95.2606943\ttotal: 4m 18s\tremaining: 1.12s\n",
            "2987:\tlearn: 95.2601837\ttotal: 4m 18s\tremaining: 1.04s\n",
            "2988:\tlearn: 95.2592158\ttotal: 4m 18s\tremaining: 950ms\n",
            "2989:\tlearn: 95.2554581\ttotal: 4m 18s\tremaining: 864ms\n",
            "2990:\tlearn: 95.2519113\ttotal: 4m 18s\tremaining: 778ms\n",
            "2991:\tlearn: 95.2505644\ttotal: 4m 18s\tremaining: 691ms\n",
            "2992:\tlearn: 95.2451444\ttotal: 4m 18s\tremaining: 605ms\n",
            "2993:\tlearn: 95.2416082\ttotal: 4m 18s\tremaining: 518ms\n",
            "2994:\tlearn: 95.2363973\ttotal: 4m 18s\tremaining: 432ms\n",
            "2995:\tlearn: 95.2294847\ttotal: 4m 18s\tremaining: 346ms\n",
            "2996:\tlearn: 95.2275197\ttotal: 4m 18s\tremaining: 259ms\n",
            "2997:\tlearn: 95.2253139\ttotal: 4m 19s\tremaining: 173ms\n",
            "2998:\tlearn: 95.2250400\ttotal: 4m 19s\tremaining: 86.4ms\n",
            "2999:\tlearn: 95.2244804\ttotal: 4m 19s\tremaining: 0us\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XxMjvjbyyHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('dict.csv', 'w') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    for key, value in mydict.items():\n",
        "       writer.writerow([key, value])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwqb_ktE2ydj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05f3fb68-fa63-4d58-fe43-0df5ef38780d"
      },
      "source": [
        "!pip install optuna "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/b0/9a6313c78bca92abfacc08a2ad8b27bfe845256f615786ee2b6452ae1978/optuna-2.0.0.tar.gz (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 2.8MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 9.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.1MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/63/88/d5e9b78151dce671d7e78ee4cc8905d83208254caa2a386b163ae0ab0027/cmaes-0.6.0-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/81/12d77537c82c5d46aa2721dfee25a0e873ef5920ebd0827152f411effb57/colorlog-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.19)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.48.2)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/6c/60bfe4e7c3ae2e95b30925beba84371502fe06a1ed6a8b51bfd920b2a9c7/cmd2-1.3.8-py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 25.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/f4/041afc90e684f2b7d00a7f49abcbaf0b8c03e916bbc398ce49dce2a3c408/stevedore-3.2.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.7.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.6.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.1.0)\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159540 sha256=83caa9de0b874fe7b6b9e4936ad8ce02bfb770310fbc61f7c105ea3e5ef94b33\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.0.0-cp36-none-any.whl size=312967 sha256=8028feb544c0ffb905d2e412e561efcb1f5ba664df08a7a6bbf2b0a635796de2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/c9/03/c45484454bf657ffed0ed6af153bd3d213928df115eb2a56eb\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=477c950838bc2187d4acc3b4c688c3b65f70571cc0c3e2e58ff1c49f89fc2ddb\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: python-editor, Mako, alembic, colorama, pyperclip, cmd2, pbr, stevedore, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 cliff-3.4.0 cmaes-0.6.0 cmd2-1.3.8 colorama-0.4.3 colorlog-4.2.1 optuna-2.0.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MZmpFonj_eK",
        "colab_type": "text"
      },
      "source": [
        "## **optuna-catboost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUJgcvNejyAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "912786e2-8c53-46e5-c0ff-6304398e74cf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import Pool\n",
        "import sklearn.metrics\n",
        "def objective(trial):\n",
        "    X_train = X_df_dummy_train.dropna().drop([\"y\"],axis=1).values\n",
        "    y_train = .dropna()[\"y\"].values\n",
        "    # トレーニングデータとテストデータを分割\n",
        "    categorical_features_indices = []\n",
        "    for index, j in enumerate(X_train[0]):\n",
        "      if (type(j) == str):\n",
        "        categorical_features_indices.append(index)\n",
        "      train_pool = Pool(X_train, label=y_train, cat_features=categorical_features_indices)\n",
        "      test_pool = Pool(TARGET, label=test_y, cat_features=categorical_features_indices)\n",
        "\n",
        "    # パラメータの指定\n",
        "    params = {\n",
        "        'iterations' : trial.suggest_int('iterations', 50, 300),                         \n",
        "        'depth' : trial.suggest_int('depth', 4, 10),                                       \n",
        "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.3),               \n",
        "        'random_strength' :trial.suggest_int('random_strength', 0, 100),                       \n",
        "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00), \n",
        "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
        "        'od_wait' :trial.suggest_int('od_wait', 10, 50)\n",
        "    }\n",
        "\n",
        "    # 学習\n",
        "    model = CatBoostClassifier(**params)\n",
        "    model.fit(train_pool)\n",
        "    # 予測\n",
        "    pred_y = model.predict(test_pool)\n",
        "    pred_y = np.rint(pred_y)\n",
        "    # 精度 (Accuracy) を検証する\n",
        "    rmse = np.sqrt(mean_squared_error(val_y, pred_y))\n",
        "    print('RMSE:', rmse)\n",
        "\n",
        "    return rmse\n",
        "\n",
        "import optuna\n",
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=10)\n",
        "print(study.best_trial)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[W 2020-08-30 14:54:20,377] Trial 0 failed because of the following error: NameError(\"name 'train_x' is not defined\",)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/optuna/study.py\", line 709, in _run_trial\n",
            "    result = func(trial)\n",
            "  File \"<ipython-input-29-09fcfbb9b39d>\", line 12, in objective\n",
            "    train_pool = Pool(train_x, label=train_y, cat_features=categorical_features_indices)\n",
            "NameError: name 'train_x' is not defined\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-09fcfbb9b39d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m                 )\n\u001b[1;32m    294\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    652\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-09fcfbb9b39d>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mtrain_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mtest_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    }
  ]
}